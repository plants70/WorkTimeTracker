================================================================================
PROJECT SNAPSHOT
Generated:   2025-09-02 17:12:59
Root:        C:\moy python\projects vs code\roma
Python:      3.13.5
================================================================================

================================================================================
PROJECT TREE
================================================================================
├── .env
├── .gitignore
├── __init__.py
├── admin_app
│   ├── gui_admin.py
│   ├── main_admin.py
│   ├── repo.py
│   └── schedule_parser.py
├── archiver.py
├── auto_sync.py
├── build_admin.py
├── build_user.py
├── bundle_project.py
├── config.py
├── credentials
│   └── secret_creds.zip
├── diagnose_sync.log
├── diagnose_user_log.log
├── diagnostics_report.json
├── libcrypto-1_1-x64.dll
├── libcrypto-1_1.dll
├── libssl-1_1-x64.dll
├── libssl-1_1.dll
├── local_backup.db
├── logging_setup.py
├── logs

├── map_project.py
├── project_report.txt
├── pyproject.toml
├── requirements.txt
├── secret_creds.zip
├── sheets_api.py
├── sync
│   ├── __init__.py
│   ├── network.py
│   ├── notifications.py
│   └── sync_queue.py
├── telegram_bot
│   ├── __init__.py
│   ├── main.py
│   └── notifier.py
├── tools
│   ├── doctor.py
│   ├── tg_envcheck.py
│   └── tg_send.py
├── user_app
│   ├── __init__.py
│   ├── api.py
│   ├── app.log
│   ├── db_local.py
│   ├── db_migrations.py
│   ├── gui.py
│   ├── login_window.py
│   ├── main.py
│   ├── sberhealf.ico
│   ├── sberhealf.png
│   ├── signals.py
│   └── ui_helpers.py
└── work_time_tracker.egg-info
    ├── PKG-INFO
    ├── SOURCES.txt
    ├── dependency_links.txt
    ├── entry_points.txt
    ├── requires.txt
    └── top_level.txt

================================================================================
LOCAL SQLITE OVERVIEW
DB Path: c:\moy python\projects vs code\roma\local_backup.db
================================================================================
database_list: [(0, 'main', 'c:\\moy python\\projects vs code\\roma\\local_backup.db')]
--------------------------------------------------------------------------------
[TABLE] app_logs
schema: CREATE TABLE app_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - level TEXT NOTNULL=1 PK=0 DEFAULT=None
  - message TEXT NOTNULL=1 PK=0 DEFAULT=None
indexes:
  - idx_app_logs_ts UNIQUE=0
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TABLE] app_logs_legacy_20250826175446
schema: CREATE TABLE "app_logs_legacy_20250826175446" (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - level TEXT NOTNULL=1 PK=0 DEFAULT=None
  - message TEXT NOTNULL=1 PK=0 DEFAULT=None
indexes:
  - idx_logs_ts UNIQUE=0
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TABLE] logs
schema: CREATE TABLE logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                email TEXT NOT NULL,
                name TEXT NOT NULL,
                status TEXT,
                action_type TEXT NOT NULL,
                comment TEXT,
                timestamp TEXT NOT NULL,
                synced INTEGER DEFAULT 0,
                sync_attempts INTEGER DEFAULT 0,
                last_sync_attempt TEXT,
                priority INTEGER DEFAULT 1,
                status_start_time TEXT,
                status_end_time TEXT,
                reason TEXT,
                user_group TEXT
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - session_id TEXT NOTNULL=1 PK=0 DEFAULT=None
  - email TEXT NOTNULL=1 PK=0 DEFAULT=None
  - name TEXT NOTNULL=1 PK=0 DEFAULT=None
  - status TEXT NOTNULL=0 PK=0 DEFAULT=None
  - action_type TEXT NOTNULL=1 PK=0 DEFAULT=None
  - comment TEXT NOTNULL=0 PK=0 DEFAULT=None
  - timestamp TEXT NOTNULL=1 PK=0 DEFAULT=None
  - synced INTEGER NOTNULL=0 PK=0 DEFAULT=0
  - sync_attempts INTEGER NOTNULL=0 PK=0 DEFAULT=0
  - last_sync_attempt TEXT NOTNULL=0 PK=0 DEFAULT=None
  - priority INTEGER NOTNULL=0 PK=0 DEFAULT=1
  - status_start_time TEXT NOTNULL=0 PK=0 DEFAULT=None
  - status_end_time TEXT NOTNULL=0 PK=0 DEFAULT=None
  - reason TEXT NOTNULL=0 PK=0 DEFAULT=None
  - user_group TEXT NOTNULL=0 PK=0 DEFAULT=None
indexes:
  - idx_logs_session UNIQUE=0
      * 1: session_id
  - idx_logs_timestamp UNIQUE=0
      * 7: timestamp
  - idx_logs_synced UNIQUE=0
      * 8: synced
  - idx_logs_email UNIQUE=0
      * 2: email
triggers:
  - check_comment_length: CREATE TRIGGER check_comment_length
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN length(NEW.comment) > 500
            BEGIN
                SELECT RAISE(ABORT, 'Comment too long');
            END
  - prevent_duplicate_logout: CREATE TRIGGER prevent_duplicate_logout
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (
                SELECT 1 FROM logs
                WHERE session_id = NEW.session_id
                  AND LOWER(action_type) = 'logout'
                  AND timestamp > datetime('now', '-5 minutes')
            )
            BEGIN
                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');
            END
rows_count: 26
sample rows (last):
  • (26, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Завершено', 'LOGOUT', 'Завершение смены (нормальное)', '2025-09-02T07:31:20.622314+00:00', 0, 0, None, 1, '2025-09-02T10:31:20.622249', '2025-09-02T10:31:20.622249', 'user', 'Стоматология')
  • (25, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Аудио', 'STATUS_CHANGE', None, '2025-09-02T07:30:03.200596+00:00', 1, 1, '2025-09-02T07:30:05.016279+00:00', 1, '2025-09-02T10:30:03.197439', '2025-09-02T07:31:20.619894+00:00', None, None)
  • (24, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Чат', 'STATUS_CHANGE', None, '2025-09-02T07:29:57.160421+00:00', 1, 2, '2025-09-02T07:30:03.496395+00:00', 1, '2025-09-02T10:29:57.156445', '2025-09-02T10:30:03.197439', None, None)
  • (23, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-02T07:25:58.866299+00:00', 1, 2, '2025-09-02T07:29:57.501512+00:00', 1, '2025-09-02T10:25:58.866228', '2025-09-02T10:29:57.156445', None, None)
  • (22, '10@ya.ru_20250901175741', '10@ya.ru', 'тест стом 3', 'Завершено', 'LOGOUT', 'Приложение закрыто через крестик', '2025-09-02T05:58:06.182047+00:00', 0, 0, None, 1, '2025-09-02T08:58:06.181994', '2025-09-02T08:58:06.181994', 'user', 'Стоматология')
--------------------------------------------------------------------------------
[TABLE] offline_actions
schema: CREATE TABLE offline_actions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                action_type TEXT NOT NULL,
                payload TEXT NOT NULL,  -- JSON-строка
                status TEXT NOT NULL DEFAULT 'pending'  -- pending|synced|failed
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - action_type TEXT NOTNULL=1 PK=0 DEFAULT=None
  - payload TEXT NOTNULL=1 PK=0 DEFAULT=None
  - status TEXT NOTNULL=1 PK=0 DEFAULT='pending'
indexes:
  - idx_offline_actions_status_ts UNIQUE=0
      * 4: status
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TRIGGERS GLOBAL]
  - check_comment_length on logs: CREATE TRIGGER check_comment_length
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN length(NEW.comment) > 500
            BEGIN
                SELECT RAISE(ABORT, 'Comment too long');
            END
  - prevent_duplicate_logout on logs: CREATE TRIGGER prevent_duplicate_logout
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (
                SELECT 1 FROM logs
                WHERE session_id = NEW.session_id
                  AND LOWER(action_type) = 'logout'
                  AND timestamp > datetime('now', '-5 minutes')
            )
            BEGIN
                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');
            END
================================================================================
GOOGLE SHEETS OVERVIEW
================================================================================
Spreadsheet: WorkLog
--------------------------------------------------------------------------------
[SHEET] Admins
header: ['Login', 'Password']
rows_count (non-empty): 1
sample rows (first 3):
  • ['Admin', 'qwerty']
--------------------------------------------------------------------------------
[SHEET] Users
header: ['Email', 'Name', 'Phone', 'Role', 'Telegram', 'ShiftHours', 'Hours', 'NotifyTelegram', 'Group']
rows_count (non-empty): 12
sample rows (first 3):
  • ['1@ya.ru', 'тестовый чел', '888', 'Специалист', '', '5/2', '8', '', '']
  • ['2@ya.ru', 'Тестовый Вася', '111', '', '', '', '', '', '']
  • ['3@ya.ru', 'третий чел', '3333', '', '', '', '', '', '']
--------------------------------------------------------------------------------
[SHEET] Groups
header: ['Group', 'Sheet', 'Statuses', 'Возможные статусы: "В работе",\n    "Чат",\n    "Аудио",\n    "Запись",\n    "Анкеты",\n    "Перерыв",\n    "Обед",\n    "ЦИТО",\n    "Обучение" \nУказывать через запятую, без ковычек']
rows_count (non-empty): 4
sample rows (first 3):
  • ['Входящие', 'WorkLog_Входящие', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
  • ['Запись', 'WorkLog_Запись', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
  • ['Стоматология', 'WorkLog_Стоматология', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Запись
header: ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517']
rows_count (non-empty): 6
sample rows (first 3):
  • ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517', '', '']
  • ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517', '2025-08-25T17:49:56.465386', '']
  • ['123@ya.ru', 'тест записи', 'Завершено', 'LOGOUT', 'Разлогинен администратором (удалённо)', '2025-08-25T17:49:56.505634', '123@ya.r_20250825174924', '2025-08-25T17:49:56.505530', '2025-08-25T17:49:56.505530', 'admin']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Входящие
header: ['Email', 'Name', 'Status', 'ActionType', 'Comment', 'Timestamp', 'SessionID', 'StatusStartTime', 'StatusEndTime']
rows_count (non-empty): 27
sample rows (first 3):
  • ['7@ya.ru_20250823171203', '7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-23T17:12:03.958642', '2025-08-23T17:12:03.958610', '2025-08-23T17:12:11.051848', '']
  • ['pid:dkuj4sai7negjt4x', 'PID-dkuj4s', 'В работе', 'LOGIN', 'Начало смены', '2025-08-27 14:41:46', 'pid:dkuj_20250827144146', '2025-08-27 17:41:46', '2025-08-27 14:41:52', '']
  • ['pid:dkuj4sai7negjt4x', 'PID-dkuj4s', 'В работе', 'LOGIN', 'Начало смены', '2025-08-27 14:41:46', 'pid:dkuj_20250827144146', '2025-08-27 17:41:46', '2025-08-27 14:57:43', '']
--------------------------------------------------------------------------------
[SHEET] ActiveSessions
header: ['Email', 'Name', 'SessionID', 'LoginTime', 'Status', 'LogoutTime', 'RemoteCommand']
rows_count (non-empty): 158
sample rows (first 3):
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731150702', '2025-07-31T15:07:02', 'finished', '2025-08-15 14:38:22', '']
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731152815', '2025-07-31T15:28:15', 'finished', '2025-07-31T15:28:49.376478', '']
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731154231', '2025-07-31T15:42:31', 'finished', '2025-07-31T15:43:08.484935', '']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Стоматология
header: ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:05:14', '10@ya.ru_20250901160514', '2025-09-01 19:05:14', '2025-09-01 16:05:20']
rows_count (non-empty): 19
sample rows (first 3):
  • ['10@ya.ru', 'тест стом 3', 'Чат', 'STATUS_CHANGE', '', '2025-09-01 16:05:31', '10@ya.ru_20250901160514', '2025-09-01 19:05:31', '2025-09-01 16:05:31']
  • ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:05:14', '10@ya.ru_20250901160514', '2025-09-01 19:05:14', '2025-09-01 19:05:31']
  • ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:48:28', '10@ya.ru_20250901164828', '2025-09-01 19:48:28', '2025-09-01 16:48:33']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Почта
header: ['7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T14:21:50.941225', '7@ya.ru_20250825142150', '2025-08-25T14:21:50.941160']
rows_count (non-empty): 18
sample rows (first 3):
  • ['7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T14:21:50.941225', '7@ya.ru_20250825142150', '2025-08-25T14:21:50.941160', '2025-08-25T14:23:04.217964', '']
  • ['7@ya.ru', 'Тест почты', 'Чат', 'STATUS_CHANGE', '', '2025-08-25T14:23:04.223693', '7@ya.ru_20250825142150', '2025-08-25T14:23:04.217964', '', '']
  • ['7@ya.ru', 'Тест почты', 'Чат', 'STATUS_CHANGE', '', '2025-08-25T14:23:04.223693', '7@ya.ru_20250825142150', '2025-08-25T14:23:04.217964', '2025-08-25T14:25:21.425490', '']
--------------------------------------------------------------------------------
[SHEET] AccessControl
header: ['KeyType', 'KeyValue', 'AccessStatus', 'BlockUntil', 'Reason', 'UpdatedAt']
rows_count (non-empty): 0
================================================================================
PROJECT REPORT
Generated:   2025-09-02 17:14:32
Root:        C:\moy python\projects vs code\roma
Python:      3.13.5
Files:       43
================================================================================


--------------------------------------------------------------------------------
# FILE: .gitignore
# SIZE: 437 bytes | SHA256(text): 927018a20d479a444e2d7d6b4836885f02432e4616c8f83dfb3e523ef6051a83
--------------------------------------------------------------------------------
# Python
__pycache__/
*.pyc
*.pyo
*.pyd

# SQLite (локальные БД)
*.db
*.db-shm
*.db-wal

# Логи
*.log
logs/
*.bak

# Секреты и ключи
.env
secret_creds.zip

# PyInstaller
*.spec
dist/
build/
*.exe
*.dll

# IDE/Editor
.vscode/
.idea/
.DS_Store

# GCP creds — запрещено хранить в репозитории
credentials/*.json
*.secret.json
service_account.json

--------------------------------------------------------------------------------
# FILE: __init__.py
# SIZE: 343 bytes | SHA256(text): 423245e097df4d9c26b80058efa8bc9635eddc1ac1b1a2482e90816d7b154ca6
--------------------------------------------------------------------------------
# Инициализация пакета user_app
from .version import __version__

__all__ = [
    'main',
    'gui', 
    'login_window',
    'db_local',
    'sheets_api',
    'sync'
]

# Инициализация путей
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

--------------------------------------------------------------------------------
# FILE: admin_app\gui_admin.py
# SIZE: 0 bytes | SHA256(text): e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
# FILE: admin_app\main_admin.py
# SIZE: 21626 bytes | SHA256(text): df255496219eed226297ec882cfe813e8cf046f5e231999a37080a23114343a7
--------------------------------------------------------------------------------
# admin_app/main_admin.py
from __future__ import annotations

import sys
import logging
import time
from pathlib import Path
from typing import Optional, Dict, List, Tuple

from PyQt5.QtCore import Qt
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QLineEdit,
    QPushButton, QTableWidget, QTableWidgetItem, QCheckBox, QComboBox, QMessageBox,
    QTabWidget, QGroupBox
)

# --- Единое логирование для админки ---
from logging_setup import setup_logging
from config import LOG_DIR

# --- Доменная логика/репозиторий ---
from admin_app.repo import AdminRepo

# =================== Константы UI ===================
FIELDS = ["Email", "Name", "Phone", "Role", "Telegram", "Group", "NotifyTelegram"]
ROLES = ["специалист", "старший специалист", "ведущий специалист", "руководитель группы"]

# Загрузка GROUP_MAPPING с обработкой ошибок
try:
    # статическая карта групп, если определена в config.py
    from config import GROUP_MAPPING
except Exception:
    GROUP_MAPPING = {}

# =================== Диалог редактирования пользователя ===================
from PyQt5.QtWidgets import QDialog

class UserDialog(QDialog):
    def __init__(self, parent=None, user: Optional[Dict[str, str]] = None, groups: List[str] = None):
        super().__init__(parent)
        self.setWindowTitle("Карточка сотрудника")
        self.user = user or {}
        self.groups = groups or []
        self._build()

    def _build(self):
        layout = QVBoxLayout(self)

        self.email_input = QLineEdit(str(self.user.get("Email", "")))
        self.fio_input = QLineEdit(str(self.user.get("Name", "")))
        self.phone_input = QLineEdit(str(self.user.get("Phone", "")))
        self.tg_input = QLineEdit(str(self.user.get("Telegram", "")))

        self.role_combo = QComboBox()
        self.role_combo.addItems(ROLES)
        role_val = str(self.user.get("Role", "")).strip()
        if role_val in ROLES:
            self.role_combo.setCurrentText(role_val)

        self.group_combo = QComboBox()
        self.group_combo.addItems(self.groups)
        group_val = str(self.user.get("Group", "")).strip()
        if group_val in self.groups:
            self.group_combo.setCurrentText(group_val)

        self.tg_notify_chk = QCheckBox("Отправлять уведомления в Telegram")
        chk = str(self.user.get("NotifyTelegram", "")).strip().lower()
        self.tg_notify_chk.setChecked(chk in ("yes", "true", "1", "да"))

        layout.addWidget(QLabel("Email:"))
        layout.addWidget(self.email_input)
        layout.addWidget(QLabel("ФИО:"))
        layout.addWidget(self.fio_input)
        layout.addWidget(QLabel("Телефон:"))
        layout.addWidget(self.phone_input)
        layout.addWidget(QLabel("Telegram:"))
        layout.addWidget(self.tg_input)
        layout.addWidget(QLabel("Должность:"))
        layout.addWidget(self.role_combo)
        layout.addWidget(QLabel("Группа:"))
        layout.addWidget(self.group_combo)
        layout.addWidget(self.tg_notify_chk)

        btns = QHBoxLayout()
        btn_save = QPushButton("Сохранить")
        btn_save.clicked.connect(self.accept)
        btn_cancel = QPushButton("Отмена")
        btn_cancel.clicked.connect(self.reject)
        btns.addWidget(btn_save)
        btns.addWidget(btn_cancel)
        layout.addLayout(btns)

    def get_user(self) -> Dict[str, str]:
        return {
            "Email": self.email_input.text().strip().lower(),
            "Name": self.fio_input.text().strip(),
            "Phone": self.phone_input.text().strip(),
            "Role": self.role_combo.currentText().strip(),
            "Telegram": self.tg_input.text().strip(),
            "Group": self.group_combo.currentText().strip(),
            "NotifyTelegram": "Yes" if self.tg_notify_chk.isChecked() else "No",
        }

# =================== Главное окно ===================

class AdminWindow(QMainWindow):
    def __init__(self, groups: List[str]):
        super().__init__()
        self.setWindowTitle("Админка WorkTimeTracker")
        self.resize(1400, 780)
        
        # Группы
        self.groups = groups

        # Репозиторий
        self.repo = AdminRepo()

        # Кэш пользователей и активных e-mail
        self.users: List[Dict[str, str]] = []
        self._active_cache: Tuple[float, set[str]] = (0.0, set())  # (ts, {emails})
        self._active_ttl_sec = 30.0

        self._build_ui()
        self.refresh_users()
        self.load_shift_calendar()

    # ---------- UI ----------
    def _build_ui(self):
        self.tabs = QTabWidget(self)

        # --- Вкладка "Сотрудники" ---
        self.tab_users = QWidget()
        users_layout = QVBoxLayout(self.tab_users)

        # Фильтры
        filter_layout = QHBoxLayout()
        filter_layout.addWidget(QLabel("Группа:"))
        self.group_filter_combo = QComboBox()
        self.group_filter_combo.addItem("Все группы")
        self.group_filter_combo.addItems(self.groups)
        self.group_filter_combo.currentIndexChanged.connect(self.apply_user_search)
        filter_layout.addWidget(self.group_filter_combo)

        self.only_active_chk = QCheckBox("Только активные")
        self.only_active_chk.stateChanged.connect(self.apply_user_search)
        filter_layout.addWidget(self.only_active_chk)

        filter_layout.addStretch()
        users_layout.addLayout(filter_layout)

        # Поиск и кнопки
        top_layout = QHBoxLayout()
        self.search_input = QLineEdit()
        self.search_input.setPlaceholderText("Поиск по ФИО или email")
        self.search_input.textChanged.connect(self.apply_user_search)
        top_layout.addWidget(self.search_input)

        btn_add = QPushButton("Добавить")
        btn_add.clicked.connect(self.add_user)
        btn_edit = QPushButton("Редактировать")
        btn_edit.clicked.connect(self.edit_user)
        btn_delete = QPushButton("Удалить")
        btn_delete.clicked.connect(self.on_delete_user_clicked)
        btn_kick = QPushButton("Разлогинить")
        btn_kick.clicked.connect(self.on_force_logout_clicked)

        for b in (btn_add, btn_edit, btn_delete, btn_kick):
            top_layout.addWidget(b)
        users_layout.addLayout(top_layout)

        # Таблица пользователей
        self.users_table = QTableWidget(0, len(FIELDS))
        self.users_table.setHorizontalHeaderLabels(
            ["Email", "ФИО", "Телефон", "Должность", "Telegram", "Группа", "Telegram уведомления"]
        )
        self.users_table.setSelectionBehavior(QTableWidget.SelectRows)
        users_layout.addWidget(self.users_table)

        self.tabs.addTab(self.tab_users, "Сотрудники")

        # --- Вкладка "График" ---
        self.tab_schedule = QWidget()
        schedule_layout = QVBoxLayout(self.tab_schedule)

        header_layout = QHBoxLayout()
        header_layout.addWidget(QLabel("Сотрудник:"))
        self.schedule_user_combo = QComboBox()
        self.schedule_user_combo.addItem("Выберите сотрудника")
        self.schedule_user_combo.currentIndexChanged.connect(self.on_schedule_user_change)
        header_layout.addWidget(self.schedule_user_combo)
        header_layout.addStretch()
        schedule_layout.addLayout(header_layout)

        self.info_group = QGroupBox("Информация о сотруднике")
        info_layout = QVBoxLayout()
        self.login_status_lbl = QLabel("Залогинен: Нет")
        self.btn_force_logout = QPushButton("Разлогинить")
        self.btn_force_logout.setEnabled(False)
        self.btn_force_logout.clicked.connect(self.force_logout_from_schedule)
        status_row = QHBoxLayout()
        status_row.addWidget(self.login_status_lbl)
        status_row.addWidget(self.btn_force_logout)
        status_row.addStretch()
        info_layout.addLayout(status_row)

        self.info_label = QLabel("")
        self.info_label.setWordWrap(True)
        info_layout.addWidget(self.info_label)
        self.info_group.setLayout(info_layout)
        schedule_layout.addWidget(self.info_group)

        self.schedule_table = QTableWidget()
        schedule_layout.addWidget(self.schedule_table)

        self.tabs.addTab(self.tab_schedule, "График")

        # --- Вкладка "Дополнительно" (плейсхолдер) ---
        self.tab_extra = QWidget()
        extra_layout = QVBoxLayout(self.tab_extra)
        extra_layout.addWidget(QLabel("Тут будет что-то ещё"))
        self.tabs.addTab(self.tab_extra, "Дополнительно")

        self.setCentralWidget(self.tabs)

    # ---------- Helpers ----------
    def _selected_email(self) -> Optional[str]:
        items = self.users_table.selectedItems()
        if not items:
            return None
        val = items[0].text().strip()
        return val[2:] if val.startswith("🟢 ") else val

    def _confirm(self, msg: str) -> bool:
        return QMessageBox.question(self, "Подтверждение", msg, QMessageBox.Yes | QMessageBox.No, QMessageBox.No) == QMessageBox.Yes

    def _info(self, msg: str):
        QMessageBox.information(self, "Информация", msg)

    def _warn(self, msg: str):
        QMessageBox.warning(self, "Ошибка", msg)

    # ---------- Активные сессии (кэш) ----------
    def _get_active_emails_cached(self) -> set[str]:
        ts, emails = self._active_cache
        if time.monotonic() - ts < self._active_ttl_sec:
            return emails
        try:
            sessions = self.repo.get_active_sessions()
            emails = {str(s.get("Email", "")).strip().lower() for s in sessions if str(s.get("Status", "")).strip().lower() == "active"}
            self._active_cache = (time.monotonic(), emails)
            return emails
        except Exception as e:
            logger.warning("Не удалось получить активные сессии: %s", e)
            return set()

    # =================== Таб "Сотрудники" ===================

    def refresh_users(self):
        try:
            rows = self.repo.list_users()
        except Exception as e:
            logger.exception("refresh_users failed: %s", e)
            rows = []

        self.users = []
        for r in rows:
            nt = str(r.get("NotifyTelegram", "")).strip().lower()
            nt_norm = "Yes" if nt in ("yes", "true", "1", "да") else "No"
            self.users.append({
                "Email": str(r.get("Email", "")),
                "Name": str(r.get("Name", "")),
                "Phone": str(r.get("Phone", "")),
                "Role": str(r.get("Role", "")),
                "Telegram": str(r.get("Telegram", "")),
                "Group": str(r.get("Group", "")),
                "NotifyTelegram": nt_norm,
            })

        # заполняем таблицу
        self.refresh_users_table()

        # и выпадающий список на вкладке "График"
        self.schedule_user_combo.blockSignals(True)
        self.schedule_user_combo.clear()
        self.schedule_user_combo.addItem("Выберите сотрудника")
        for u in self.users:
            fio = u.get("Name", "")
            if fio:
                self.schedule_user_combo.addItem(fio)
        self.schedule_user_combo.blockSignals(False)

    def refresh_users_table(self, filter_text: str = ""):
        self.users_table.setRowCount(0)
        selected_group = self.group_filter_combo.currentText()
        only_active = self.only_active_chk.isChecked()
        active_emails = self._get_active_emails_cached() if only_active else set()

        for u in self.users:
            email = u.get("Email", "").strip().lower()
            group = u.get("Group", "").strip()
            is_active = email in active_emails

            # поиск
            if filter_text:
                q = filter_text.lower()
                if q not in email and q not in u.get("Name", "").lower():
                    continue
            # фильтр по группе
            if selected_group != "Все группы" and group != selected_group:
                continue
            # фильтр активности
            if only_active and not is_active:
                continue

            row = self.users_table.rowCount()
            self.users_table.insertRow(row)
            for col, key in enumerate(FIELDS):
                val = u.get(key, "")
                if key == "Email" and is_active:
                    val = f"🟢 {val}"
                item = QTableWidgetItem(str(val))
                item.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)
                self.users_table.setItem(row, col, item)

    def apply_user_search(self):
        self.refresh_users_table(self.search_input.text())

    # --- CRUD/Actions ---

    def add_user(self):
        dlg = UserDialog(self, groups=self.groups)
        if dlg.exec_():
            data = dlg.get_user()
            if self.repo.add_or_update_user(data):
                self._info("Пользователь добавлен")
                self.refresh_users()
            else:
                self._warn("Ошибка при добавлении пользователя")

    def edit_user(self):
        row = self.users_table.currentRow()
        if row < 0 or row >= len(self.users):
            self._warn("Сначала выберите строку для редактирования.")
            return
        user = self.users[row]
        dlg = UserDialog(self, user=user, groups=self.groups)
        if dlg.exec_():
            data = dlg.get_user()
            if self.repo.add_or_update_user(data):
                self._info("Пользователь обновлён")
                self.refresh_users()
            else:
                self._warn("Ошибка при обновлении пользователя")

    def on_delete_user_clicked(self):
        email = self._selected_email()
        if not email:
            self._warn("Выберите пользователя")
            return
        if not self._confirm(f"Удалить пользователя {email}?"):
            return
        if self.repo.delete_user(email):
            self._info("Пользователь удалён")
            self.refresh_users()
        else:
            self._warn("Пользователь не найден или не удалён")

    def on_force_logout_clicked(self):
        email = self._selected_email()
        if not email:
            self._warn("Выберите пользователя из списка.")
            return

        # отображаем ФИО для красоты
        fio = ""
        sel = self.users_table.selectedItems()
        if sel and len(sel) > 1:
            fio = sel[1].text()

        if not self._confirm(f"Разлогинить {fio or email}?"):
            return

        if self.repo.force_logout(email=email):
            self._info(f"Пользователь {fio or email} был разлогинен.")
            # сбрасываем кэш активностей, чтобы таблица обновилась корректно
            self._active_cache = (0.0, set())
            self.refresh_users()
        else:
            self._warn("Активная сессия не найдена")

    # =================== Таб "График" ===================

    def load_shift_calendar(self):
        """Подтягиваем таблицу графика. Если её нет — отключаем элементы."""
        try:
            data = self.repo.get_shift_calendar()
        except Exception as e:
            logger.exception("Ошибка при загрузке графика: %s", e)
            data = []

        self.shift_calendar_data: List[List[str]] = data
        self.shift_headers: List[str] = data[0] if data else []

        if not data:
            self.info_label.setText("Лист графика не найден или пуст.")
            self.login_status_lbl.setText("Залогинен: Нет")
            self.btn_force_logout.setEnabled(False)
            self.schedule_table.setRowCount(0)
            self.schedule_table.setColumnCount(0)
            self.schedule_user_combo.setEnabled(bool(self.users))
            return

        self.schedule_user_combo.setEnabled(True)

    def on_schedule_user_change(self):
        idx = self.schedule_user_combo.currentIndex()
        if idx <= 0 or not self.shift_calendar_data:
            self.schedule_table.setRowCount(0)
            self.schedule_table.setColumnCount(0)
            self.info_label.setText("")
            self.login_status_lbl.setText("Залогинен: Нет")
            self.btn_force_logout.setEnabled(False)
            return

        fio = self.schedule_user_combo.currentText()
        email = ""
        for u in self.users:
            if u.get("Name", "") == fio:
                email = u.get("Email", "")
                break

        # статус логина
        active = self._get_active_emails_cached()
        is_logged_in = email.strip().lower() in active
        self.login_status_lbl.setText(f"Залогинен: {'Да' if is_logged_in else 'Нет'}")
        self.btn_force_logout.setEnabled(is_logged_in)
        self.btn_force_logout.setProperty("user_email", email)
        self.btn_force_logout.setProperty("user_fio", fio)

        # инфо по сотруднику
        info_parts = [f"<b>ФИО:</b> {fio}", f"<b>Email:</b> {email}"]
        self.info_label.setText("<br>".join(info_parts))

        # табель по дням (ищем первые числовые заголовки как дни месяца)
        headers = self.shift_headers
        row_for_user: Optional[List[str]] = None
        for r in self.shift_calendar_data[1:]:
            if r and r[0].strip() == fio:
                row_for_user = r
                break

        day_indices = [(i, h) for i, h in enumerate(headers) if str(h).isdigit()]
        self.schedule_table.setRowCount(0)
        self.schedule_table.setColumnCount(len(day_indices))
        self.schedule_table.setHorizontalHeaderLabels([str(h) for _, h in day_indices])

        if row_for_user:
            self.schedule_table.setRowCount(1)
            for col, (i, _) in enumerate(day_indices):
                val = row_for_user[i] if i < len(row_for_user) else ""
                self.schedule_table.setItem(0, col, QTableWidgetItem(str(val)))
            self.schedule_table.resizeColumnsToContents()

    def force_logout_from_schedule(self):
        email = self.btn_force_logout.property("user_email")
        fio = self.btn_force_logout.property("user_fio")
        if not email:
            self._warn("Не удалось определить Email пользователя.")
            return
        if not self._confirm(f"Разлогинить {fio or email}?"):
            return

        if self.repo.force_logout(email=email):
            self._info(f"Пользователь {fio or email} разлогинен.")
            self.btn_force_logout.setEnabled(False)
            self.login_status_lbl.setText("Залогинен: Нет")
            # сбрасываем кэш активностей
            self._active_cache = (0.0, set())
            self.refresh_users()
        else:
            self._warn("Активная сессия не найдена")

# =================== Вспомогательные функции ===================

def get_available_groups(repo: AdminRepo) -> list[str]:
    """Получение списка доступных групп"""
    if GROUP_MAPPING:
        return sorted(set(GROUP_MAPPING.values()))
    return repo.list_groups_from_sheet()

# =================== Entrypoint ===================

def main():
    # Единое логирование для админки
    log_path = setup_logging(app_name="wtt-admin", log_dir=LOG_DIR)
    logger = logging.getLogger(__name__)
    logger.info("Admin app logging initialized (path=%s)", log_path)
    
    # Получение списка групп
    repo = AdminRepo()
    groups = get_available_groups(repo)
    logger.info("Groups: %s", ", ".join(groups) if groups else "<none>")
    
    # Запуск GUI с передачей списка групп
    app = QApplication(sys.argv)
    win = AdminWindow(groups=groups)
    win.show()
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: admin_app\repo.py
# SIZE: 8954 bytes | SHA256(text): 4a8ef84d5b996624f84258294e093fd05e5cc30c7b2ab55b47d86761e409c0ed
--------------------------------------------------------------------------------
# admin_app/repo.py
from __future__ import annotations

import logging
from typing import List, Dict, Optional
from datetime import datetime, timezone

from sheets_api import SheetsAPI, SheetsAPIError
from config import (
    GOOGLE_SHEET_NAME,
    USERS_SHEET,
    ACTIVE_SESSIONS_SHEET,
)

logger = logging.getLogger(__name__)

# Возможные названия листа с графиком (по приоритету)
CANDIDATE_SCHEDULE_TITLES = ["ShiftCalendar", "Schedule", "График"]


class AdminRepo:
    """
    Репозиторий административных операций.
    Все операции идут через централизованный SheetsAPI (ретраи/квоты/логирование).
    """

    def __init__(self, sheets: Optional[SheetsAPI] = None):
        self.sheets = sheets or SheetsAPI()

    # -------------------------------------------------------------------------
    # Users
    # -------------------------------------------------------------------------
    def list_users(self) -> List[Dict[str, str]]:
        """
        Возвращает список пользователей как список словарей (колонки по заголовку листа Users).
        """
        try:
            # Используем высокоуровневый метод SheetsAPI, чтобы не дублировать логику
            users = self.sheets.get_users()  # type: ignore[attr-defined]
            return users or []
        except AttributeError:
            # Фолбэк, если вдруг нет get_users() (старый SheetsAPI)
            ws = self.sheets.get_worksheet(USERS_SHEET)
            values = self.sheets._request_with_retry(ws.get_all_values)
            if not values:
                return []
            header = values[0]
            out: List[Dict[str, str]] = []
            for row in values[1:]:
                if any((c or "").strip() for c in row):
                    out.append({header[i]: (row[i] if i < len(header) else "") for i in range(len(header))})
            return out
        except Exception as e:
            logger.exception("Не удалось получить список пользователей: %s", e)
            return []

    def add_or_update_user(self, user: Dict[str, str]) -> bool:
        """
        Добавляет или обновляет пользователя (по Email).
        """
        try:
            self.sheets.upsert_user(user)  # type: ignore[attr-defined]
            return True
        except AttributeError:
            # Фолбэк на старый интерфейс — пробуем обновить набор полей
            try:
                email = user.get("Email") or user.get("email")
                if not email:
                    raise ValueError("user.Email is required")
                fields = {k: v for k, v in user.items() if k != "Email"}
                self.sheets.update_user_fields(email=email, fields=fields)  # type: ignore[attr-defined]
                return True
            except Exception as e:
                logger.exception("Fallback upsert_user failed: %s", e)
                return False
        except Exception as e:
            logger.exception("add_or_update_user error: %s", e)
            return False

    def delete_user(self, email: str) -> bool:
        """
        Удаляет пользователя по Email.
        """
        try:
            return bool(self.sheets.delete_user(email))  # type: ignore[attr-defined]
        except Exception as e:
            logger.exception("delete_user error for %s: %s", email, e)
            return False

    # -------------------------------------------------------------------------
    # Groups
    # -------------------------------------------------------------------------
    def list_groups_from_sheet(self) -> list[str]:
        """
        Возвращает список доступных групп из листа 'Groups' (колонка 'Group').
        Пустые/дубликаты фильтруются.
        """
        try:
            ws = self.sheets.get_worksheet("Groups")
            values = self.sheets._request_with_retry(ws.get_all_values)
            groups = []
            for row in values[1:]:  # пропускаем заголовок
                if not row:
                    continue
                g = (row[0] or "").strip()
                if g:
                    groups.append(g)
            return sorted(set(groups))
        except Exception as e:
            logger.warning("list_groups_from_sheet failed: %s", e)
            return []

    # -------------------------------------------------------------------------
    # Active sessions
    # -------------------------------------------------------------------------
    def get_active_sessions(self) -> List[Dict]:
        """
        Возвращает все записи листа ActiveSessions (словари колонок).
        """
        try:
            sessions = self.sheets.get_all_active_sessions()  # type: ignore[attr-defined]
            return sessions or []
        except Exception as e:
            logger.exception("get_active_sessions error: %s", e)
            return []

    def force_logout(self, email: str) -> bool:
        """
        Принудительно завершает ПОСЛЕДНЮЮ активную сессию пользователя.
        Возвращает True, если удалось обновить строку.
        """
        try:
            ok = self.sheets.kick_active_session(email=email)  # type: ignore[attr-defined]
            if ok:
                logger.info("Force logout success for %s", email)
            else:
                logger.info("Force logout: активная сессия не найдена для %s", email)
            return bool(ok)
        except Exception as e:
            logger.exception("force_logout error for %s: %s", email, e)
            return False

    # -------------------------------------------------------------------------
    # Schedule (Shift calendar)
    # -------------------------------------------------------------------------
    def _list_titles(self) -> List[str]:
        """
        Возвращает список названий листов книги.
        """
        try:
            if hasattr(self.sheets, "list_worksheet_titles"):
                return list(self.sheets.list_worksheet_titles())  # type: ignore[attr-defined]
        except Exception:
            pass

        # Фолбэк через открытую книгу
        try:
            spreadsheet = self.sheets._request_with_retry(self.sheets.client.open, GOOGLE_SHEET_NAME)
            worksheets = self.sheets._request_with_retry(spreadsheet.worksheets)
            return [ws.title for ws in worksheets]
        except Exception as e:
            logger.warning("Не удалось получить список листов: %s", e)
            return []

    def _pick_schedule_title(self, titles: List[str]) -> Optional[str]:
        """
        Выбирает название листа графика из известных вариантов.
        """
        available = set(titles)
        for cand in CANDIDATE_SCHEDULE_TITLES:
            if cand in available:
                return cand
        return None

    def get_shift_calendar(self) -> List[List[str]]:
        """
        Возвращает таблицу графика как список списков:
        [ [header...], [row1...], ... ]. Если лист отсутствует — [].
        """
        try:
            titles = self._list_titles()
            if not titles:
                logger.info("В книге '%s' не найдено листов.", GOOGLE_SHEET_NAME)
                return []

            name = self._pick_schedule_title(titles)
            if not name:
                logger.info(
                    "Лист графика не найден. Ожидались: %s; есть: %s",
                    ", ".join(CANDIDATE_SCHEDULE_TITLES),
                    ", ".join(titles),
                )
                return []

            ws = self.sheets.get_worksheet(name)
            values = self.sheets._request_with_retry(ws.get_all_values)
            return values or []
        except SheetsAPIError as e:
            logger.warning("Ошибка доступа к листу графика: %s", e)
            return []
        except Exception as e:
            logger.exception("get_shift_calendar error: %s", e)
            return []

--------------------------------------------------------------------------------
# FILE: admin_app\schedule_parser.py
# SIZE: 4599 bytes | SHA256(text): 5f71b0fd877ad4c30a0ff770ef0ca2e0c748c080591488fa53c0ca65c9fb27c6
--------------------------------------------------------------------------------
# admin_app/schedule_parser.py
"""
DEPRECATED: помогает сохранить совместимость, но не должен использоваться в новом коде.
Теперь график читается централизованно через SheetsAPI / AdminRepo.get_shift_calendar().

Если модуль всё ещё импортируется старыми участками кода, функции ниже делегируют чтение
в Google Sheets через SheetsAPI (без pandas/requests и без прямых gspread-вызовов).
"""

from __future__ import annotations
from typing import List, Optional
import logging
from pathlib import Path
import sys

# Добавляем корень проекта в sys.path, чтобы были доступны config и sheets_api при прямом запуске
ROOT_PATH = str(Path(__file__).parent.parent.resolve())
if ROOT_PATH not in sys.path:
    sys.path.insert(0, ROOT_PATH)

from sheets_api import SheetsAPI, SheetsAPIError  # централизованный слой
from config import GOOGLE_SHEET_NAME  # только для сообщений

logger = logging.getLogger(__name__)
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO)

# Возможные названия листа с графиком (приоритет по порядку)
CANDIDATE_SCHEDULE_TITLES = ["ShiftCalendar", "Schedule", "График"]


def _list_titles(sheets: SheetsAPI) -> List[str]:
    """Пытаемся получить список названий листов через SheetsAPI, с фолбэком."""
    try:
        # Новая версия SheetsAPI может иметь list_worksheet_titles()
        if hasattr(sheets, "list_worksheet_titles"):
            return list(sheets.list_worksheet_titles())  # type: ignore
    except Exception:
        pass

    # Фолбэк: напрямую через открытую книгу (всё равно через _request_with_retry)
    try:
        spreadsheet = sheets._request_with_retry(sheets.client.open, GOOGLE_SHEET_NAME)
        worksheets = sheets._request_with_retry(spreadsheet.worksheets)
        return [ws.title for ws in worksheets]
    except Exception as e:
        logger.warning("Не удалось получить список листов: %s", e)
        return []


def _pick_schedule_sheet_title(titles: List[str]) -> Optional[str]:
    """Выбираем первый подходящий лист из известных вариантов."""
    tset = set(titles)
    for cand in CANDIDATE_SCHEDULE_TITLES:
        if cand in tset:
            return cand
    return None


def get_shift_calendar() -> List[List[str]]:
    """
    Возвращает «таблицу графика» как список списков: [ [header...], [row1...], ... ].
    Если лист графика отсутствует — вернёт [].
    В новом коде используйте AdminRepo.get_shift_calendar().
    """
    sheets = SheetsAPI()

    titles = _list_titles(sheets)
    if not titles:
        logger.info("В книге '%s' не найдено ни одного листа.", GOOGLE_SHEET_NAME)
        return []

    sheet_name = _pick_schedule_sheet_title(titles)
    if not sheet_name:
        logger.info(
            "Лист графика не найден. Ожидались один из: %s; есть: %s",
            ", ".join(CANDIDATE_SCHEDULE_TITLES), ", ".join(titles),
        )
        return []

    try:
        ws = sheets.get_worksheet(sheet_name)
        values = sheets._request_with_retry(ws.get_all_values)
        if not values:
            logger.info("Лист '%s' пустой.", sheet_name)
            return []
        return values
    except SheetsAPIError as e:
        logger.warning("Ошибка доступа к листу '%s': %s", sheet_name, e)
        return []
    except Exception as e:
        logger.exception("Не удалось прочитать лист '%s': %s", sheet_name, e)
        return []


# Для обратной совместимости со старым именем
def get_shift_info() -> List[List[str]]:
    """Старое имя функции, оставлено для совместимости."""
    logger.warning("schedule_parser.get_shift_info() устарела — используйте AdminRepo.get_shift_calendar().")
    return get_shift_calendar()

--------------------------------------------------------------------------------
# FILE: archiver.py
# SIZE: 7712 bytes | SHA256(text): bdfd07e45105c2a0c310884e7ac82791d9cabb3eccfefbe7f52395601d450874
--------------------------------------------------------------------------------
# archiver.py (reworked to use centralized SheetsAPI only)
from __future__ import annotations

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import List, Tuple, Optional, Dict
import logging
import argparse

# Ensure project root is importable (so we can import config and sheets_api when run directly)
ROOT_PATH = str(Path(__file__).parent.resolve())
if ROOT_PATH not in sys.path:
    sys.path.insert(0, ROOT_PATH)

from config import GOOGLE_SHEET_NAME, WORKLOG_SHEET, ARCHIVE_SHEET  # type: ignore
from sheets_api import SheetsAPI, SheetsAPIError  # type: ignore

logger = logging.getLogger(__name__)


# ---- helpers ----

TS_HEADER_CANDIDATES = ("timestamp", "Timestamp", "time", "Time", "Дата", "Время", "DateTime", "datetime")

def _parse_ts(s: str) -> Optional[datetime]:
    """
    Parse timestamp in flexible formats. Prefer ISO-8601 with timezone.
    Returns timezone-aware datetime in local timezone for date comparison.
    """
    s = (s or "").strip()
    if not s:
        return None
    fmts = [
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%dT%H:%M:%S.%f%z",
        "%Y-%m-%d %H:%M:%S%z",
        "%Y-%m-%d %H:%M:%S",
        "%d.%m.%Y %H:%M:%S",
        "%d.%m.%Y",
        "%Y-%m-%d",
    ]
    for f in fmts:
        try:
            dt = datetime.strptime(s, f)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt.astimezone()
        except Exception:
            continue
    try:
        dt = datetime.fromisoformat(s)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt.astimezone()
    except Exception:
        return None


def _yesterday_local(base: Optional[datetime] = None) -> datetime.date:
    now_local = (base or datetime.now().astimezone())
    return (now_local.date() - timedelta(days=1))


def _find_timestamp_index(header: List[str]) -> Optional[int]:
    idx_map = { (h or "").strip(): i for i, h in enumerate(header) }
    for key in TS_HEADER_CANDIDATES:
        for h,i in idx_map.items():
            if h.lower() == key.lower():
                return i
    if len(header) >= 6 and header[5].lower().startswith("time"):
        return 5
    return None


def _ensure_archive_sheet(sheets: SheetsAPI, header: List[str]) -> object:
    """
    Get archive worksheet; if missing — create and put header.
    """
    try:
        ws = sheets.get_worksheet(ARCHIVE_SHEET)
        values = sheets._request_with_retry(ws.get_all_values)
        if not values:
            sheets._request_with_retry(ws.update, "A1", [header])
        elif values and values[0] != header:
            pass
        return ws
    except SheetsAPIError:
        from config import GOOGLE_SHEET_NAME  # lazy import
        spreadsheet = sheets._request_with_retry(sheets.client.open, GOOGLE_SHEET_NAME)
        ws = sheets._request_with_retry(spreadsheet.add_worksheet, title=ARCHIVE_SHEET, rows=1, cols=max(1, len(header)))
        sheets._request_with_retry(ws.update, "A1", [header])
        return ws


def _collect_rows_for_date(values: List[List[str]], day: datetime.date) -> Tuple[List[List[str]], List[List[str]], List[str]]:
    """
    Split table rows to (to_archive, to_keep).
    Returns (to_archive_rows, keep_rows, header)
    """
    if not values:
        return [], [], []

    header = values[0]
    body = values[1:]
    ts_idx = _find_timestamp_index(header)
    if ts_idx is None:
        logger.warning("Timestamp column not found in header: %s", header)
        return [], values[1:], header

    to_archive: List[List[str]] = []
    keep_rows: List[List[str]] = []

    for row in body:
        ts_raw = row[ts_idx] if ts_idx < len(row) else ""
        dt = _parse_ts(ts_raw)
        if dt and dt.date() == day:
            to_archive.append(row)
        else:
            keep_rows.append(row)

    return to_archive, keep_rows, header


def _process_sheet(sheets: SheetsAPI, sheet_name: str, day: datetime.date, dry_run: bool = False) -> Tuple[int,int]:
    """
    Process one sheet: move rows for `day` to ARCHIVE_SHEET.
    Returns (archived_count, kept_count)
    """
    try:
        ws = sheets.get_worksheet(sheet_name)
        values = sheets._request_with_retry(ws.get_all_values)
        to_move, keep, header = _collect_rows_for_date(values, day)
        if not header:
            logger.info("[%s] empty or no header — skipping", sheet_name)
            return 0, len(keep)

        archived = len(to_move)
        if archived == 0:
            logger.info("[%s] no rows for %s", sheet_name, day.isoformat())
            return 0, len(keep)

        logger.info("[%s] archiving %d rows for %s", sheet_name, archived, day.isoformat())

        if dry_run:
            return archived, len(keep)

        arch = _ensure_archive_sheet(sheets, header)
        sheets._request_with_retry(arch.append_rows, to_move, value_input_option="USER_ENTERED")

        new_data = [header] + keep if keep else [header]
        sheets._request_with_retry(ws.clear)
        sheets._request_with_retry(ws.update, "A1", new_data)

        return archived, len(keep)
    except Exception as e:
        logger.exception("Failed to process sheet %s: %s", sheet_name, e)
        return 0, 0


def run_archive(target_date: Optional[str] = None, dry_run: bool = False, only_sheet: Optional[str] = None) -> None:
    """
    Archive rows for yesterday (or for specific date YYYY-MM-DD) from WorkLog sheets to Archive.
    - If `only_sheet` is provided, process only that sheet.
    - Otherwise process WORKLOG_SHEET and all 'WorkLog_*' sheets that exist.
    """
    sheets = SheetsAPI()

    if target_date:
        try:
            day = datetime.strptime(target_date, "%Y-%m-%d").date()
        except Exception:
            raise SystemExit("Invalid --date format. Use YYYY-MM-DD")
    else:
        day = _yesterday_local()

    titles: List[str] = []
    try:
        titles = sheets.list_worksheet_titles()
    except Exception:
        pass

    candidates: List[str] = []
    if only_sheet:
        if only_sheet not in titles:
            raise SystemExit(f"Sheet '{only_sheet}' not found in {GOOGLE_SHEET_NAME}")
        candidates = [only_sheet]
    else:
        for t in titles:
            if t == WORKLOG_SHEET or t.startswith(f"{WORKLOG_SHEET}_"):
                candidates.append(t)

    if not candidates:
        logger.warning("No WorkLog-like sheets found. Nothing to do.")
        return

    total_archived = 0
    for name in candidates:
        a, _k = _process_sheet(sheets, name, day, dry_run=dry_run)
        total_archived += a

    if dry_run:
        logger.info("DRY-RUN complete. Would archive %d rows total for %s.", total_archived, day.isoformat())
    else:
        logger.info("Archive complete. Archived %d rows total for %s.", total_archived, day.isoformat())


def main():
    ap = argparse.ArgumentParser(description="Archive yesterday's rows from WorkLog sheets to Archive via SheetsAPI.")
    ap.add_argument("--date", help="Target date YYYY-MM-DD (default: yesterday in local tz)", default=None)
    ap.add_argument("--dry-run", action="store_true", help="Do not modify sheets, just report.")
    ap.add_argument("--only-sheet", help="Process only given sheet name", default=None)
    args = ap.parse_args()
    run_archive(target_date=args.date, dry_run=args.dry_run, only_sheet=args.only_sheet)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: auto_sync.py
# SIZE: 22760 bytes | SHA256(text): ae8962e4c852506b031ec63650b245dbc6fd3c1cb39b170bc47cc10c23553088
--------------------------------------------------------------------------------
import sys
import logging
import time
import signal
from datetime import datetime
from threading import Event, RLock, Thread
from pathlib import Path
from typing import Dict, List, Optional
import socket
from time import monotonic

PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from PyQt5.QtCore import QObject, pyqtSignal
except ImportError:
    logging.warning("PyQt5 не найден. Сигналы GUI не будут работать. Запуск в режиме CLI.")
    class QObject: pass
    class pyqtSignal:
        def __init__(self): pass
        def emit(self, *args, **kwargs): pass

try:
    from config import (
        SYNC_INTERVAL,
        API_MAX_RETRIES,
        SYNC_BATCH_SIZE,
        SYNC_RETRY_STRATEGY,
        SYNC_INTERVAL_ONLINE,
        SYNC_INTERVAL_OFFLINE_RECOVERY
    )
    from user_app.db_local import LocalDB
    from sheets_api import sheets_api
    from sync.network import is_internet_available
except ImportError as e:
    logging.error(f"Ошибка импорта модулей: {e}")
    raise

logger = logging.getLogger(__name__)

PING_PORT = 43333
PING_TIMEOUT = 3600  # 1 час

class SyncSignals(QObject):
    force_logout = pyqtSignal()
    sync_status_updated = pyqtSignal(dict)

class SyncManager(QObject):
    def __init__(self, signals: Optional[SyncSignals] = None, background_mode: bool = True):
        super().__init__()
        logger.info(f"Инициализация SyncManager: background_mode={background_mode}")
        self._db = LocalDB()
        self._db_lock = RLock()
        self._stop_event = Event()
        self.signals = signals
        self._background_mode = background_mode
        self._sync_interval = SYNC_INTERVAL if background_mode else 0
        self._last_sync_time = None
        self._is_offline_recovery = False  # Флаг для режима восстановления
        self._stats = {
            'total_synced': 0,
            'last_sync': None,
            'last_duration': 0,
            'success_rate': 1.0,
            'queue_size': 0
        }
        self._last_ping = time.time()
        self._last_loop_started = monotonic()
        if background_mode:
            self._ping_thread = Thread(target=self._ping_listener, daemon=True)
            self._ping_thread.start()
            logger.debug("Ping listener поток запущен")

    def _check_remote_commands(self):
        logger.info("=== ПРОВЕРКА КОМАНД ===")
        if not is_internet_available():
            logger.debug("Проверка удаленных команд невозможна: нет интернета.")
            return

        with self._db_lock:
            email = self._db.get_current_user_email()
            logger.debug(f"Текущий email пользователя: {email}")
            session = self._db.get_active_session(email) if email else None
            session_id = session["session_id"] if session else None
            logger.debug(f"Активная сессия: session_id={session_id}")

        if not email or not session_id:
            logger.debug("Нет активной сессии для проверки удаленных команд.")
            return

        try:
            logger.info(f"Проверка статуса сессии для пользователя {email}, session_id: {session_id}")
            remote_status = self._check_user_session_status(email, session_id)
            logger.debug(f"Получен удаленный статус: {remote_status}")
            
            if remote_status == "kicked":
                logger.info(f"[ADMIN_LOGOUT] Обнаружен статус 'kicked' для пользователя {email}. Испускаем force_logout.")
                if self.signals:
                    self.signals.force_logout.emit()
                # Отправляем ACK подтверждение команды
                try:
                    sheets_api.ack_remote_command(email=email, session_id=session_id)
                    logger.info(f"ACK отправлен для команды kick пользователя {email}")
                except Exception as ack_error:
                    logger.error(f"Ошибка отправки ACK: {ack_error}")
                return
            elif remote_status == "finished":
                logger.warning(f"Получена команда 'finished' для пользователя {email}. Отправка сигнала в GUI.")
                if self.signals:
                    logger.info("Emit force_logout signal to GUI")
                    self.signals.force_logout.emit()
                # Отправляем ACK подтверждение команды
                try:
                    sheets_api.ack_remote_command(email=email, session_id=session_id)
                    logger.info(f"ACK отправлен для команды finished пользователя {email}")
                except Exception as ack_error:
                    logger.error(f"Ошибка отправки ACK: {ack_error}")
                # НЕ вызываем self.stop() здесь!
            else:
                logger.debug(f"Статус сессии в норме: {remote_status}")
                
        except Exception as e:
            logger.error(f"Ошибка при проверке удаленных команд для {email}: {e}", exc_info=True)

    def _check_user_session_status(self, email: str, session_id: str) -> str:
        """
        Проверяет статус указанной сессии пользователя в Google Sheets.
        Возвращает: 'active', 'kicked', 'finished', 'expired', 'unknown'
        """
        try:
            return sheets_api.check_user_session_status(email, session_id)
        except Exception as e:
            logger.error(f"Ошибка при проверке статуса сессии: {e}")
            return "unknown"

    def _ping_listener(self):
        logger.info(f"Запуск ping listener на UDP порту {PING_PORT}")
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.bind(("127.0.0.1", PING_PORT))
        s.settimeout(2)
        logger.info(f"Ping listener запущен на UDP порту {PING_PORT}")
        while not self._stop_event.is_set():
            try:
                data, addr = s.recvfrom(1024)
                logger.debug(f"Получен UDP пакет от {addr}: {data}")
                if data == b"ping":
                    self._last_ping = time.time()
                    logger.debug("Получен ping, обновлено время последнего ping")
            except socket.timeout:
                continue
            except Exception as e:
                logger.warning(f"Ошибка в ping listener: {e}", exc_info=True)
        s.close()
        logger.info("Ping listener завершен")

    def _prepare_batch(self) -> Optional[Dict[str, List[Dict]]]:
        logger.debug("Подготовка пакета данных для синхронизации")
        with self._db_lock:
            try:
                unsynced = self._db.get_unsynced_actions(SYNC_BATCH_SIZE)
                logger.debug(f"Найдено {len(unsynced)} несинхронизированных действий")
                
                if not unsynced:
                    logger.debug("Нет данных для подготовки пакета")
                    return None
                
                batch = {}
                for action in unsynced:
                    email = action[1]
                    if email not in batch:
                        batch[email] = []
                    batch[email].append({
                        'id': action[0],
                        'email': action[1],
                        'name': action[2],
                        'status': action[3],
                        'action_type': action[4],
                        'comment': action[5],
                        'timestamp': action[6],
                        'session_id': action[7],
                        'status_start_time': action[8],
                        'status_end_time': action[9],
                        'reason': action[10],        # NEW
                        'user_group': action[11],    # NEW
                    })
                
                logger.info(f"Подготовлен пакет для {len(batch)} пользователей, всего действий: {sum(len(actions) for actions in batch.values())}")
                return batch
                
            except Exception as e:
                logger.error(f"Ошибка подготовки пакета: {e}", exc_info=True)
                return None

    def _sync_batch(self, batch: Dict[str, List[Dict]]) -> bool:
        if not batch:
            logger.debug("Пустой пакет, пропускаем синхронизацию")
            return True
            
        start_time = time.time()
        total_actions = sum(len(actions) for actions in batch.values())
        success_count = 0
        synced_ids = []
        
        logger.info(f"Начало синхронизации пакета из {total_actions} действий для {len(batch)} пользователей")
        
        for email, actions in batch.items():
            logger.debug(f"Синхронизация для пользователя {email}: {len(actions)} действий")
            
            for attempt in range(API_MAX_RETRIES):
                try:
                    logger.debug(f"Попытка {attempt + 1}/{API_MAX_RETRIES} для пользователя {email}")
                    
                    if not is_internet_available():
                        logger.warning("Интернет недоступен, пропускаем синхронизацию.")
                        return False
                    
                    # Получаем группу пользователя из листа Users
                    user = sheets_api.get_user_by_email(email)
                    user_group = user.get("group") if user else None
                    
                    # Готовим список словарей для отправки
                    actions_payload = []
                    for a in actions:
                        actions_payload.append({
                            "session_id": a['session_id'],
                            "email": a['email'],
                            "name": a['name'],
                            "status": a['status'],
                            "action_type": a['action_type'],
                            "comment": a['comment'],
                            "timestamp": a['timestamp'],
                            "status_start_time": a['status_start_time'],
                            "status_end_time": a['status_end_time'],
                            "reason": a.get('reason'),
                        })

                    # Используем новую сигнатуру API с передачей user_group
                    if sheets_api.log_user_actions(actions_payload, email, user_group=user_group):
                        success_count += len(actions)
                        synced_ids.extend([a['id'] for a in actions])
                        logger.info(f"Успешно синхронизировано {len(actions)} действий для {email}")
                        break
                    else:
                        logger.warning(f"Не удалось синхронизировать действия для {email}, попытка {attempt + 1}")
                        
                except Exception as e:
                    logger.error(f"Ошибка синхронизации для {email} (попытка {attempt + 1}): {e}", exc_info=True)
                
                if attempt < API_MAX_RETRIES - 1:
                    delay = SYNC_RETRY_STRATEGY[min(attempt, len(SYNC_RETRY_STRATEGY) - 1)]
                    logger.info(f"Повторная попытка через {delay} сек...")
                    time.sleep(delay)
        
        if synced_ids:
            with self._db_lock:
                try:
                    logger.debug(f"Помечаем как синхронизированные {len(synced_ids)} записей")
                    self._db.mark_actions_synced(synced_ids)
                    logger.info(f"Успешно синхронизировано и отмечено {len(synced_ids)} записей.")
                except Exception as e:
                    logger.error(f"Ошибка обновления статуса записей в локальной БД: {e}", exc_info=True)
        
        duration = time.time() - start_time
        logger.info(f"Синхронизация завершена за {duration:.2f} сек. Успешно: {success_count}/{total_actions}")
        
        self._update_stats(success_count, total_actions, duration)
        return success_count == total_actions

    def _update_stats(self, success_count: int, total_actions: int, duration: float):
        logger.debug(f"Обновление статистики: success={success_count}, total={total_actions}, duration={duration:.2f}")
        with self._db_lock:
            self._stats['total_synced'] += success_count
            self._stats['last_sync'] = datetime.now().isoformat(timespec='seconds')
            self._stats['last_duration'] = round(duration, 3)
            if total_actions > 0:
                rate = success_count / total_actions
                self._stats['success_rate'] = 0.9 * self._stats['success_rate'] + 0.1 * rate
            self._stats['queue_size'] = self._db.get_unsynced_count()
            
        logger.debug(f"Обновленная статистика: {self._stats}")
        if self.signals:
            self.signals.sync_status_updated.emit(self._stats.copy())
            logger.debug("Сигнал sync_status_updated отправлен")

    def sync_once(self) -> bool:
        logger.info("=== ЗАПУСК РАЗОВОЙ СИНХРОНИЗАЦИИ ===")
        start = time.time()
        ok = False
        try:
            batch = self._prepare_batch()
            if not batch:
                logger.debug("Нет данных для синхронизации.")
                return True

            total_actions = sum(len(actions) for actions in batch.values())
            logger.info(f"Начало синхронизации пакета из {total_actions} записей.")

            # Если очередь очень большая, активируем режим восстановления
            if total_actions > 100 and not self._is_offline_recovery:
                self._is_offline_recovery = True
                self._sync_interval = SYNC_INTERVAL_OFFLINE_RECOVERY
                logger.info(f"Обнаружено большое количество действий ({total_actions}). Активирован режим восстановления.")

            ok = self._sync_batch(batch)
            logger.info(f"Результат разовой синхронизации: {'УСПЕХ' if ok else 'НЕУДАЧА'}")
        finally:
            elapsed = time.time() - start
            self._stats['last_sync'] = datetime.now().isoformat(timespec='seconds')
            self._stats['last_duration'] = round(elapsed, 3)
            self._stats['queue_size'] = self._db.get_unsynced_count()
            if ok:
                self._stats['total_synced'] += 1
            if self.signals:
                self.signals.sync_status_updated.emit(dict(self._stats))
        return ok

    def run_service(self):
        logger.info(f"Сервис синхронизации запущен. Интервал: {self._sync_interval} сек.")
        cycle_count = 0
        
        while not self._stop_event.is_set():
            cycle_count += 1
            self._last_loop_started = monotonic()
            logger.debug(f"=== ЦИКЛ СИНХРОНИЗАЦИИ #{cycle_count} ===")
            
            now = time.time()
            if (now - self._last_ping) > PING_TIMEOUT:
                logger.warning("Ping не получен более часа — завершаем работу сервиса.")
                break
            
            start_time = time.time()
            try:
                # Проверяем, есть ли интернет
                internet_available = is_internet_available()
                logger.debug(f"Доступность интернета: {internet_available}")
                
                if internet_available:
                    # Если интернет есть, проверяем, в каком режиме мы находимся
                    if self._is_offline_recovery:
                        # Если мы в режиме восстановления, проверяем, сколько записей осталось
                        queue_size = self._db.get_unsynced_count()
                        logger.debug(f"Режим восстановления. Размер очереди: {queue_size}")
                        
                        if queue_size < 50:  # Если осталось меньше 50 записей, считаем, что восстановление завершено
                            self._is_offline_recovery = False
                            self._sync_interval = SYNC_INTERVAL  # Возвращаемся к нормальному интервалу
                            logger.info("Режим восстановления завершен. Возвращаемся к нормальному интервалу синхронизации.")
                        else:
                            self._sync_interval = SYNC_INTERVAL_OFFLINE_RECOVERY
                    else:
                        # Нормальный режим
                        self._sync_interval = SYNC_INTERVAL_ONLINE
                else:
                    # Нет интернета — используем минимальный интервал для быстрого обнаружения его появления
                    self._sync_interval = 10
                    logger.debug("Нет интернета, установлен интервал 10 сек")

                logger.debug(f"Текущий интервал синхронизации: {self._sync_interval} сек")
                
                # Выполняем синхронизацию
                self.sync_once()
                self._check_remote_commands()
                
            except Exception as e:
                logger.critical(f"Критическая ошибка в цикле синхронизации: {e}", exc_info=True)
            
            elapsed = time.time() - start_time
            sleep_time = max(1, self._sync_interval - elapsed)
            logger.debug(f"Цикл завершен за {elapsed:.2f} сек. Ожидание {sleep_time:.2f} сек")
            
            self._stop_event.wait(sleep_time)

        logger.info("Сервис синхронизации завершён.")

    def stop(self):
        logger.info("Остановка SyncManager...")
        self._stop_event.set()
        try:
            self._db.close()
            logger.debug("База данных закрыта")
        except Exception as e:
            logger.error(f"Ошибка при закрытии БД: {e}", exc_info=True)
        logger.info("Сервис синхронизации остановлен.")

def configure_logging(background_mode: bool):
    log_file = 'auto_sync.log' if background_mode else None
    handlers = [logging.StreamHandler()]
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    # Увеличиваем уровень логирования до DEBUG для более детальной информации
    logging.basicConfig(
        level=logging.DEBUG,  # Изменено с INFO на DEBUG
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )
    
    # Для некоторых библиотеки устанавливаем более высокий уровень, чтобы избежать слишком много логов
    logging.getLogger('urllib3').setLevel(logging.INFO)
    logging.getLogger('googleapiclient').setLevel(logging.INFO)

def handle_shutdown(signum, frame):
    logger.info("Получен сигнал завершения работы (SIGTERM/SIGINT)")
    raise SystemExit("Завершение по сигналу.")

def main(background_mode: bool = True):
    configure_logging(background_mode)
    manager = None
    try:
        signal.signal(signal.SIGINT, handle_shutdown)
        signal.signal(signal.SIGTERM, handle_shutdown)

        demo_signals = SyncSignals()
        def on_force_logout():
            logger.info("--- Демонстрация: получен сигнал force_logout! Приложение должно выйти. ---")
        demo_signals.force_logout.connect(on_force_logout)

        manager = SyncManager(signals=demo_signals, background_mode=background_mode)

        if background_mode:
            logger.info("Запуск в режиме сервиса (демо)")
            manager.run_service()
        else:
            logger.info("Выполнение разовой синхронизации (демо)")
            manager.sync_once()
            manager._check_remote_commands()

    except SystemExit as e:
        logger.info(f"Завершение работы: {e}")
    except Exception as e:
        logger.critical(f"Фатальная ошибка в main: {e}", exc_info=True)
    finally:
        if manager:
            manager.stop()

if __name__ == "__main__":
    main(background_mode=True)

--------------------------------------------------------------------------------
# FILE: build_admin.py
# SIZE: 2141 bytes | SHA256(text): 61314b2fa48430cce7746bb0fdb899626af3e0abb44d0cccd4eee315f3035c98
--------------------------------------------------------------------------------
# build_admin.py
import os
import sys
import logging
import shutil
from pathlib import Path
from PyInstaller.__main__ import run

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('build_admin.log', mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info("🚀 Сборка админки...")
        app_name = "WorkTimeTracker_Admin"
        main_script = "admin_app/main_admin.py" # Путь от корня
        icon_file = "user_app/sberhealf.ico" # Используем ту же иконку

        for dir_name in ['dist', 'build']:
            if Path(dir_name).exists():
                shutil.rmtree(dir_name)
                logger.info(f"🧹 Очищена директория: {dir_name}")

        options = [
            main_script,
            f'--name={app_name}',
            '--onedir',
            '--windowed',
            '--clean',
            '--noconfirm',
            '--log-level=WARN',
            f'--icon={icon_file}' if Path(icon_file).exists() else None,
            '--paths=.', # Ключевая строка
            '--add-data=secret_creds.zip;.',
            '--add-data=config.py;.',
            '--add-data=user_app/sberhealf.png;user_app',
            '--hidden-import=auto_sync',
            '--hidden-import=sheets_api',
            '--hidden-import=user_app.db_local',
        ]

        options = [opt for opt in options if opt is not None]

        logger.info(f"⚙️  Запуск: {' '.join(options)}")
        run(options)

        exe_path = Path('dist') / app_name / f"{app_name}.exe"
        if exe_path.exists():
            logger.info(f"✅ Успех! {exe_path}")
        else:
            raise RuntimeError("Сборка прошла, но exe не найден.")

    except Exception as e:
        logger.critical(f"❌ Ошибка: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: build_user.py
# SIZE: 2979 bytes | SHA256(text): 4216f57927b7d0a06a8307c71e8e7ad393eec607de641709d5b8061c3f154ff3
--------------------------------------------------------------------------------
# build_user.py
import os
import sys
import logging
import shutil
from pathlib import Path
from PyInstaller.__main__ import run

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('build_user.log', mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info("🚀 Сборка пользовательской части...")
        app_name = "WorkTimeTracker_User"
        main_script = "user_app/main.py"
        icon_file = "user_app/sberhealf.ico"

        # Очистка
        for dir_name in ['dist', 'build']:
            if Path(dir_name).exists():
                shutil.rmtree(dir_name)
                logger.info(f"🧹 Очищена директория: {dir_name}")

        # Проверка существования файлов
        required_files = [
            'secret_creds.zip',
            'config.py',
            'auto_sync.py',
            'sheets_api.py',
            'user_app',
            'sync'
        ]
        for file in required_files:
            if not Path(file).exists():
                logger.critical(f"❌ КРИТИЧЕСКАЯ ОШИБКА: {file} не найден!")
                sys.exit(1)

        options = [
            main_script,
            f'--name={app_name}',
            '--onedir',
            '--windowed',
            '--clean',
            '--noconfirm',
            '--log-level=WARN',
            f'--icon={icon_file}' if Path(icon_file).exists() else None,
            '--paths=.',
            '--add-data=secret_creds.zip;.',
            '--add-data=config.py;.',
            '--add-data=auto_sync.py;.',
            '--add-data=sheets_api.py;.',
            '--add-data=user_app;user_app',
            '--add-data=sync;sync',
            '--hidden-import=PyQt5.sip',
            '--hidden-import=gspread',
            '--hidden-import=oauth2client',
            '--hidden-import=google.auth',
            '--hidden-import=googleapiclient',
            '--hidden-import=google.oauth2',
            '--hidden-import=googleapiclient.discovery',
            '--hidden-import=httplib2',
            '--hidden-import=OpenSSL',
            '--hidden-import=requests',
        ]

        options = [opt for opt in options if opt is not None]
        logger.info(f"⚙️ Запуск: {' '.join(options)}")
        run(options)

        exe_path = Path('dist') / app_name / f"{app_name}.exe"
        if exe_path.exists():
            logger.info(f"✅ Успех! {exe_path}")
        else:
            raise RuntimeError("Сборка прошла, но exe не найден.")

    except Exception as e:
        logger.critical(f"❌ Ошибка: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: bundle_project.py
# SIZE: 21101 bytes | SHA256(text): b6c1f1599c20041b8ed5c6b641e5fd454d41846711bd7674452a97216ce01493
--------------------------------------------------------------------------------
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
inspect_and_bundle.py — единый инструмент:
  1) Снимок дерева проекта (с исключениями)
  2) TXT-бандл исходников/конфигов
  3) Обзор локальной SQLite (схема, индексы, триггеры, счётчики, примеры)
  4) Обзор Google Sheets (книга, листы, заголовки, количество строк, примеры)

Зависимости:
  - stdlib
  - Ваш проект (config.py, sheets_api.py) — для путей/доступа к Google Sheets.
    sheets_api уже содержит «ленивый» прокси/клиент и ретраи.

Примеры:
  python inspect_and_bundle.py -r . -o project_report.txt
  python inspect_and_bundle.py -r . -o report.txt --db C:/path/to/local_backup.db
  python inspect_and_bundle.py --git-only --no-sheets
"""

from __future__ import annotations

import argparse
import hashlib
import mimetypes
import os
import sqlite3
import sys
import time
from pathlib import Path
from typing import Iterable, List, Dict, Optional, Tuple

# -----------------------------------
# 1) Настройки для дерева и бандла
# -----------------------------------

EXCLUDE_TREE = {'.venv', '__pycache__', '.git', '.idea', 'dist', 'build', '.vscode', '.mypy_cache', '.pytest_cache', '.ruff_cache', 'node_modules', 'target', 'out'}
DEFAULT_EXCLUDE_DIRS = {
    ".git", ".hg", ".svn", ".idea", ".vscode",
    ".venv", "venv", "env",
    "__pycache__", ".mypy_cache", ".pytest_cache", ".ruff_cache",
    "build", "dist", ".cache", ".eggs", ".tox", ".coverage",
    "node_modules", "target", "out"
}

# Текстовые расширения (можно расширить через --include-ext)
DEFAULT_INCLUDE_EXTS = {
    # code
    ".py", ".pyw", ".ipynb",
    ".js", ".jsx", ".ts", ".tsx", ".vue", ".svelte",
    ".java", ".kt", ".kts", ".scala", ".go", ".rb", ".php",
    ".c", ".cc", ".cpp", ".h", ".hpp", ".cs", ".rs", ".swift",
    # web / markup
    ".html", ".htm", ".css", ".scss", ".sass",
    ".xml", ".xsd", ".xslt",
    # config
    ".json", ".jsonc", ".yaml", ".yml", ".ini", ".cfg", ".toml", ".env",
    # scripts
    ".bat", ".cmd", ".ps1", ".psm1", ".sh", ".bash",
    # data-ish (text)
    ".md", ".rst", ".txt", ".csv", ".tsv", ".sql",
    # project files
    ".sln", ".csproj", ".vbproj", ".props", ".targets", ".cmake", "CMakeLists.txt",
    ".gradle", ".pro", ".pri", "Makefile", "Dockerfile", "Procfile",
}
SPECIAL_FILENAMES = {"Makefile", "Dockerfile", "Procfile", "CMakeLists.txt", ".gitignore", ".gitattributes"}

# -----------------------------------
# 2) Вспомогалки
# -----------------------------------

def normalize_extensions_set(exts: Iterable[str]) -> set[str]:
    out = set()
    for e in exts:
        e = (e or "").strip()
        if not e:
            continue
        if not e.startswith(".") and e not in SPECIAL_FILENAMES:
            e = "." + e
        out.add(e)
    return out

def is_binary_by_chunk(p: Path, chunk_size: int = 2048) -> bool:
    try:
        with p.open("rb") as f:
            chunk = f.read(chunk_size)
        if b"\x00" in chunk:
            return True
        text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7f})
        nontext = chunk.translate(None, text_chars)
        return len(nontext) / max(1, len(chunk)) > 0.30
    except Exception:
        return True

def should_include_file(p: Path, include_exts: set[str]) -> bool:
    name = p.name
    if name in SPECIAL_FILENAMES:
        return True
    ext = p.suffix
    if ext in include_exts:
        return True
    mtype, _ = mimetypes.guess_type(str(p))
    if mtype and mtype.startswith("text/"):
        return True
    return False

def sha256_of_text(s: str) -> str:
    import hashlib as _h
    return _h.sha256(s.encode("utf-8", errors="replace")).hexdigest()

def read_text_best_effort(p: Path) -> str:
    for enc in ("utf-8", "utf-8-sig", "cp1251", "latin-1"):
        try:
            return p.read_text(encoding=enc)
        except Exception:
            continue
    try:
        return p.read_bytes().decode("latin-1", errors="replace")
    except Exception:
        return ""

# -----------------------------------
# 3) Дерево проекта (в строку)
# -----------------------------------

def render_tree(dir_path: Path, prefix: str = "", exclude: set[str] = None) -> str:
    exclude = exclude or set()
    lines: List[str] = []
    try:
        entries = [e for e in os.listdir(dir_path) if e not in exclude]
    except Exception as e:
        return f"[tree] Ошибка доступа к {dir_path}: {e}\n"
    entries.sort()
    for i, name in enumerate(entries):
        path = dir_path / name
        connector = "└── " if i == len(entries) - 1 else "├── "
        lines.append(prefix + connector + name)
        if path.is_dir():
            extension = "    " if i == len(entries) - 1 else "│   "
            lines.append(render_tree(path, prefix + extension, exclude))
    return "\n".join(lines)

# -----------------------------------
# 4) Сбор файлов проекта в TXT
# -----------------------------------

def collect_files(root: Path, include_exts: set[str], exclude_dirs: set[str], max_bytes: int) -> List[Path]:
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        dp = Path(dirpath)
        for fname in filenames:
            p = dp / fname
            try:
                if not p.is_file():
                    continue
                if p.stat().st_size > max_bytes:
                    continue
                if not should_include_file(p, include_exts):
                    continue
                if is_binary_by_chunk(p):
                    continue
                files.append(p)
            except Exception:
                continue
    files.sort(key=lambda x: str(x).lower())
    return files

def write_bundle(out, root: Path, files: List[Path]) -> None:
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    header = [
        "=" * 80,
        f"PROJECT REPORT",
        f"Generated:   {ts}",
        f"Root:        {root}",
        f"Python:      {sys.version.split()[0]}",
        f"Files:       {len(files)}",
        "=" * 80,
        ""
    ]
    out.write("\n".join(header) + "\n")
    for p in files:
        try:
            rel = p.relative_to(root)
        except Exception:
            rel = p
        try:
            text = read_text_best_effort(p)
            size = p.stat().st_size
            h = sha256_of_text(text)
            out.write("\n" + "-" * 80 + "\n")
            out.write(f"# FILE: {rel}\n")
            out.write(f"# SIZE: {size} bytes | SHA256(text): {h}\n")
            out.write("-" * 80 + "\n")
            out.write(text)
            if not text.endswith("\n"):
                out.write("\n")
        except Exception as e:
            out.write("\n" + "-" * 80 + "\n")
            out.write(f"# FILE: {rel}\n")
            out.write(f"# ERROR: {e}\n")
            out.write("-" * 80 + "\n\n")

# -----------------------------------
# 5) Инспекция SQLite
# -----------------------------------

def _sql_fetchall_safe(cur: sqlite3.Cursor, sql: str, params: Tuple = ()) -> List[Tuple]:
    try:
        cur.execute(sql, params)
        return cur.fetchall()
    except Exception:
        return []

def introspect_sqlite(db_path: Path, sample_limit: int = 5) -> str:
    out: List[str] = []
    out.append("=" * 80)
    out.append("LOCAL SQLITE OVERVIEW")
    out.append(f"DB Path: {db_path}")
    out.append("=" * 80)

    if not db_path.exists():
        out.append(f"[warn] Файл БД не найден: {db_path}")
        return "\n".join(out) + "\n"

    try:
        conn = sqlite3.connect(str(db_path))
        cur = conn.cursor()

        # Базовая инфо
        db_list = _sql_fetchall_safe(cur, "PRAGMA database_list;")
        out.append(f"database_list: {db_list}")

        # Таблицы (кроме служебных)
        tables = _sql_fetchall_safe(
            cur, "SELECT name, sql FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name;"
        )
        for name, create_sql in tables:
            out.append("-" * 80)
            out.append(f"[TABLE] {name}")
            out.append(f"schema: {create_sql}")

            # Колонки
            cols = _sql_fetchall_safe(cur, f"PRAGMA table_info({name});")
            if cols:
                out.append("columns:")
                for cid, cname, ctype, notnull, dflt, pk in cols:
                    out.append(f"  - {cname} {ctype or ''} NOTNULL={notnull} PK={pk} DEFAULT={dflt}")

            # Индексы
            idxs = _sql_fetchall_safe(cur, f"PRAGMA index_list({name});")
            if idxs:
                out.append("indexes:")
                for idx in idxs:
                    iname = idx[1]
                    unique = idx[2]
                    out.append(f"  - {iname} UNIQUE={unique}")
                    idxcols = _sql_fetchall_safe(cur, f"PRAGMA index_info({iname});")
                    for _, seqno, cname in idxcols:
                        out.append(f"      * {seqno}: {cname}")

            # Триггеры по таблице
            trigs = _sql_fetchall_safe(
                cur, "SELECT name, sql FROM sqlite_master WHERE type='trigger' AND tbl_name=? ORDER BY name;", (name,)
            )
            if trigs:
                out.append("triggers:")
                for tname, tsql in trigs:
                    out.append(f"  - {tname}: {tsql}")

            # Счётчик строк
            cnt = _sql_fetchall_safe(cur, f"SELECT COUNT(*) FROM {name};")
            if cnt:
                out.append(f"rows_count: {cnt[0][0]}")

            # Примеры строк
            samples = _sql_fetchall_safe(cur, f"SELECT * FROM {name} ORDER BY ROWID DESC LIMIT {int(sample_limit)};")
            if samples:
                out.append("sample rows (last):")
                for row in samples:
                    out.append(f"  • {row}")

        # Глобальные триггеры
        gtrigs = _sql_fetchall_safe(cur, "SELECT name, tbl_name, sql FROM sqlite_master WHERE type='trigger' ORDER BY name;")
        if gtrigs:
            out.append("-" * 80)
            out.append("[TRIGGERS GLOBAL]")
            for name, tbl, sql in gtrigs:
                out.append(f"  - {name} on {tbl}: {sql}")

        conn.close()
    except Exception as e:
        out.append(f"[error] Ошибка открытия/чтения SQLite: {e}")

    out.append("")
    return "\n".join(out)

# -----------------------------------
# 6) Инспекция Google Sheets
# -----------------------------------

def introspect_gsheets(sample_limit: int = 3) -> str:
    """
    Пытается импортировать ваш sheets_api и построить обзор книги:
      - Название книги из config
      - Список листов
      - Заголовок каждой таблицы
      - Кол-во непустых строк (по get_all_values)
      - Первые sample_limit строк
    """
    out: List[str] = []
    out.append("=" * 80)
    out.append("GOOGLE SHEETS OVERVIEW")
    out.append("=" * 80)

    try:
        # Импортируем ленивый прокси/клиент из вашего проекта
        # В проекте есть методы list_worksheet_titles(), get_users(), get_all_active_sessions() и т.п. :contentReference[oaicite:2]{index=2}
        import importlib

        try:
            sheets_mod = importlib.import_module("sheets_api")
        except Exception as e:
            out.append(f"[warn] Не удалось импортировать sheets_api: {e}")
            return "\n".join(out) + "\n"

        # Возьмём реальный инстанс
        if hasattr(sheets_mod, "get_sheets_api"):
            sheets = sheets_mod.get_sheets_api()
        elif hasattr(sheets_mod, "SheetsAPI"):
            sheets = sheets_mod.SheetsAPI()
        else:
            out.append("[warn] sheets_api не содержит SheetsAPI/get_sheets_api")
            return "\n".join(out) + "\n"

        # Заголовок и листы
        try:
            from config import GOOGLE_SHEET_NAME  # имя книги хранится в конфиге :contentReference[oaicite:3]{index=3}
        except Exception:
            GOOGLE_SHEET_NAME = "(см. config)"

        out.append(f"Spreadsheet: {GOOGLE_SHEET_NAME}")

        titles: List[str] = []
        try:
            titles = list(sheets.list_worksheet_titles())
        except Exception as e:
            out.append(f"[warn] list_worksheet_titles error: {e}")

        if not titles:
            out.append("[warn] Листы не найдены или нет доступа.")
            return "\n".join(out) + "\n"

        for t in titles:
            out.append("-" * 80)
            out.append(f"[SHEET] {t}")

            try:
                ws = sheets._get_ws(t)  # внутренний helper у вас есть
            except Exception:
                # fallback: через клиент
                try:
                    ss = sheets.client.open(GOOGLE_SHEET_NAME)
                    ws = ss.worksheet(t)
                except Exception as e:
                    out.append(f"  [warn] Не удалось открыть лист '{t}': {e}")
                    continue

            # Заголовок
            try:
                header = sheets._request_with_retry(lambda: ws.row_values(1))
                out.append(f"header: {header}")
            except Exception as e:
                out.append(f"  [warn] header read error: {e}")
                header = []

            # Все значения, чтобы посчитать заполненные строки (без пустых хвостов)
            values: List[List[str]] = []
            try:
                values = sheets._request_with_retry(lambda: ws.get_all_values())
            except Exception as e:
                out.append(f"  [warn] get_all_values error: {e}")

            if values:
                # Непустые строки (грубая оценка)
                nonempty = [r for r in values[1:] if any((c or "").strip() for c in r)]
                out.append(f"rows_count (non-empty): {len(nonempty)}")
                # Примеры первых N
                if nonempty:
                    out.append(f"sample rows (first {sample_limit}):")
                    for row in nonempty[:sample_limit]:
                        out.append("  • " + str(row))

    except Exception as e:
        out.append(f"[error] Ошибка обзора Google Sheets: {e}")

    out.append("")
    return "\n".join(out)

# -----------------------------------
# 7) Главная функция/CLI
# -----------------------------------

def main():
    ap = argparse.ArgumentParser(description="Собрать отчёт по проекту (дерево, бандл, SQLite, Google Sheets).")
    ap.add_argument("-r", "--root", type=str, default=".", help="Корень проекта (default .)")
    ap.add_argument("-o", "--output", type=str, default="project_report.txt", help="Путь к выходному TXT.")
    ap.add_argument("--max-bytes", type=int, default=3_000_000, help="Макс. размер одного файла (байт).")
    ap.add_argument("--include-ext", type=str, nargs="*", default=None, help="Доп. расширения (py toml conf ...)")
    ap.add_argument("--exclude-dir", type=str, nargs="*", default=None, help="Доп. каталоги для исключения (имена).")
    ap.add_argument("--git-only", action="store_true", help="Собирает только файлы, отслеживаемые Git.")
    ap.add_argument("--no-tree", action="store_true", help="Не добавлять дерево проекта.")
    ap.add_argument("--no-db", action="store_true", help="Не добавлять обзор SQLite.")
    ap.add_argument("--no-sheets", action="store_true", help="Не добавлять обзор Google Sheets.")
    ap.add_argument("--db", type=str, default=None, help="Путь к SQLite (иначе возьмём из config.LOCAL_DB_PATH).")
    ap.add_argument("--db-sample", type=int, default=5, help="Количество строк-примеров из таблиц SQLite.")
    ap.add_argument("--sheets-sample", type=int, default=3, help="Количество строк-примеров из листов Google Sheets.")

    args = ap.parse_args()

    root = Path(args.root).resolve()
    out_path = Path(args.output).resolve()
    out_path.parent.mkdir(parents=True, exist_ok=True)

    include_exts = set(DEFAULT_INCLUDE_EXTS)
    if args.include_ext:
        include_exts |= normalize_extensions_set(set(args.include_ext))

    exclude_dirs = set(DEFAULT_EXCLUDE_DIRS)
    if args.exclude_dir:
        exclude_dirs |= set(args.exclude_dir)

    # --- Подготовим список файлов ---
    if args.git_only:
        try:
            import subprocess
            res = subprocess.run(
                ["git", "ls-files"],
                check=True,
                cwd=str(root),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding="utf-8",
            )
            files = []
            tracked = [root / line.strip() for line in res.stdout.splitlines() if line.strip()]
            for p in tracked:
                try:
                    if not p.exists() or not p.is_file():
                        continue
                    if p.stat().st_size > args.max_bytes:
                        continue
                    if not should_include_file(p, include_exts):
                        continue
                    if is_binary_by_chunk(p):
                        continue
                    files.append(p)
                except Exception:
                    continue
            files.sort(key=lambda x: str(x).lower())
        except Exception as e:
            print(f"[WARN] git-only режим не удался: {e}. Переход к файловому обходу.", file=sys.stderr)
            files = collect_files(root, include_exts, exclude_dirs, args.max_bytes)
    else:
        files = collect_files(root, include_exts, exclude_dirs, args.max_bytes)

    # --- Путь к локальной БД ---
    db_path: Optional[Path] = None
    if not args.no_db:
        if args.db:
            db_path = Path(args.db)
        else:
            # Попробуем достать из config.LOCAL_DB_PATH (у вас так и сделано в проекте) :contentReference[oaicite:4]{index=4}
            try:
                import importlib
                cfg = importlib.import_module("config")
                db_path = Path(getattr(cfg, "LOCAL_DB_PATH"))
            except Exception:
                # Фолбэк — ищем *.db рядом
                candidates = list(root.glob("**/*.db"))
                db_path = candidates[0] if candidates else None

    # --- Запись отчёта ---
    with out_path.open("w", encoding="utf-8", newline="\n") as out:
        # Шапка + TREE
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        out.write("=" * 80 + "\n")
        out.write("PROJECT SNAPSHOT\n")
        out.write(f"Generated:   {ts}\n")
        out.write(f"Root:        {root}\n")
        out.write(f"Python:      {sys.version.split()[0]}\n")
        out.write("=" * 80 + "\n\n")

        if not args.no_tree:
            out.write("=" * 80 + "\n")
            out.write("PROJECT TREE\n")
            out.write("=" * 80 + "\n")
            out.write(render_tree(root, exclude=EXCLUDE_TREE))
            out.write("\n\n")

        # DB overview
        if not args.no_db and db_path:
            out.write(introspect_sqlite(db_path, sample_limit=args.db_sample))

        # Sheets overview
        if not args.no_sheets:
            out.write(introspect_gsheets(sample_limit=args.sheets_sample))

        # Бандл исходников
        write_bundle(out, root, files)

    print(f"✓ Готово: {out_path}")

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: config.py
# SIZE: 13794 bytes | SHA256(text): 2c1974d45eb66463e295ed01cce1a7b722213ca30c9967b4f06f69f00f148742
--------------------------------------------------------------------------------
# config.py
import os
import sys
import platform
from pathlib import Path
from typing import Dict, List, Set, Optional
from contextlib import contextmanager
import atexit

# ==================== Загрузка переменных окружения из .env ====================
from dotenv import load_dotenv
load_dotenv()

# ==================== Импорт для работы с зашифрованным credentials ====================
import pyzipper
import tempfile

# ==================== Базовые настройки ====================
if getattr(sys, 'frozen', False):
    # Режим сборки (PyInstaller)
    BASE_DIR = Path(sys.executable).parent
else:
    # Режим разработки
    BASE_DIR = Path(__file__).parent.absolute()

# --- Исправлено: Создаем LOG_DIR сразу ---
if platform.system() == "Windows":
    LOG_DIR = Path(os.getenv('APPDATA')) / "WorkTimeTracker" / "logs"
else:
    LOG_DIR = Path.home() / ".local" / "share" / "WorkTimeTracker" / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True) # Создаем при импорте модуля
# ---

# ==================== Пути к файлам ====================
# Настройки для зашифрованного архива с credentials
CREDENTIALS_ZIP = BASE_DIR / 'secret_creds.zip'  # архив должен лежать рядом с exe

# Пароль берётся из переменной окружения
CREDENTIALS_ZIP_PASSWORD = os.getenv("CREDENTIALS_ZIP_PASSWORD")
if CREDENTIALS_ZIP_PASSWORD is None:
    raise RuntimeError("CREDENTIALS_ZIP_PASSWORD не найден в .env файле!")
CREDENTIALS_ZIP_PASSWORD = CREDENTIALS_ZIP_PASSWORD.encode('utf-8')

# --- Ленивая загрузка credentials ---
_CREDS_TMP_DIR = Path(tempfile.gettempdir()) / "wtt_creds"
_CREDS_TMP_DIR.mkdir(parents=True, exist_ok=True)
_CREDENTIALS_FILE: Optional[Path] = None

def _cleanup_credentials():
    """Удаляет временный файл с учетными данными при выходе из процесса."""
    try:
        if _CREDENTIALS_FILE and _CREDENTIALS_FILE.exists():
            _CREDENTIALS_FILE.unlink()
    except Exception:
        pass

# Регистрируем очистку при выходе
atexit.register(_cleanup_credentials)

@contextmanager
def credentials_path() -> Path:
    """
    Лениво и временно извлекает service_account.json из зашифрованного ZIP.
    Используйте: with credentials_path() as p: ...
    """
    global _CREDENTIALS_FILE
    
    # Если файл уже извлечен и существует, используем его
    if _CREDENTIALS_FILE and _CREDENTIALS_FILE.exists():
        yield _CREDENTIALS_FILE
        return
    
    # Проверяем существование ZIP-архива
    if not CREDENTIALS_ZIP.exists():
        raise FileNotFoundError(f"Zip с credentials не найден: {CREDENTIALS_ZIP}")
    
    # Извлекаем файл из зашифрованного архива
    with pyzipper.AESZipFile(CREDENTIALS_ZIP) as zf:
        zf.pwd = CREDENTIALS_ZIP_PASSWORD
        try:
            data = zf.read('service_account.json')
        except KeyError:
            raise FileNotFoundError("Файл 'service_account.json' не найден в архиве")
        
        # Сохраняем во временный файл
        temp_file = _CREDS_TMP_DIR / 'service_account.json'
        with open(temp_file, 'wb') as f:
            f.write(data)
        
        _CREDENTIALS_FILE = temp_file
        yield _CREDENTIALS_FILE

def get_credentials_file() -> Path:
    """Обратная совместимость: получить путь к JSON (извлечёт при первом вызове)."""
    with credentials_path() as p:
        return Path(p)

LOCAL_DB_PATH = BASE_DIR / 'local_backup.db'
ERROR_LOG_FILE = LOG_DIR / 'error.log'
SYNC_LOG_FILE = LOG_DIR / 'sync.log'  # Добавлен лог для синхронизации

# ==================== Настройки Google Sheets ====================
GOOGLE_SHEET_NAME = "WorkLog"
USERS_SHEET = "Users"
WORKLOG_SHEET = "WorkLog"
ARCHIVE_SHEET = "Archive"
ACTIVE_SESSIONS_SHEET = "ActiveSessions"
SHIFT_CALENDAR_SHEET = ""  # опционально: 'ShiftCalendar' / 'График' если появится лист графика

# ==================== Лимиты API ====================
GOOGLE_API_LIMITS: Dict[str, int] = {
    'max_requests_per_minute': 60,
    'max_rows_per_request': 50,
    'max_cells_per_request': 10000,
    'daily_limit': 100000
}

# ==================== Настройки синхронизации ====================
SYNC_INTERVAL: int = 100
SYNC_BATCH_SIZE: int = 35
API_MAX_RETRIES: int = 5  # Увеличено количество ретраев
API_DELAY_SECONDS: float = 1.5  # Увеличен базовый интервал
SYNC_RETRY_STRATEGY: List[int] = [60, 300, 900, 1800, 3600]  # 1, 5, 15, 30, 60 минут - увеличенная стратегия

# Интервалы синхронизации для разных режимов работы
SYNC_INTERVAL_ONLINE: int = 60  # 60 секунд при нормальной работе
SYNC_INTERVAL_OFFLINE_RECOVERY: int = 300  # 300 секунд (5 минут) при восстановлении после оффлайна

# ==================== Группы обработки ====================
GROUP_MAPPING: Dict[str, str] = {
    "call": "Входящие",
    "appointment": "Запись",
    "mail": "Почта",
    "dental": "Стоматология",
    "default": "Входящие"
}

# ==================== Статусы системы ====================
STATUSES: List[str] = [
    "В работе",
    "Чат",
    "Аудио",
    "Запись",
    "Анкеты",
    "Перерыв",
    "Обед",
    "ЦИТО",
    "Обучение"
]

# Группы для интерфейса (раскладка кнопок)
STATUS_GROUPS: List[List[str]] = [
    ["В работе", "Чат", "Аудио", "Запись", "Анкеты"],   # Основная работа
    ["Перерыв", "Обед"],                                # Перерывы
    ["ЦИТО", "Обучение"]                                # Специальные
]

CONFIRMATION_STATUSES: Set[str] = {"Перерыв", "Обед", "ЦИТО"}
RESTRICTED_STATUSES_FIRST_2H: Set[str] = {"Перерыв", "Обед"}
MAX_COMMENT_LENGTH: int = 500
MAX_HISTORY_DAYS: int = 30

# ==================== Настройки безопасности ====================
PASSWORD_MIN_LENGTH: int = 8
SESSION_TIMEOUT: int = 3600  # секунды
ALLOWED_DOMAINS: List[str] = ["company.com", "sberhealth.ru"]

# ==================== Telegram уведомления ====================
TELEGRAM_BOT_TOKEN: str | None = os.getenv("8318266102:AAESpe4TIQpkTEAFuFD_ECZKWBkc5Tk32LU") or None
# Личный чат админа:
TELEGRAM_ADMIN_CHAT_ID: str | None = os.getenv("1053909260") or None
# Общий канал для групповых объявлений (может быть отрицательный id):
TELEGRAM_BROADCAST_CHAT_ID: str | None = os.getenv("TELEGRAM_BROADCAST_CHAT_ID") or None
# Анти-спам ключей (минут между одинаковыми событиями)
TELEGRAM_MIN_INTERVAL_SEC: int = int(os.getenv("TELEGRAM_MIN_INTERVAL_SEC", "600"))
# Тихие уведомления по умолчанию
TELEGRAM_SILENT: bool = os.getenv("TELEGRAM_SILENT", "0") == "1"
TELEGRAM_ALERTS_ENABLED: bool = bool(TELEGRAM_BOT_TOKEN and (TELEGRAM_ADMIN_CHAT_ID or TELEGRAM_BROADCAST_CHAT_ID))

# ==================== Архивирование ====================
ARCHIVE_DELETE_SOURCE_ROWS: bool = os.getenv("ARCHIVE_DELETE_SOURCE_ROWS", "1") == "1"

# ==================== Пороги правил уведомлений ====================
# опоздание на логин, минут
LATE_LOGIN_MINUTES: int = int(os.getenv("LATE_LOGIN_MINUTES", "15"))
# слишком частая смена статусов, штук за час
OVER_STATUS_MAX_PER_HOUR: int = int(os.getenv("OVER_STATUS_MAX_PER_HOUR", "10"))
# порог очереди несинхрона
NOTIFY_QUEUE_THRESHOLD: int = int(os.getenv("NOTIFY_QUEUE_THRESHOLD", "50"))

# ==================== Настройки мониторинга и логирования ====================
LOG_LEVEL: str = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_ROTATION_SIZE: int = 10 * 1024 * 1024  # 10MB
LOG_BACKUP_COUNT: int = 5  # Количество резервных копий логов

# ==================== Валидация конфигурации ====================
def validate_config() -> None:
    """Проверяет корректность конфигурации при запуске."""
    errors = []
    
    # Ленивая проверка учетных данных
    try:
        with credentials_path() as creds_file:
            if not creds_file.exists():
                errors.append(f"Файл учетных данных не найден: {creds_file}")
    except Exception as e:
        errors.append(f"Ошибка доступа к учетным данным: {e}")
    
    if not LOG_DIR.exists():
        try:
            LOG_DIR.mkdir(parents=True)
        except Exception as e:
            errors.append(f"Не удалось создать директорию логов: {e}")
    
    if not GROUP_MAPPING.get("default"):
        errors.append("Не определена группы по умолчанию в GROUP_MAPPING")
    
    # Проверяем наличие критически важных файлов
    if not CREDENTIALS_ZIP.exists():
        errors.append(f"Файл secret_creds.zip не найден: {CREDENTIALS_ZIP}")
    
    # Проверяем стратегию ретраев
    if len(SYNC_RETRY_STRATEGY) < 3:
        errors.append("Стратегия повторных попыток синхронизации должна содержать минимум 3 интервала")
    
    if max(SYNC_RETRY_STRATEGY) < 1800:
        errors.append("Максимальный интервал повторных попыток должен быть не менее 1800 секунд (30 минут)")
    
    if errors:
        raise ValueError("Ошибки конфигурации:\n- " + "\n- ".join(errors))

# ==================== Утилиты для работы с конфигурации ====================
def get_sync_retry_delay(attempt: int) -> int:
    """
    Возвращает задержку для повторной попытки синхронизации.
    
    Args:
        attempt: Номер попытки (начиная с 0)
    
    Returns:
        Задержка в секундах
    """
    if attempt < len(SYNC_RETRY_STRATEGY):
        return SYNC_RETRY_STRATEGY[attempt]
    return SYNC_RETRY_STRATEGY[-1]  # Последний интервал для всех последующих попыток

def should_retry_sync(error: Exception) -> bool:
    """
    Определяет, следует ли повторять попытку синхронизации при данной ошибке.
    
    Args:
        error: Исключение, которое произошло
        
    Returns:
        True если следует повторить, False если нет
    """
    # Ошибки, при которых стоит повторять попытку
    retryable_errors = [
        "ConnectionError",
        "TimeoutError",
        "HttpError",
        "ServiceUnavailable",
        "RateLimitExceeded"
    ]
    
    error_name = type(error).__name__
    return any(retryable in error_name for retryable in retryable_errors)

# ==================== Инициализация конфигурации ====================
try:
    validate_config()
    print("✓ Конфигурация успешно проверена")
    print(f"✓ Стратегия повторных попыток: {SYNC_RETRY_STRATEGY}")
except Exception as e:
    print(f"✗ Ошибка конфигурации: {e}")
    raise

# ==================== Утилиты для PyInstaller ====================
def get_resource_path(relative_path: str) -> str:
    """Возвращает абсолютный путь к ресурсу, учитывая PyInstaller."""
    if hasattr(sys, '_MEIPASS'):
        base_path = Path(sys._MEIPASS)
    else:
        base_path = BASE_DIR
    return str(base_path / relative_path)

# ==================== Константы для тестирования ====================
if __name__ == "__main__":
    print(f"BASE_DIR: {BASE_DIR}")
    print(f"LOG_DIR: {LOG_DIR}")
    print(f"CREDENTIALS_ZIP: {CREDENTIALS_ZIP}")
    print(f"SYNC_RETRY_STRATEGY: {SYNC_RETRY_STRATEGY}")
    print(f"Максимальная задержка: {max(SYNC_RETRY_STRATEGY)} секунд ({max(SYNC_RETRY_STRATEGY)/60} минут)")
    
    # Тестируем ленивую загрузку credentials
    try:
        with credentials_path() as creds:
            print(f"✓ Credentials file: {creds}")
            print(f"✓ File exists: {creds.exists()}")
    except Exception as e:
        print(f"✗ Error accessing credentials: {e}")

--------------------------------------------------------------------------------
# FILE: diagnostics_report.json
# SIZE: 10268 bytes | SHA256(text): 24d3d43f0e8dcf768c19369a3df6144f027ebd4d14aa43e3310cb20bda4f8f25
--------------------------------------------------------------------------------
{
  "ts": "2025-09-02T17:13:19",
  "log_dir": "C:\\Users\\Сергей\\AppData\\Roaming\\WorkTimeTracker\\logs",
  "credentials_file": "C:\\Temp\\wtt_creds\\service_account.json",
  "sqlite": {
    "objects": [
      {
        "name": "app_logs",
        "type": "table",
        "sql": "CREATE TABLE app_logs (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                level TEXT NOT NULL,\n                message TEXT NOT NULL\n            )"
      },
      {
        "name": "app_logs_legacy_20250826175446",
        "type": "table",
        "sql": "CREATE TABLE \"app_logs_legacy_20250826175446\" (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                level TEXT NOT NULL,\n                message TEXT NOT NULL\n            )"
      },
      {
        "name": "check_comment_length",
        "type": "trigger",
        "sql": "CREATE TRIGGER check_comment_length\n            BEFORE INSERT ON logs\n            FOR EACH ROW\n            WHEN length(NEW.comment) > 500\n            BEGIN\n                SELECT RAISE(ABORT, 'Comment too long');\n            END"
      },
      {
        "name": "idx_app_logs_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_app_logs_ts ON app_logs(ts)"
      },
      {
        "name": "idx_logs_email",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_email ON logs(email)"
      },
      {
        "name": "idx_logs_session",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_session ON logs(session_id)"
      },
      {
        "name": "idx_logs_synced",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_synced ON logs(synced)"
      },
      {
        "name": "idx_logs_timestamp",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_timestamp ON logs(timestamp)"
      },
      {
        "name": "idx_logs_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_ts ON \"app_logs_legacy_20250826175446\"(ts)"
      },
      {
        "name": "idx_offline_actions_status_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_offline_actions_status_ts ON offline_actions(status, ts)"
      },
      {
        "name": "logs",
        "type": "table",
        "sql": "CREATE TABLE logs (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                session_id TEXT NOT NULL,\n                email TEXT NOT NULL,\n                name TEXT NOT NULL,\n                status TEXT,\n                action_type TEXT NOT NULL,\n                comment TEXT,\n                timestamp TEXT NOT NULL,\n                synced INTEGER DEFAULT 0,\n                sync_attempts INTEGER DEFAULT 0,\n                last_sync_attempt TEXT,\n                priority INTEGER DEFAULT 1,\n                status_start_time TEXT,\n                status_end_time TEXT,\n                reason TEXT,\n                user_group TEXT\n            )"
      },
      {
        "name": "offline_actions",
        "type": "table",
        "sql": "CREATE TABLE offline_actions (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                action_type TEXT NOT NULL,\n                payload TEXT NOT NULL,  -- JSON-строка\n                status TEXT NOT NULL DEFAULT 'pending'  -- pending|synced|failed\n            )"
      },
      {
        "name": "prevent_duplicate_logout",
        "type": "trigger",
        "sql": "CREATE TRIGGER prevent_duplicate_logout\n            BEFORE INSERT ON logs\n            FOR EACH ROW\n            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (\n                SELECT 1 FROM logs\n                WHERE session_id = NEW.session_id\n                  AND LOWER(action_type) = 'logout'\n                  AND timestamp > datetime('now', '-5 minutes')\n            )\n            BEGIN\n                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');\n            END"
      },
      {
        "name": "sqlite_sequence",
        "type": "table",
        "sql": "CREATE TABLE sqlite_sequence(name,seq)"
      }
    ],
    "stats": {
      "app_logs": 0,
      "app_logs_legacy_20250826175446": 0,
      "logs": 26,
      "offline_actions": 0
    },
    "samples": {
      "app_logs": [],
      "app_logs_legacy_20250826175446": [],
      "logs": [
        [
          26,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Завершено",
          "LOGOUT",
          "Завершение смены (нормальное)",
          "2025-09-02T07:31:20.622314+00:00",
          0,
          0,
          null,
          1,
          "2025-09-02T10:31:20.622249",
          "2025-09-02T10:31:20.622249",
          "user",
          "Стоматология"
        ],
        [
          25,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Аудио",
          "STATUS_CHANGE",
          null,
          "2025-09-02T07:30:03.200596+00:00",
          1,
          1,
          "2025-09-02T07:30:05.016279+00:00",
          1,
          "2025-09-02T10:30:03.197439",
          "2025-09-02T07:31:20.619894+00:00",
          null,
          null
        ],
        [
          24,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Чат",
          "STATUS_CHANGE",
          null,
          "2025-09-02T07:29:57.160421+00:00",
          1,
          2,
          "2025-09-02T07:30:03.496395+00:00",
          1,
          "2025-09-02T10:29:57.156445",
          "2025-09-02T10:30:03.197439",
          null,
          null
        ],
        [
          23,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-09-02T07:25:58.866299+00:00",
          1,
          2,
          "2025-09-02T07:29:57.501512+00:00",
          1,
          "2025-09-02T10:25:58.866228",
          "2025-09-02T10:29:57.156445",
          null,
          null
        ],
        [
          22,
          "10@ya.ru_20250901175741",
          "10@ya.ru",
          "тест стом 3",
          "Завершено",
          "LOGOUT",
          "Приложение закрыто через крестик",
          "2025-09-02T05:58:06.182047+00:00",
          0,
          0,
          null,
          1,
          "2025-09-02T08:58:06.181994",
          "2025-09-02T08:58:06.181994",
          "user",
          "Стоматология"
        ]
      ],
      "offline_actions": []
    },
    "extra": {
      "logs_unsynced": 2,
      "offline_actions_pending": 0
    }
  },
  "sheets": {
    "worksheets": [
      {
        "title": "Admins",
        "header": [
          "Login",
          "Password"
        ],
        "rows_hint": 1000,
        "cols_hint": 26
      },
      {
        "title": "Users",
        "header": [
          "Email",
          "Name",
          "Phone",
          "Role",
          "Telegram",
          "ShiftHours",
          "Hours",
          "NotifyTelegram",
          "Group"
        ],
        "rows_hint": 999,
        "cols_hint": 26
      },
      {
        "title": "Groups",
        "header": [
          "Group",
          "Sheet",
          "Statuses",
          "Возможные статусы: \"В работе\",\n    \"Чат\",\n    \"Аудио\",\n    \"Запись\",\n    \"Анкеты\",\n    \"Перерыв\",\n    \"Обед\",\n    \"ЦИТО\",\n    \"Обучение\" \nУказывать через запятую, без ковычек"
        ],
        "rows_hint": 1000,
        "cols_hint": 18
      },
      {
        "title": "WorkLog_Запись",
        "header": [
          "123@ya.ru",
          "тест записи",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-08-25T17:49:24.965579",
          "123@ya.r_20250825174924",
          "2025-08-25T17:49:24.965517"
        ],
        "rows_hint": 1000,
        "cols_hint": 20
      },
      {
        "title": "WorkLog_Входящие",
        "header": [
          "Email",
          "Name",
          "Status",
          "ActionType",
          "Comment",
          "Timestamp",
          "SessionID",
          "StatusStartTime",
          "StatusEndTime"
        ],
        "rows_hint": 28,
        "cols_hint": 20
      },
      {
        "title": "ActiveSessions",
        "header": [
          "Email",
          "Name",
          "SessionID",
          "LoginTime",
          "Status",
          "LogoutTime",
          "RemoteCommand"
        ],
        "rows_hint": 905,
        "cols_hint": 26
      },
      {
        "title": "WorkLog_Стоматология",
        "header": [
          "10@ya.ru",
          "тест стом 3",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-09-01 16:05:14",
          "10@ya.ru_20250901160514",
          "2025-09-01 19:05:14",
          "2025-09-01 16:05:20"
        ],
        "rows_hint": 775,
        "cols_hint": 18
      },
      {
        "title": "WorkLog_Почта",
        "header": [
          "7@ya.ru",
          "Тест почты",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-08-25T14:21:50.941225",
          "7@ya.ru_20250825142150",
          "2025-08-25T14:21:50.941160"
        ],
        "rows_hint": 891,
        "cols_hint": 20
      },
      {
        "title": "AccessControl",
        "header": [
          "KeyType",
          "KeyValue",
          "AccessStatus",
          "BlockUntil",
          "Reason",
          "UpdatedAt"
        ],
        "rows_hint": 1000,
        "cols_hint": 26
      }
    ],
    "expectations": []
  }
}

--------------------------------------------------------------------------------
# FILE: logging_setup.py
# SIZE: 2050 bytes | SHA256(text): 98dc7bafe517d42a5c51d8b834ca7b819571876388aff69be7e13d72421c7037
--------------------------------------------------------------------------------
# logging_setup.py
from __future__ import annotations

import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
import sys
import re

def _mask_pii(msg: str) -> str:
    # простое маскирование email и телефонов
    msg = re.sub(r'([A-Za-z0-9._%+-]+)@([A-Za-z0-9.-]+\.[A-Za-z]{2,})', r'***@\2', msg)
    msg = re.sub(r'\+?\d[\d\s\-()]{6,}\d', '***PHONE***', msg)
    return msg

class PIIFilter(logging.Filter):
    def filter(self, record: logging.LogRecord) -> bool:
        if isinstance(record.msg, str):
            record.msg = _mask_pii(record.msg)
        return True

def setup_logging(app_name: str, log_dir: Path, level_console: int = logging.INFO, level_file: int = logging.DEBUG, reset: bool = True):
    log_dir.mkdir(parents=True, exist_ok=True)
    logfile = log_dir / f"{app_name}.log"

    root = logging.getLogger()
    root.setLevel(logging.DEBUG)
    # ВАЖНО: убираем ранее навешанные хендлеры (basicConfig и т.д.), чтобы не было дублей
    if reset and root.handlers:
        for h in list(root.handlers):
            root.removeHandler(h)

    fmt = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )

    # файл
    fh = RotatingFileHandler(logfile, maxBytes=5_000_000, backupCount=5, encoding="utf-8")
    fh.setLevel(level_file)
    fh.setFormatter(fmt)
    fh.addFilter(PIIFilter())
    root.addHandler(fh)

    # консоль
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(level_console)
    ch.setFormatter(fmt)
    ch.addFilter(PIIFilter())
    root.addHandler(ch)

    # Глушим болтливые сторонние либы
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("google").setLevel(logging.WARNING)
    logging.getLogger("gspread").setLevel(logging.INFO)
    logging.captureWarnings(True)
    return logfile

--------------------------------------------------------------------------------
# FILE: map_project.py
# SIZE: 569 bytes | SHA256(text): b482c900c1c23a191bee42e296ea4d67d4d4c8044506ff8e103397d7392a9907
--------------------------------------------------------------------------------
import os

EXCLUDE = {'.venv', '__pycache__', '.git', '.idea', 'dist', 'build'}
def tree(dir_path, prefix=''):
    entries = [e for e in os.listdir(dir_path) if e not in EXCLUDE]
    entries.sort()
    for i, name in enumerate(entries):
        path = os.path.join(dir_path, name)
        connector = '└── ' if i == len(entries) - 1 else '├── '
        print(prefix + connector + name)
        if os.path.isdir(path):
            extension = '    ' if i == len(entries) - 1 else '│   '
            tree(path, prefix + extension)

tree('.')

--------------------------------------------------------------------------------
# FILE: project_report.txt
# SIZE: 133737 bytes | SHA256(text): 844b022beeadc435d2117c68bb65b3181031f8e509b99077d4096a47eb70fbbc
--------------------------------------------------------------------------------
================================================================================
PROJECT SNAPSHOT
Generated:   2025-09-02 17:12:59
Root:        C:\moy python\projects vs code\roma
Python:      3.13.5
================================================================================

================================================================================
PROJECT TREE
================================================================================
├── .env
├── .gitignore
├── __init__.py
├── admin_app
│   ├── gui_admin.py
│   ├── main_admin.py
│   ├── repo.py
│   └── schedule_parser.py
├── archiver.py
├── auto_sync.py
├── build_admin.py
├── build_user.py
├── bundle_project.py
├── config.py
├── credentials
│   └── secret_creds.zip
├── diagnose_sync.log
├── diagnose_user_log.log
├── diagnostics_report.json
├── libcrypto-1_1-x64.dll
├── libcrypto-1_1.dll
├── libssl-1_1-x64.dll
├── libssl-1_1.dll
├── local_backup.db
├── logging_setup.py
├── logs

├── map_project.py
├── project_report.txt
├── pyproject.toml
├── requirements.txt
├── secret_creds.zip
├── sheets_api.py
├── sync
│   ├── __init__.py
│   ├── network.py
│   ├── notifications.py
│   └── sync_queue.py
├── telegram_bot
│   ├── __init__.py
│   ├── main.py
│   └── notifier.py
├── tools
│   ├── doctor.py
│   ├── tg_envcheck.py
│   └── tg_send.py
├── user_app
│   ├── __init__.py
│   ├── api.py
│   ├── app.log
│   ├── db_local.py
│   ├── db_migrations.py
│   ├── gui.py
│   ├── login_window.py
│   ├── main.py
│   ├── sberhealf.ico
│   ├── sberhealf.png
│   ├── signals.py
│   └── ui_helpers.py
└── work_time_tracker.egg-info
    ├── PKG-INFO
    ├── SOURCES.txt
    ├── dependency_links.txt
    ├── entry_points.txt
    ├── requires.txt
    └── top_level.txt

================================================================================
LOCAL SQLITE OVERVIEW
DB Path: c:\moy python\projects vs code\roma\local_backup.db
================================================================================
database_list: [(0, 'main', 'c:\\moy python\\projects vs code\\roma\\local_backup.db')]
--------------------------------------------------------------------------------
[TABLE] app_logs
schema: CREATE TABLE app_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - level TEXT NOTNULL=1 PK=0 DEFAULT=None
  - message TEXT NOTNULL=1 PK=0 DEFAULT=None
indexes:
  - idx_app_logs_ts UNIQUE=0
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TABLE] app_logs_legacy_20250826175446
schema: CREATE TABLE "app_logs_legacy_20250826175446" (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - level TEXT NOTNULL=1 PK=0 DEFAULT=None
  - message TEXT NOTNULL=1 PK=0 DEFAULT=None
indexes:
  - idx_logs_ts UNIQUE=0
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TABLE] logs
schema: CREATE TABLE logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                email TEXT NOT NULL,
                name TEXT NOT NULL,
                status TEXT,
                action_type TEXT NOT NULL,
                comment TEXT,
                timestamp TEXT NOT NULL,
                synced INTEGER DEFAULT 0,
                sync_attempts INTEGER DEFAULT 0,
                last_sync_attempt TEXT,
                priority INTEGER DEFAULT 1,
                status_start_time TEXT,
                status_end_time TEXT,
                reason TEXT,
                user_group TEXT
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - session_id TEXT NOTNULL=1 PK=0 DEFAULT=None
  - email TEXT NOTNULL=1 PK=0 DEFAULT=None
  - name TEXT NOTNULL=1 PK=0 DEFAULT=None
  - status TEXT NOTNULL=0 PK=0 DEFAULT=None
  - action_type TEXT NOTNULL=1 PK=0 DEFAULT=None
  - comment TEXT NOTNULL=0 PK=0 DEFAULT=None
  - timestamp TEXT NOTNULL=1 PK=0 DEFAULT=None
  - synced INTEGER NOTNULL=0 PK=0 DEFAULT=0
  - sync_attempts INTEGER NOTNULL=0 PK=0 DEFAULT=0
  - last_sync_attempt TEXT NOTNULL=0 PK=0 DEFAULT=None
  - priority INTEGER NOTNULL=0 PK=0 DEFAULT=1
  - status_start_time TEXT NOTNULL=0 PK=0 DEFAULT=None
  - status_end_time TEXT NOTNULL=0 PK=0 DEFAULT=None
  - reason TEXT NOTNULL=0 PK=0 DEFAULT=None
  - user_group TEXT NOTNULL=0 PK=0 DEFAULT=None
indexes:
  - idx_logs_session UNIQUE=0
      * 1: session_id
  - idx_logs_timestamp UNIQUE=0
      * 7: timestamp
  - idx_logs_synced UNIQUE=0
      * 8: synced
  - idx_logs_email UNIQUE=0
      * 2: email
triggers:
  - check_comment_length: CREATE TRIGGER check_comment_length
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN length(NEW.comment) > 500
            BEGIN
                SELECT RAISE(ABORT, 'Comment too long');
            END
  - prevent_duplicate_logout: CREATE TRIGGER prevent_duplicate_logout
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (
                SELECT 1 FROM logs
                WHERE session_id = NEW.session_id
                  AND LOWER(action_type) = 'logout'
                  AND timestamp > datetime('now', '-5 minutes')
            )
            BEGIN
                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');
            END
rows_count: 26
sample rows (last):
  • (26, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Завершено', 'LOGOUT', 'Завершение смены (нормальное)', '2025-09-02T07:31:20.622314+00:00', 0, 0, None, 1, '2025-09-02T10:31:20.622249', '2025-09-02T10:31:20.622249', 'user', 'Стоматология')
  • (25, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Аудио', 'STATUS_CHANGE', None, '2025-09-02T07:30:03.200596+00:00', 1, 1, '2025-09-02T07:30:05.016279+00:00', 1, '2025-09-02T10:30:03.197439', '2025-09-02T07:31:20.619894+00:00', None, None)
  • (24, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'Чат', 'STATUS_CHANGE', None, '2025-09-02T07:29:57.160421+00:00', 1, 2, '2025-09-02T07:30:03.496395+00:00', 1, '2025-09-02T10:29:57.156445', '2025-09-02T10:30:03.197439', None, None)
  • (23, '10@ya.ru_20250902102558', '10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-02T07:25:58.866299+00:00', 1, 2, '2025-09-02T07:29:57.501512+00:00', 1, '2025-09-02T10:25:58.866228', '2025-09-02T10:29:57.156445', None, None)
  • (22, '10@ya.ru_20250901175741', '10@ya.ru', 'тест стом 3', 'Завершено', 'LOGOUT', 'Приложение закрыто через крестик', '2025-09-02T05:58:06.182047+00:00', 0, 0, None, 1, '2025-09-02T08:58:06.181994', '2025-09-02T08:58:06.181994', 'user', 'Стоматология')
--------------------------------------------------------------------------------
[TABLE] offline_actions
schema: CREATE TABLE offline_actions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                action_type TEXT NOT NULL,
                payload TEXT NOT NULL,  -- JSON-строка
                status TEXT NOT NULL DEFAULT 'pending'  -- pending|synced|failed
            )
columns:
  - id INTEGER NOTNULL=0 PK=1 DEFAULT=None
  - ts TEXT NOTNULL=1 PK=0 DEFAULT=None
  - action_type TEXT NOTNULL=1 PK=0 DEFAULT=None
  - payload TEXT NOTNULL=1 PK=0 DEFAULT=None
  - status TEXT NOTNULL=1 PK=0 DEFAULT='pending'
indexes:
  - idx_offline_actions_status_ts UNIQUE=0
      * 4: status
      * 1: ts
rows_count: 0
--------------------------------------------------------------------------------
[TRIGGERS GLOBAL]
  - check_comment_length on logs: CREATE TRIGGER check_comment_length
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN length(NEW.comment) > 500
            BEGIN
                SELECT RAISE(ABORT, 'Comment too long');
            END
  - prevent_duplicate_logout on logs: CREATE TRIGGER prevent_duplicate_logout
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (
                SELECT 1 FROM logs
                WHERE session_id = NEW.session_id
                  AND LOWER(action_type) = 'logout'
                  AND timestamp > datetime('now', '-5 minutes')
            )
            BEGIN
                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');
            END
================================================================================
GOOGLE SHEETS OVERVIEW
================================================================================
Spreadsheet: WorkLog
--------------------------------------------------------------------------------
[SHEET] Admins
header: ['Login', 'Password']
rows_count (non-empty): 1
sample rows (first 3):
  • ['Admin', 'qwerty']
--------------------------------------------------------------------------------
[SHEET] Users
header: ['Email', 'Name', 'Phone', 'Role', 'Telegram', 'ShiftHours', 'Hours', 'NotifyTelegram', 'Group']
rows_count (non-empty): 12
sample rows (first 3):
  • ['1@ya.ru', 'тестовый чел', '888', 'Специалист', '', '5/2', '8', '', '']
  • ['2@ya.ru', 'Тестовый Вася', '111', '', '', '', '', '', '']
  • ['3@ya.ru', 'третий чел', '3333', '', '', '', '', '', '']
--------------------------------------------------------------------------------
[SHEET] Groups
header: ['Group', 'Sheet', 'Statuses', 'Возможные статусы: "В работе",\n    "Чат",\n    "Аудио",\n    "Запись",\n    "Анкеты",\n    "Перерыв",\n    "Обед",\n    "ЦИТО",\n    "Обучение" \nУказывать через запятую, без ковычек']
rows_count (non-empty): 4
sample rows (first 3):
  • ['Входящие', 'WorkLog_Входящие', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
  • ['Запись', 'WorkLog_Запись', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
  • ['Стоматология', 'WorkLog_Стоматология', 'В работе,Чат,Аудио,Перерыв,Обед,ЦИТО', '']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Запись
header: ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517']
rows_count (non-empty): 6
sample rows (first 3):
  • ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517', '', '']
  • ['123@ya.ru', 'тест записи', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T17:49:24.965579', '123@ya.r_20250825174924', '2025-08-25T17:49:24.965517', '2025-08-25T17:49:56.465386', '']
  • ['123@ya.ru', 'тест записи', 'Завершено', 'LOGOUT', 'Разлогинен администратором (удалённо)', '2025-08-25T17:49:56.505634', '123@ya.r_20250825174924', '2025-08-25T17:49:56.505530', '2025-08-25T17:49:56.505530', 'admin']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Входящие
header: ['Email', 'Name', 'Status', 'ActionType', 'Comment', 'Timestamp', 'SessionID', 'StatusStartTime', 'StatusEndTime']
rows_count (non-empty): 27
sample rows (first 3):
  • ['7@ya.ru_20250823171203', '7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-23T17:12:03.958642', '2025-08-23T17:12:03.958610', '2025-08-23T17:12:11.051848', '']
  • ['pid:dkuj4sai7negjt4x', 'PID-dkuj4s', 'В работе', 'LOGIN', 'Начало смены', '2025-08-27 14:41:46', 'pid:dkuj_20250827144146', '2025-08-27 17:41:46', '2025-08-27 14:41:52', '']
  • ['pid:dkuj4sai7negjt4x', 'PID-dkuj4s', 'В работе', 'LOGIN', 'Начало смены', '2025-08-27 14:41:46', 'pid:dkuj_20250827144146', '2025-08-27 17:41:46', '2025-08-27 14:57:43', '']
--------------------------------------------------------------------------------
[SHEET] ActiveSessions
header: ['Email', 'Name', 'SessionID', 'LoginTime', 'Status', 'LogoutTime', 'RemoteCommand']
rows_count (non-empty): 158
sample rows (first 3):
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731150702', '2025-07-31T15:07:02', 'finished', '2025-08-15 14:38:22', '']
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731152815', '2025-07-31T15:28:15', 'finished', '2025-07-31T15:28:49.376478', '']
  • ['5@ya.ru', 'Голубева Юлия Викторовна', '5@ya.ru_20250731154231', '2025-07-31T15:42:31', 'finished', '2025-07-31T15:43:08.484935', '']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Стоматология
header: ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:05:14', '10@ya.ru_20250901160514', '2025-09-01 19:05:14', '2025-09-01 16:05:20']
rows_count (non-empty): 19
sample rows (first 3):
  • ['10@ya.ru', 'тест стом 3', 'Чат', 'STATUS_CHANGE', '', '2025-09-01 16:05:31', '10@ya.ru_20250901160514', '2025-09-01 19:05:31', '2025-09-01 16:05:31']
  • ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:05:14', '10@ya.ru_20250901160514', '2025-09-01 19:05:14', '2025-09-01 19:05:31']
  • ['10@ya.ru', 'тест стом 3', 'В работе', 'LOGIN', 'Начало смены', '2025-09-01 16:48:28', '10@ya.ru_20250901164828', '2025-09-01 19:48:28', '2025-09-01 16:48:33']
--------------------------------------------------------------------------------
[SHEET] WorkLog_Почта
header: ['7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T14:21:50.941225', '7@ya.ru_20250825142150', '2025-08-25T14:21:50.941160']
rows_count (non-empty): 18
sample rows (first 3):
  • ['7@ya.ru', 'Тест почты', 'В работе', 'LOGIN', 'Начало смены', '2025-08-25T14:21:50.941225', '7@ya.ru_20250825142150', '2025-08-25T14:21:50.941160', '2025-08-25T14:23:04.217964', '']
  • ['7@ya.ru', 'Тест почты', 'Чат', 'STATUS_CHANGE', '', '2025-08-25T14:23:04.223693', '7@ya.ru_20250825142150', '2025-08-25T14:23:04.217964', '', '']
  • ['7@ya.ru', 'Тест почты', 'Чат', 'STATUS_CHANGE', '', '2025-08-25T14:23:04.223693', '7@ya.ru_20250825142150', '2025-08-25T14:23:04.217964', '2025-08-25T14:25:21.425490', '']
--------------------------------------------------------------------------------
[SHEET] AccessControl
header: ['KeyType', 'KeyValue', 'AccessStatus', 'BlockUntil', 'Reason', 'UpdatedAt']
rows_count (non-empty): 0
================================================================================
PROJECT REPORT
Generated:   2025-09-02 17:14:32
Root:        C:\moy python\projects vs code\roma
Python:      3.13.5
Files:       43
================================================================================


--------------------------------------------------------------------------------
# FILE: .gitignore
# SIZE: 437 bytes | SHA256(text): 927018a20d479a444e2d7d6b4836885f02432e4616c8f83dfb3e523ef6051a83
--------------------------------------------------------------------------------
# Python
__pycache__/
*.pyc
*.pyo
*.pyd

# SQLite (локальные БД)
*.db
*.db-shm
*.db-wal

# Логи
*.log
logs/
*.bak

# Секреты и ключи
.env
secret_creds.zip

# PyInstaller
*.spec
dist/
build/
*.exe
*.dll

# IDE/Editor
.vscode/
.idea/
.DS_Store

# GCP creds — запрещено хранить в репозитории
credentials/*.json
*.secret.json
service_account.json

--------------------------------------------------------------------------------
# FILE: __init__.py
# SIZE: 343 bytes | SHA256(text): 423245e097df4d9c26b80058efa8bc9635eddc1ac1b1a2482e90816d7b154ca6
--------------------------------------------------------------------------------
# Инициализация пакета user_app
from .version import __version__

__all__ = [
    'main',
    'gui', 
    'login_window',
    'db_local',
    'sheets_api',
    'sync'
]

# Инициализация путей
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

--------------------------------------------------------------------------------
# FILE: admin_app\gui_admin.py
# SIZE: 0 bytes | SHA256(text): e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
# FILE: admin_app\main_admin.py
# SIZE: 21626 bytes | SHA256(text): df255496219eed226297ec882cfe813e8cf046f5e231999a37080a23114343a7
--------------------------------------------------------------------------------
# admin_app/main_admin.py
from __future__ import annotations

import sys
import logging
import time
from pathlib import Path
from typing import Optional, Dict, List, Tuple

from PyQt5.QtCore import Qt
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QLineEdit,
    QPushButton, QTableWidget, QTableWidgetItem, QCheckBox, QComboBox, QMessageBox,
    QTabWidget, QGroupBox
)

# --- Единое логирование для админки ---
from logging_setup import setup_logging
from config import LOG_DIR

# --- Доменная логика/репозиторий ---
from admin_app.repo import AdminRepo

# =================== Константы UI ===================
FIELDS = ["Email", "Name", "Phone", "Role", "Telegram", "Group", "NotifyTelegram"]
ROLES = ["специалист", "старший специалист", "ведущий специалист", "руководитель группы"]

# Загрузка GROUP_MAPPING с обработкой ошибок
try:
    # статическая карта групп, если определена в config.py
    from config import GROUP_MAPPING
except Exception:
    GROUP_MAPPING = {}

# =================== Диалог редактирования пользователя ===================
from PyQt5.QtWidgets import QDialog

class UserDialog(QDialog):
    def __init__(self, parent=None, user: Optional[Dict[str, str]] = None, groups: List[str] = None):
        super().__init__(parent)
        self.setWindowTitle("Карточка сотрудника")
        self.user = user or {}
        self.groups = groups or []
        self._build()

    def _build(self):
        layout = QVBoxLayout(self)

        self.email_input = QLineEdit(str(self.user.get("Email", "")))
        self.fio_input = QLineEdit(str(self.user.get("Name", "")))
        self.phone_input = QLineEdit(str(self.user.get("Phone", "")))
        self.tg_input = QLineEdit(str(self.user.get("Telegram", "")))

        self.role_combo = QComboBox()
        self.role_combo.addItems(ROLES)
        role_val = str(self.user.get("Role", "")).strip()
        if role_val in ROLES:
            self.role_combo.setCurrentText(role_val)

        self.group_combo = QComboBox()
        self.group_combo.addItems(self.groups)
        group_val = str(self.user.get("Group", "")).strip()
        if group_val in self.groups:
            self.group_combo.setCurrentText(group_val)

        self.tg_notify_chk = QCheckBox("Отправлять уведомления в Telegram")
        chk = str(self.user.get("NotifyTelegram", "")).strip().lower()
        self.tg_notify_chk.setChecked(chk in ("yes", "true", "1", "да"))

        layout.addWidget(QLabel("Email:"))
        layout.addWidget(self.email_input)
        layout.addWidget(QLabel("ФИО:"))
        layout.addWidget(self.fio_input)
        layout.addWidget(QLabel("Телефон:"))
        layout.addWidget(self.phone_input)
        layout.addWidget(QLabel("Telegram:"))
        layout.addWidget(self.tg_input)
        layout.addWidget(QLabel("Должность:"))
        layout.addWidget(self.role_combo)
        layout.addWidget(QLabel("Группа:"))
        layout.addWidget(self.group_combo)
        layout.addWidget(self.tg_notify_chk)

        btns = QHBoxLayout()
        btn_save = QPushButton("Сохранить")
        btn_save.clicked.connect(self.accept)
        btn_cancel = QPushButton("Отмена")
        btn_cancel.clicked.connect(self.reject)
        btns.addWidget(btn_save)
        btns.addWidget(btn_cancel)
        layout.addLayout(btns)

    def get_user(self) -> Dict[str, str]:
        return {
            "Email": self.email_input.text().strip().lower(),
            "Name": self.fio_input.text().strip(),
            "Phone": self.phone_input.text().strip(),
            "Role": self.role_combo.currentText().strip(),
            "Telegram": self.tg_input.text().strip(),
            "Group": self.group_combo.currentText().strip(),
            "NotifyTelegram": "Yes" if self.tg_notify_chk.isChecked() else "No",
        }

# =================== Главное окно ===================

class AdminWindow(QMainWindow):
    def __init__(self, groups: List[str]):
        super().__init__()
        self.setWindowTitle("Админка WorkTimeTracker")
        self.resize(1400, 780)
        
        # Группы
        self.groups = groups

        # Репозиторий
        self.repo = AdminRepo()

        # Кэш пользователей и активных e-mail
        self.users: List[Dict[str, str]] = []
        self._active_cache: Tuple[float, set[str]] = (0.0, set())  # (ts, {emails})
        self._active_ttl_sec = 30.0

        self._build_ui()
        self.refresh_users()
        self.load_shift_calendar()

    # ---------- UI ----------
    def _build_ui(self):
        self.tabs = QTabWidget(self)

        # --- Вкладка "Сотрудники" ---
        self.tab_users = QWidget()
        users_layout = QVBoxLayout(self.tab_users)

        # Фильтры
        filter_layout = QHBoxLayout()
        filter_layout.addWidget(QLabel("Группа:"))
        self.group_filter_combo = QComboBox()
        self.group_filter_combo.addItem("Все группы")
        self.group_filter_combo.addItems(self.groups)
        self.group_filter_combo.currentIndexChanged.connect(self.apply_user_search)
        filter_layout.addWidget(self.group_filter_combo)

        self.only_active_chk = QCheckBox("Только активные")
        self.only_active_chk.stateChanged.connect(self.apply_user_search)
        filter_layout.addWidget(self.only_active_chk)

        filter_layout.addStretch()
        users_layout.addLayout(filter_layout)

        # Поиск и кнопки
        top_layout = QHBoxLayout()
        self.search_input = QLineEdit()
        self.search_input.setPlaceholderText("Поиск по ФИО или email")
        self.search_input.textChanged.connect(self.apply_user_search)
        top_layout.addWidget(self.search_input)

        btn_add = QPushButton("Добавить")
        btn_add.clicked.connect(self.add_user)
        btn_edit = QPushButton("Редактировать")
        btn_edit.clicked.connect(self.edit_user)
        btn_delete = QPushButton("Удалить")
        btn_delete.clicked.connect(self.on_delete_user_clicked)
        btn_kick = QPushButton("Разлогинить")
        btn_kick.clicked.connect(self.on_force_logout_clicked)

        for b in (btn_add, btn_edit, btn_delete, btn_kick):
            top_layout.addWidget(b)
        users_layout.addLayout(top_layout)

        # Таблица пользователей
        self.users_table = QTableWidget(0, len(FIELDS))
        self.users_table.setHorizontalHeaderLabels(
            ["Email", "ФИО", "Телефон", "Должность", "Telegram", "Группа", "Telegram уведомления"]
        )
        self.users_table.setSelectionBehavior(QTableWidget.SelectRows)
        users_layout.addWidget(self.users_table)

        self.tabs.addTab(self.tab_users, "Сотрудники")

        # --- Вкладка "График" ---
        self.tab_schedule = QWidget()
        schedule_layout = QVBoxLayout(self.tab_schedule)

        header_layout = QHBoxLayout()
        header_layout.addWidget(QLabel("Сотрудник:"))
        self.schedule_user_combo = QComboBox()
        self.schedule_user_combo.addItem("Выберите сотрудника")
        self.schedule_user_combo.currentIndexChanged.connect(self.on_schedule_user_change)
        header_layout.addWidget(self.schedule_user_combo)
        header_layout.addStretch()
        schedule_layout.addLayout(header_layout)

        self.info_group = QGroupBox("Информация о сотруднике")
        info_layout = QVBoxLayout()
        self.login_status_lbl = QLabel("Залогинен: Нет")
        self.btn_force_logout = QPushButton("Разлогинить")
        self.btn_force_logout.setEnabled(False)
        self.btn_force_logout.clicked.connect(self.force_logout_from_schedule)
        status_row = QHBoxLayout()
        status_row.addWidget(self.login_status_lbl)
        status_row.addWidget(self.btn_force_logout)
        status_row.addStretch()
        info_layout.addLayout(status_row)

        self.info_label = QLabel("")
        self.info_label.setWordWrap(True)
        info_layout.addWidget(self.info_label)
        self.info_group.setLayout(info_layout)
        schedule_layout.addWidget(self.info_group)

        self.schedule_table = QTableWidget()
        schedule_layout.addWidget(self.schedule_table)

        self.tabs.addTab(self.tab_schedule, "График")

        # --- Вкладка "Дополнительно" (плейсхолдер) ---
        self.tab_extra = QWidget()
        extra_layout = QVBoxLayout(self.tab_extra)
        extra_layout.addWidget(QLabel("Тут будет что-то ещё"))
        self.tabs.addTab(self.tab_extra, "Дополнительно")

        self.setCentralWidget(self.tabs)

    # ---------- Helpers ----------
    def _selected_email(self) -> Optional[str]:
        items = self.users_table.selectedItems()
        if not items:
            return None
        val = items[0].text().strip()
        return val[2:] if val.startswith("🟢 ") else val

    def _confirm(self, msg: str) -> bool:
        return QMessageBox.question(self, "Подтверждение", msg, QMessageBox.Yes | QMessageBox.No, QMessageBox.No) == QMessageBox.Yes

    def _info(self, msg: str):
        QMessageBox.information(self, "Информация", msg)

    def _warn(self, msg: str):
        QMessageBox.warning(self, "Ошибка", msg)

    # ---------- Активные сессии (кэш) ----------
    def _get_active_emails_cached(self) -> set[str]:
        ts, emails = self._active_cache
        if time.monotonic() - ts < self._active_ttl_sec:
            return emails
        try:
            sessions = self.repo.get_active_sessions()
            emails = {str(s.get("Email", "")).strip().lower() for s in sessions if str(s.get("Status", "")).strip().lower() == "active"}
            self._active_cache = (time.monotonic(), emails)
            return emails
        except Exception as e:
            logger.warning("Не удалось получить активные сессии: %s", e)
            return set()

    # =================== Таб "Сотрудники" ===================

    def refresh_users(self):
        try:
            rows = self.repo.list_users()
        except Exception as e:
            logger.exception("refresh_users failed: %s", e)
            rows = []

        self.users = []
        for r in rows:
            nt = str(r.get("NotifyTelegram", "")).strip().lower()
            nt_norm = "Yes" if nt in ("yes", "true", "1", "да") else "No"
            self.users.append({
                "Email": str(r.get("Email", "")),
                "Name": str(r.get("Name", "")),
                "Phone": str(r.get("Phone", "")),
                "Role": str(r.get("Role", "")),
                "Telegram": str(r.get("Telegram", "")),
                "Group": str(r.get("Group", "")),
                "NotifyTelegram": nt_norm,
            })

        # заполняем таблицу
        self.refresh_users_table()

        # и выпадающий список на вкладке "График"
        self.schedule_user_combo.blockSignals(True)
        self.schedule_user_combo.clear()
        self.schedule_user_combo.addItem("Выберите сотрудника")
        for u in self.users:
            fio = u.get("Name", "")
            if fio:
                self.schedule_user_combo.addItem(fio)
        self.schedule_user_combo.blockSignals(False)

    def refresh_users_table(self, filter_text: str = ""):
        self.users_table.setRowCount(0)
        selected_group = self.group_filter_combo.currentText()
        only_active = self.only_active_chk.isChecked()
        active_emails = self._get_active_emails_cached() if only_active else set()

        for u in self.users:
            email = u.get("Email", "").strip().lower()
            group = u.get("Group", "").strip()
            is_active = email in active_emails

            # поиск
            if filter_text:
                q = filter_text.lower()
                if q not in email and q not in u.get("Name", "").lower():
                    continue
            # фильтр по группе
            if selected_group != "Все группы" and group != selected_group:
                continue
            # фильтр активности
            if only_active and not is_active:
                continue

            row = self.users_table.rowCount()
            self.users_table.insertRow(row)
            for col, key in enumerate(FIELDS):
                val = u.get(key, "")
                if key == "Email" and is_active:
                    val = f"🟢 {val}"
                item = QTableWidgetItem(str(val))
                item.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)
                self.users_table.setItem(row, col, item)

    def apply_user_search(self):
        self.refresh_users_table(self.search_input.text())

    # --- CRUD/Actions ---

    def add_user(self):
        dlg = UserDialog(self, groups=self.groups)
        if dlg.exec_():
            data = dlg.get_user()
            if self.repo.add_or_update_user(data):
                self._info("Пользователь добавлен")
                self.refresh_users()
            else:
                self._warn("Ошибка при добавлении пользователя")

    def edit_user(self):
        row = self.users_table.currentRow()
        if row < 0 or row >= len(self.users):
            self._warn("Сначала выберите строку для редактирования.")
            return
        user = self.users[row]
        dlg = UserDialog(self, user=user, groups=self.groups)
        if dlg.exec_():
            data = dlg.get_user()
            if self.repo.add_or_update_user(data):
                self._info("Пользователь обновлён")
                self.refresh_users()
            else:
                self._warn("Ошибка при обновлении пользователя")

    def on_delete_user_clicked(self):
        email = self._selected_email()
        if not email:
            self._warn("Выберите пользователя")
            return
        if not self._confirm(f"Удалить пользователя {email}?"):
            return
        if self.repo.delete_user(email):
            self._info("Пользователь удалён")
            self.refresh_users()
        else:
            self._warn("Пользователь не найден или не удалён")

    def on_force_logout_clicked(self):
        email = self._selected_email()
        if not email:
            self._warn("Выберите пользователя из списка.")
            return

        # отображаем ФИО для красоты
        fio = ""
        sel = self.users_table.selectedItems()
        if sel and len(sel) > 1:
            fio = sel[1].text()

        if not self._confirm(f"Разлогинить {fio or email}?"):
            return

        if self.repo.force_logout(email=email):
            self._info(f"Пользователь {fio or email} был разлогинен.")
            # сбрасываем кэш активностей, чтобы таблица обновилась корректно
            self._active_cache = (0.0, set())
            self.refresh_users()
        else:
            self._warn("Активная сессия не найдена")

    # =================== Таб "График" ===================

    def load_shift_calendar(self):
        """Подтягиваем таблицу графика. Если её нет — отключаем элементы."""
        try:
            data = self.repo.get_shift_calendar()
        except Exception as e:
            logger.exception("Ошибка при загрузке графика: %s", e)
            data = []

        self.shift_calendar_data: List[List[str]] = data
        self.shift_headers: List[str] = data[0] if data else []

        if not data:
            self.info_label.setText("Лист графика не найден или пуст.")
            self.login_status_lbl.setText("Залогинен: Нет")
            self.btn_force_logout.setEnabled(False)
            self.schedule_table.setRowCount(0)
            self.schedule_table.setColumnCount(0)
            self.schedule_user_combo.setEnabled(bool(self.users))
            return

        self.schedule_user_combo.setEnabled(True)

    def on_schedule_user_change(self):
        idx = self.schedule_user_combo.currentIndex()
        if idx <= 0 or not self.shift_calendar_data:
            self.schedule_table.setRowCount(0)
            self.schedule_table.setColumnCount(0)
            self.info_label.setText("")
            self.login_status_lbl.setText("Залогинен: Нет")
            self.btn_force_logout.setEnabled(False)
            return

        fio = self.schedule_user_combo.currentText()
        email = ""
        for u in self.users:
            if u.get("Name", "") == fio:
                email = u.get("Email", "")
                break

        # статус логина
        active = self._get_active_emails_cached()
        is_logged_in = email.strip().lower() in active
        self.login_status_lbl.setText(f"Залогинен: {'Да' if is_logged_in else 'Нет'}")
        self.btn_force_logout.setEnabled(is_logged_in)
        self.btn_force_logout.setProperty("user_email", email)
        self.btn_force_logout.setProperty("user_fio", fio)

        # инфо по сотруднику
        info_parts = [f"<b>ФИО:</b> {fio}", f"<b>Email:</b> {email}"]
        self.info_label.setText("<br>".join(info_parts))

        # табель по дням (ищем первые числовые заголовки как дни месяца)
        headers = self.shift_headers
        row_for_user: Optional[List[str]] = None
        for r in self.shift_calendar_data[1:]:
            if r and r[0].strip() == fio:
                row_for_user = r
                break

        day_indices = [(i, h) for i, h in enumerate(headers) if str(h).isdigit()]
        self.schedule_table.setRowCount(0)
        self.schedule_table.setColumnCount(len(day_indices))
        self.schedule_table.setHorizontalHeaderLabels([str(h) for _, h in day_indices])

        if row_for_user:
            self.schedule_table.setRowCount(1)
            for col, (i, _) in enumerate(day_indices):
                val = row_for_user[i] if i < len(row_for_user) else ""
                self.schedule_table.setItem(0, col, QTableWidgetItem(str(val)))
            self.schedule_table.resizeColumnsToContents()

    def force_logout_from_schedule(self):
        email = self.btn_force_logout.property("user_email")
        fio = self.btn_force_logout.property("user_fio")
        if not email:
            self._warn("Не удалось определить Email пользователя.")
            return
        if not self._confirm(f"Разлогинить {fio or email}?"):
            return

        if self.repo.force_logout(email=email):
            self._info(f"Пользователь {fio or email} разлогинен.")
            self.btn_force_logout.setEnabled(False)
            self.login_status_lbl.setText("Залогинен: Нет")
            # сбрасываем кэш активностей
            self._active_cache = (0.0, set())
            self.refresh_users()
        else:
            self._warn("Активная сессия не найдена")

# =================== Вспомогательные функции ===================

def get_available_groups(repo: AdminRepo) -> list[str]:
    """Получение списка доступных групп"""
    if GROUP_MAPPING:
        return sorted(set(GROUP_MAPPING.values()))
    return repo.list_groups_from_sheet()

# =================== Entrypoint ===================

def main():
    # Единое логирование для админки
    log_path = setup_logging(app_name="wtt-admin", log_dir=LOG_DIR)
    logger = logging.getLogger(__name__)
    logger.info("Admin app logging initialized (path=%s)", log_path)
    
    # Получение списка групп
    repo = AdminRepo()
    groups = get_available_groups(repo)
    logger.info("Groups: %s", ", ".join(groups) if groups else "<none>")
    
    # Запуск GUI с передачей списка групп
    app = QApplication(sys.argv)
    win = AdminWindow(groups=groups)
    win.show()
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: admin_app\repo.py
# SIZE: 8954 bytes | SHA256(text): 4a8ef84d5b996624f84258294e093fd05e5cc30c7b2ab55b47d86761e409c0ed
--------------------------------------------------------------------------------
# admin_app/repo.py
from __future__ import annotations

import logging
from typing import List, Dict, Optional
from datetime import datetime, timezone

from sheets_api import SheetsAPI, SheetsAPIError
from config import (
    GOOGLE_SHEET_NAME,
    USERS_SHEET,
    ACTIVE_SESSIONS_SHEET,
)

logger = logging.getLogger(__name__)

# Возможные названия листа с графиком (по приоритету)
CANDIDATE_SCHEDULE_TITLES = ["ShiftCalendar", "Schedule", "График"]


class AdminRepo:
    """
    Репозиторий административных операций.
    Все операции идут через централизованный SheetsAPI (ретраи/квоты/логирование).
    """

    def __init__(self, sheets: Optional[SheetsAPI] = None):
        self.sheets = sheets or SheetsAPI()

    # -------------------------------------------------------------------------
    # Users
    # -------------------------------------------------------------------------
    def list_users(self) -> List[Dict[str, str]]:
        """
        Возвращает список пользователей как список словарей (колонки по заголовку листа Users).
        """
        try:
            # Используем высокоуровневый метод SheetsAPI, чтобы не дублировать логику
            users = self.sheets.get_users()  # type: ignore[attr-defined]
            return users or []
        except AttributeError:
            # Фолбэк, если вдруг нет get_users() (старый SheetsAPI)
            ws = self.sheets.get_worksheet(USERS_SHEET)
            values = self.sheets._request_with_retry(ws.get_all_values)
            if not values:
                return []
            header = values[0]
            out: List[Dict[str, str]] = []
            for row in values[1:]:
                if any((c or "").strip() for c in row):
                    out.append({header[i]: (row[i] if i < len(header) else "") for i in range(len(header))})
            return out
        except Exception as e:
            logger.exception("Не удалось получить список пользователей: %s", e)
            return []

    def add_or_update_user(self, user: Dict[str, str]) -> bool:
        """
        Добавляет или обновляет пользователя (по Email).
        """
        try:
            self.sheets.upsert_user(user)  # type: ignore[attr-defined]
            return True
        except AttributeError:
            # Фолбэк на старый интерфейс — пробуем обновить набор полей
            try:
                email = user.get("Email") or user.get("email")
                if not email:
                    raise ValueError("user.Email is required")
                fields = {k: v for k, v in user.items() if k != "Email"}
                self.sheets.update_user_fields(email=email, fields=fields)  # type: ignore[attr-defined]
                return True
            except Exception as e:
                logger.exception("Fallback upsert_user failed: %s", e)
                return False
        except Exception as e:
            logger.exception("add_or_update_user error: %s", e)
            return False

    def delete_user(self, email: str) -> bool:
        """
        Удаляет пользователя по Email.
        """
        try:
            return bool(self.sheets.delete_user(email))  # type: ignore[attr-defined]
        except Exception as e:
            logger.exception("delete_user error for %s: %s", email, e)
            return False

    # -------------------------------------------------------------------------
    # Groups
    # -------------------------------------------------------------------------
    def list_groups_from_sheet(self) -> list[str]:
        """
        Возвращает список доступных групп из листа 'Groups' (колонка 'Group').
        Пустые/дубликаты фильтруются.
        """
        try:
            ws = self.sheets.get_worksheet("Groups")
            values = self.sheets._request_with_retry(ws.get_all_values)
            groups = []
            for row in values[1:]:  # пропускаем заголовок
                if not row:
                    continue
                g = (row[0] or "").strip()
                if g:
                    groups.append(g)
            return sorted(set(groups))
        except Exception as e:
            logger.warning("list_groups_from_sheet failed: %s", e)
            return []

    # -------------------------------------------------------------------------
    # Active sessions
    # -------------------------------------------------------------------------
    def get_active_sessions(self) -> List[Dict]:
        """
        Возвращает все записи листа ActiveSessions (словари колонок).
        """
        try:
            sessions = self.sheets.get_all_active_sessions()  # type: ignore[attr-defined]
            return sessions or []
        except Exception as e:
            logger.exception("get_active_sessions error: %s", e)
            return []

    def force_logout(self, email: str) -> bool:
        """
        Принудительно завершает ПОСЛЕДНЮЮ активную сессию пользователя.
        Возвращает True, если удалось обновить строку.
        """
        try:
            ok = self.sheets.kick_active_session(email=email)  # type: ignore[attr-defined]
            if ok:
                logger.info("Force logout success for %s", email)
            else:
                logger.info("Force logout: активная сессия не найдена для %s", email)
            return bool(ok)
        except Exception as e:
            logger.exception("force_logout error for %s: %s", email, e)
            return False

    # -------------------------------------------------------------------------
    # Schedule (Shift calendar)
    # -------------------------------------------------------------------------
    def _list_titles(self) -> List[str]:
        """
        Возвращает список названий листов книги.
        """
        try:
            if hasattr(self.sheets, "list_worksheet_titles"):
                return list(self.sheets.list_worksheet_titles())  # type: ignore[attr-defined]
        except Exception:
            pass

        # Фолбэк через открытую книгу
        try:
            spreadsheet = self.sheets._request_with_retry(self.sheets.client.open, GOOGLE_SHEET_NAME)
            worksheets = self.sheets._request_with_retry(spreadsheet.worksheets)
            return [ws.title for ws in worksheets]
        except Exception as e:
            logger.warning("Не удалось получить список листов: %s", e)
            return []

    def _pick_schedule_title(self, titles: List[str]) -> Optional[str]:
        """
        Выбирает название листа графика из известных вариантов.
        """
        available = set(titles)
        for cand in CANDIDATE_SCHEDULE_TITLES:
            if cand in available:
                return cand
        return None

    def get_shift_calendar(self) -> List[List[str]]:
        """
        Возвращает таблицу графика как список списков:
        [ [header...], [row1...], ... ]. Если лист отсутствует — [].
        """
        try:
            titles = self._list_titles()
            if not titles:
                logger.info("В книге '%s' не найдено листов.", GOOGLE_SHEET_NAME)
                return []

            name = self._pick_schedule_title(titles)
            if not name:
                logger.info(
                    "Лист графика не найден. Ожидались: %s; есть: %s",
                    ", ".join(CANDIDATE_SCHEDULE_TITLES),
                    ", ".join(titles),
                )
                return []

            ws = self.sheets.get_worksheet(name)
            values = self.sheets._request_with_retry(ws.get_all_values)
            return values or []
        except SheetsAPIError as e:
            logger.warning("Ошибка доступа к листу графика: %s", e)
            return []
        except Exception as e:
            logger.exception("get_shift_calendar error: %s", e)
            return []

--------------------------------------------------------------------------------
# FILE: admin_app\schedule_parser.py
# SIZE: 4599 bytes | SHA256(text): 5f71b0fd877ad4c30a0ff770ef0ca2e0c748c080591488fa53c0ca65c9fb27c6
--------------------------------------------------------------------------------
# admin_app/schedule_parser.py
"""
DEPRECATED: помогает сохранить совместимость, но не должен использоваться в новом коде.
Теперь график читается централизованно через SheetsAPI / AdminRepo.get_shift_calendar().

Если модуль всё ещё импортируется старыми участками кода, функции ниже делегируют чтение
в Google Sheets через SheetsAPI (без pandas/requests и без прямых gspread-вызовов).
"""

from __future__ import annotations
from typing import List, Optional
import logging
from pathlib import Path
import sys

# Добавляем корень проекта в sys.path, чтобы были доступны config и sheets_api при прямом запуске
ROOT_PATH = str(Path(__file__).parent.parent.resolve())
if ROOT_PATH not in sys.path:
    sys.path.insert(0, ROOT_PATH)

from sheets_api import SheetsAPI, SheetsAPIError  # централизованный слой
from config import GOOGLE_SHEET_NAME  # только для сообщений

logger = logging.getLogger(__name__)
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO)

# Возможные названия листа с графиком (приоритет по порядку)
CANDIDATE_SCHEDULE_TITLES = ["ShiftCalendar", "Schedule", "График"]


def _list_titles(sheets: SheetsAPI) -> List[str]:
    """Пытаемся получить список названий листов через SheetsAPI, с фолбэком."""
    try:
        # Новая версия SheetsAPI может иметь list_worksheet_titles()
        if hasattr(sheets, "list_worksheet_titles"):
            return list(sheets.list_worksheet_titles())  # type: ignore
    except Exception:
        pass

    # Фолбэк: напрямую через открытую книгу (всё равно через _request_with_retry)
    try:
        spreadsheet = sheets._request_with_retry(sheets.client.open, GOOGLE_SHEET_NAME)
        worksheets = sheets._request_with_retry(spreadsheet.worksheets)
        return [ws.title for ws in worksheets]
    except Exception as e:
        logger.warning("Не удалось получить список листов: %s", e)
        return []


def _pick_schedule_sheet_title(titles: List[str]) -> Optional[str]:
    """Выбираем первый подходящий лист из известных вариантов."""
    tset = set(titles)
    for cand in CANDIDATE_SCHEDULE_TITLES:
        if cand in tset:
            return cand
    return None


def get_shift_calendar() -> List[List[str]]:
    """
    Возвращает «таблицу графика» как список списков: [ [header...], [row1...], ... ].
    Если лист графика отсутствует — вернёт [].
    В новом коде используйте AdminRepo.get_shift_calendar().
    """
    sheets = SheetsAPI()

    titles = _list_titles(sheets)
    if not titles:
        logger.info("В книге '%s' не найдено ни одного листа.", GOOGLE_SHEET_NAME)
        return []

    sheet_name = _pick_schedule_sheet_title(titles)
    if not sheet_name:
        logger.info(
            "Лист графика не найден. Ожидались один из: %s; есть: %s",
            ", ".join(CANDIDATE_SCHEDULE_TITLES), ", ".join(titles),
        )
        return []

    try:
        ws = sheets.get_worksheet(sheet_name)
        values = sheets._request_with_retry(ws.get_all_values)
        if not values:
            logger.info("Лист '%s' пустой.", sheet_name)
            return []
        return values
    except SheetsAPIError as e:
        logger.warning("Ошибка доступа к листу '%s': %s", sheet_name, e)
        return []
    except Exception as e:
        logger.exception("Не удалось прочитать лист '%s': %s", sheet_name, e)
        return []


# Для обратной совместимости со старым именем
def get_shift_info() -> List[List[str]]:
    """Старое имя функции, оставлено для совместимости."""
    logger.warning("schedule_parser.get_shift_info() устарела — используйте AdminRepo.get_shift_calendar().")
    return get_shift_calendar()

--------------------------------------------------------------------------------
# FILE: archiver.py
# SIZE: 7712 bytes | SHA256(text): bdfd07e45105c2a0c310884e7ac82791d9cabb3eccfefbe7f52395601d450874
--------------------------------------------------------------------------------
# archiver.py (reworked to use centralized SheetsAPI only)
from __future__ import annotations

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import List, Tuple, Optional, Dict
import logging
import argparse

# Ensure project root is importable (so we can import config and sheets_api when run directly)
ROOT_PATH = str(Path(__file__).parent.resolve())
if ROOT_PATH not in sys.path:
    sys.path.insert(0, ROOT_PATH)

from config import GOOGLE_SHEET_NAME, WORKLOG_SHEET, ARCHIVE_SHEET  # type: ignore
from sheets_api import SheetsAPI, SheetsAPIError  # type: ignore

logger = logging.getLogger(__name__)


# ---- helpers ----

TS_HEADER_CANDIDATES = ("timestamp", "Timestamp", "time", "Time", "Дата", "Время", "DateTime", "datetime")

def _parse_ts(s: str) -> Optional[datetime]:
    """
    Parse timestamp in flexible formats. Prefer ISO-8601 with timezone.
    Returns timezone-aware datetime in local timezone for date comparison.
    """
    s = (s or "").strip()
    if not s:
        return None
    fmts = [
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%dT%H:%M:%S.%f%z",
        "%Y-%m-%d %H:%M:%S%z",
        "%Y-%m-%d %H:%M:%S",
        "%d.%m.%Y %H:%M:%S",
        "%d.%m.%Y",
        "%Y-%m-%d",
    ]
    for f in fmts:
        try:
            dt = datetime.strptime(s, f)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt.astimezone()
        except Exception:
            continue
    try:
        dt = datetime.fromisoformat(s)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt.astimezone()
    except Exception:
        return None


def _yesterday_local(base: Optional[datetime] = None) -> datetime.date:
    now_local = (base or datetime.now().astimezone())
    return (now_local.date() - timedelta(days=1))


def _find_timestamp_index(header: List[str]) -> Optional[int]:
    idx_map = { (h or "").strip(): i for i, h in enumerate(header) }
    for key in TS_HEADER_CANDIDATES:
        for h,i in idx_map.items():
            if h.lower() == key.lower():
                return i
    if len(header) >= 6 and header[5].lower().startswith("time"):
        return 5
    return None


def _ensure_archive_sheet(sheets: SheetsAPI, header: List[str]) -> object:
    """
    Get archive worksheet; if missing — create and put header.
    """
    try:
        ws = sheets.get_worksheet(ARCHIVE_SHEET)
        values = sheets._request_with_retry(ws.get_all_values)
        if not values:
            sheets._request_with_retry(ws.update, "A1", [header])
        elif values and values[0] != header:
            pass
        return ws
    except SheetsAPIError:
        from config import GOOGLE_SHEET_NAME  # lazy import
        spreadsheet = sheets._request_with_retry(sheets.client.open, GOOGLE_SHEET_NAME)
        ws = sheets._request_with_retry(spreadsheet.add_worksheet, title=ARCHIVE_SHEET, rows=1, cols=max(1, len(header)))
        sheets._request_with_retry(ws.update, "A1", [header])
        return ws


def _collect_rows_for_date(values: List[List[str]], day: datetime.date) -> Tuple[List[List[str]], List[List[str]], List[str]]:
    """
    Split table rows to (to_archive, to_keep).
    Returns (to_archive_rows, keep_rows, header)
    """
    if not values:
        return [], [], []

    header = values[0]
    body = values[1:]
    ts_idx = _find_timestamp_index(header)
    if ts_idx is None:
        logger.warning("Timestamp column not found in header: %s", header)
        return [], values[1:], header

    to_archive: List[List[str]] = []
    keep_rows: List[List[str]] = []

    for row in body:
        ts_raw = row[ts_idx] if ts_idx < len(row) else ""
        dt = _parse_ts(ts_raw)
        if dt and dt.date() == day:
            to_archive.append(row)
        else:
            keep_rows.append(row)

    return to_archive, keep_rows, header


def _process_sheet(sheets: SheetsAPI, sheet_name: str, day: datetime.date, dry_run: bool = False) -> Tuple[int,int]:
    """
    Process one sheet: move rows for `day` to ARCHIVE_SHEET.
    Returns (archived_count, kept_count)
    """
    try:
        ws = sheets.get_worksheet(sheet_name)
        values = sheets._request_with_retry(ws.get_all_values)
        to_move, keep, header = _collect_rows_for_date(values, day)
        if not header:
            logger.info("[%s] empty or no header — skipping", sheet_name)
            return 0, len(keep)

        archived = len(to_move)
        if archived == 0:
            logger.info("[%s] no rows for %s", sheet_name, day.isoformat())
            return 0, len(keep)

        logger.info("[%s] archiving %d rows for %s", sheet_name, archived, day.isoformat())

        if dry_run:
            return archived, len(keep)

        arch = _ensure_archive_sheet(sheets, header)
        sheets._request_with_retry(arch.append_rows, to_move, value_input_option="USER_ENTERED")

        new_data = [header] + keep if keep else [header]
        sheets._request_with_retry(ws.clear)
        sheets._request_with_retry(ws.update, "A1", new_data)

        return archived, len(keep)
    except Exception as e:
        logger.exception("Failed to process sheet %s: %s", sheet_name, e)
        return 0, 0


def run_archive(target_date: Optional[str] = None, dry_run: bool = False, only_sheet: Optional[str] = None) -> None:
    """
    Archive rows for yesterday (or for specific date YYYY-MM-DD) from WorkLog sheets to Archive.
    - If `only_sheet` is provided, process only that sheet.
    - Otherwise process WORKLOG_SHEET and all 'WorkLog_*' sheets that exist.
    """
    sheets = SheetsAPI()

    if target_date:
        try:
            day = datetime.strptime(target_date, "%Y-%m-%d").date()
        except Exception:
            raise SystemExit("Invalid --date format. Use YYYY-MM-DD")
    else:
        day = _yesterday_local()

    titles: List[str] = []
    try:
        titles = sheets.list_worksheet_titles()
    except Exception:
        pass

    candidates: List[str] = []
    if only_sheet:
        if only_sheet not in titles:
            raise SystemExit(f"Sheet '{only_sheet}' not found in {GOOGLE_SHEET_NAME}")
        candidates = [only_sheet]
    else:
        for t in titles:
            if t == WORKLOG_SHEET or t.startswith(f"{WORKLOG_SHEET}_"):
                candidates.append(t)

    if not candidates:
        logger.warning("No WorkLog-like sheets found. Nothing to do.")
        return

    total_archived = 0
    for name in candidates:
        a, _k = _process_sheet(sheets, name, day, dry_run=dry_run)
        total_archived += a

    if dry_run:
        logger.info("DRY-RUN complete. Would archive %d rows total for %s.", total_archived, day.isoformat())
    else:
        logger.info("Archive complete. Archived %d rows total for %s.", total_archived, day.isoformat())


def main():
    ap = argparse.ArgumentParser(description="Archive yesterday's rows from WorkLog sheets to Archive via SheetsAPI.")
    ap.add_argument("--date", help="Target date YYYY-MM-DD (default: yesterday in local tz)", default=None)
    ap.add_argument("--dry-run", action="store_true", help="Do not modify sheets, just report.")
    ap.add_argument("--only-sheet", help="Process only given sheet name", default=None)
    args = ap.parse_args()
    run_archive(target_date=args.date, dry_run=args.dry_run, only_sheet=args.only_sheet)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: auto_sync.py
# SIZE: 22760 bytes | SHA256(text): ae8962e4c852506b031ec63650b245dbc6fd3c1cb39b170bc47cc10c23553088
--------------------------------------------------------------------------------
import sys
import logging
import time
import signal
from datetime import datetime
from threading import Event, RLock, Thread
from pathlib import Path
from typing import Dict, List, Optional
import socket
from time import monotonic

PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from PyQt5.QtCore import QObject, pyqtSignal
except ImportError:
    logging.warning("PyQt5 не найден. Сигналы GUI не будут работать. Запуск в режиме CLI.")
    class QObject: pass
    class pyqtSignal:
        def __init__(self): pass
        def emit(self, *args, **kwargs): pass

try:
    from config import (
        SYNC_INTERVAL,
        API_MAX_RETRIES,
        SYNC_BATCH_SIZE,
        SYNC_RETRY_STRATEGY,
        SYNC_INTERVAL_ONLINE,
        SYNC_INTERVAL_OFFLINE_RECOVERY
    )
    from user_app.db_local import LocalDB
    from sheets_api import sheets_api
    from sync.network import is_internet_available
except ImportError as e:
    logging.error(f"Ошибка импорта модулей: {e}")
    raise

logger = logging.getLogger(__name__)

PING_PORT = 43333
PING_TIMEOUT = 3600  # 1 час

class SyncSignals(QObject):
    force_logout = pyqtSignal()
    sync_status_updated = pyqtSignal(dict)

class SyncManager(QObject):
    def __init__(self, signals: Optional[SyncSignals] = None, background_mode: bool = True):
        super().__init__()
        logger.info(f"Инициализация SyncManager: background_mode={background_mode}")
        self._db = LocalDB()
        self._db_lock = RLock()
        self._stop_event = Event()
        self.signals = signals
        self._background_mode = background_mode
        self._sync_interval = SYNC_INTERVAL if background_mode else 0
        self._last_sync_time = None
        self._is_offline_recovery = False  # Флаг для режима восстановления
        self._stats = {
            'total_synced': 0,
            'last_sync': None,
            'last_duration': 0,
            'success_rate': 1.0,
            'queue_size': 0
        }
        self._last_ping = time.time()
        self._last_loop_started = monotonic()
        if background_mode:
            self._ping_thread = Thread(target=self._ping_listener, daemon=True)
            self._ping_thread.start()
            logger.debug("Ping listener поток запущен")

    def _check_remote_commands(self):
        logger.info("=== ПРОВЕРКА КОМАНД ===")
        if not is_internet_available():
            logger.debug("Проверка удаленных команд невозможна: нет интернета.")
            return

        with self._db_lock:
            email = self._db.get_current_user_email()
            logger.debug(f"Текущий email пользователя: {email}")
            session = self._db.get_active_session(email) if email else None
            session_id = session["session_id"] if session else None
            logger.debug(f"Активная сессия: session_id={session_id}")

        if not email or not session_id:
            logger.debug("Нет активной сессии для проверки удаленных команд.")
            return

        try:
            logger.info(f"Проверка статуса сессии для пользователя {email}, session_id: {session_id}")
            remote_status = self._check_user_session_status(email, session_id)
            logger.debug(f"Получен удаленный статус: {remote_status}")
            
            if remote_status == "kicked":
                logger.info(f"[ADMIN_LOGOUT] Обнаружен статус 'kicked' для пользователя {email}. Испускаем force_logout.")
                if self.signals:
                    self.signals.force_logout.emit()
                # Отправляем ACK подтверждение команды
                try:
                    sheets_api.ack_remote_command(email=email, session_id=session_id)
                    logger.info(f"ACK отправлен для команды kick пользователя {email}")
                except Exception as ack_error:
                    logger.error(f"Ошибка отправки ACK: {ack_error}")
                return
            elif remote_status == "finished":
                logger.warning(f"Получена команда 'finished' для пользователя {email}. Отправка сигнала в GUI.")
                if self.signals:
                    logger.info("Emit force_logout signal to GUI")
                    self.signals.force_logout.emit()
                # Отправляем ACK подтверждение команды
                try:
                    sheets_api.ack_remote_command(email=email, session_id=session_id)
                    logger.info(f"ACK отправлен для команды finished пользователя {email}")
                except Exception as ack_error:
                    logger.error(f"Ошибка отправки ACK: {ack_error}")
                # НЕ вызываем self.stop() здесь!
            else:
                logger.debug(f"Статус сессии в норме: {remote_status}")
                
        except Exception as e:
            logger.error(f"Ошибка при проверке удаленных команд для {email}: {e}", exc_info=True)

    def _check_user_session_status(self, email: str, session_id: str) -> str:
        """
        Проверяет статус указанной сессии пользователя в Google Sheets.
        Возвращает: 'active', 'kicked', 'finished', 'expired', 'unknown'
        """
        try:
            return sheets_api.check_user_session_status(email, session_id)
        except Exception as e:
            logger.error(f"Ошибка при проверке статуса сессии: {e}")
            return "unknown"

    def _ping_listener(self):
        logger.info(f"Запуск ping listener на UDP порту {PING_PORT}")
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.bind(("127.0.0.1", PING_PORT))
        s.settimeout(2)
        logger.info(f"Ping listener запущен на UDP порту {PING_PORT}")
        while not self._stop_event.is_set():
            try:
                data, addr = s.recvfrom(1024)
                logger.debug(f"Получен UDP пакет от {addr}: {data}")
                if data == b"ping":
                    self._last_ping = time.time()
                    logger.debug("Получен ping, обновлено время последнего ping")
            except socket.timeout:
                continue
            except Exception as e:
                logger.warning(f"Ошибка в ping listener: {e}", exc_info=True)
        s.close()
        logger.info("Ping listener завершен")

    def _prepare_batch(self) -> Optional[Dict[str, List[Dict]]]:
        logger.debug("Подготовка пакета данных для синхронизации")
        with self._db_lock:
            try:
                unsynced = self._db.get_unsynced_actions(SYNC_BATCH_SIZE)
                logger.debug(f"Найдено {len(unsynced)} несинхронизированных действий")
                
                if not unsynced:
                    logger.debug("Нет данных для подготовки пакета")
                    return None
                
                batch = {}
                for action in unsynced:
                    email = action[1]
                    if email not in batch:
                        batch[email] = []
                    batch[email].append({
                        'id': action[0],
                        'email': action[1],
                        'name': action[2],
                        'status': action[3],
                        'action_type': action[4],
                        'comment': action[5],
                        'timestamp': action[6],
                        'session_id': action[7],
                        'status_start_time': action[8],
                        'status_end_time': action[9],
                        'reason': action[10],        # NEW
                        'user_group': action[11],    # NEW
                    })
                
                logger.info(f"Подготовлен пакет для {len(batch)} пользователей, всего действий: {sum(len(actions) for actions in batch.values())}")
                return batch
                
            except Exception as e:
                logger.error(f"Ошибка подготовки пакета: {e}", exc_info=True)
                return None

    def _sync_batch(self, batch: Dict[str, List[Dict]]) -> bool:
        if not batch:
            logger.debug("Пустой пакет, пропускаем синхронизацию")
            return True
            
        start_time = time.time()
        total_actions = sum(len(actions) for actions in batch.values())
        success_count = 0
        synced_ids = []
        
        logger.info(f"Начало синхронизации пакета из {total_actions} действий для {len(batch)} пользователей")
        
        for email, actions in batch.items():
            logger.debug(f"Синхронизация для пользователя {email}: {len(actions)} действий")
            
            for attempt in range(API_MAX_RETRIES):
                try:
                    logger.debug(f"Попытка {attempt + 1}/{API_MAX_RETRIES} для пользователя {email}")
                    
                    if not is_internet_available():
                        logger.warning("Интернет недоступен, пропускаем синхронизацию.")
                        return False
                    
                    # Получаем группу пользователя из листа Users
                    user = sheets_api.get_user_by_email(email)
                    user_group = user.get("group") if user else None
                    
                    # Готовим список словарей для отправки
                    actions_payload = []
                    for a in actions:
                        actions_payload.append({
                            "session_id": a['session_id'],
                            "email": a['email'],
                            "name": a['name'],
                            "status": a['status'],
                            "action_type": a['action_type'],
                            "comment": a['comment'],
                            "timestamp": a['timestamp'],
                            "status_start_time": a['status_start_time'],
                            "status_end_time": a['status_end_time'],
                            "reason": a.get('reason'),
                        })

                    # Используем новую сигнатуру API с передачей user_group
                    if sheets_api.log_user_actions(actions_payload, email, user_group=user_group):
                        success_count += len(actions)
                        synced_ids.extend([a['id'] for a in actions])
                        logger.info(f"Успешно синхронизировано {len(actions)} действий для {email}")
                        break
                    else:
                        logger.warning(f"Не удалось синхронизировать действия для {email}, попытка {attempt + 1}")
                        
                except Exception as e:
                    logger.error(f"Ошибка синхронизации для {email} (попытка {attempt + 1}): {e}", exc_info=True)
                
                if attempt < API_MAX_RETRIES - 1:
                    delay = SYNC_RETRY_STRATEGY[min(attempt, len(SYNC_RETRY_STRATEGY) - 1)]
                    logger.info(f"Повторная попытка через {delay} сек...")
                    time.sleep(delay)
        
        if synced_ids:
            with self._db_lock:
                try:
                    logger.debug(f"Помечаем как синхронизированные {len(synced_ids)} записей")
                    self._db.mark_actions_synced(synced_ids)
                    logger.info(f"Успешно синхронизировано и отмечено {len(synced_ids)} записей.")
                except Exception as e:
                    logger.error(f"Ошибка обновления статуса записей в локальной БД: {e}", exc_info=True)
        
        duration = time.time() - start_time
        logger.info(f"Синхронизация завершена за {duration:.2f} сек. Успешно: {success_count}/{total_actions}")
        
        self._update_stats(success_count, total_actions, duration)
        return success_count == total_actions

    def _update_stats(self, success_count: int, total_actions: int, duration: float):
        logger.debug(f"Обновление статистики: success={success_count}, total={total_actions}, duration={duration:.2f}")
        with self._db_lock:
            self._stats['total_synced'] += success_count
            self._stats['last_sync'] = datetime.now().isoformat(timespec='seconds')
            self._stats['last_duration'] = round(duration, 3)
            if total_actions > 0:
                rate = success_count / total_actions
                self._stats['success_rate'] = 0.9 * self._stats['success_rate'] + 0.1 * rate
            self._stats['queue_size'] = self._db.get_unsynced_count()
            
        logger.debug(f"Обновленная статистика: {self._stats}")
        if self.signals:
            self.signals.sync_status_updated.emit(self._stats.copy())
            logger.debug("Сигнал sync_status_updated отправлен")

    def sync_once(self) -> bool:
        logger.info("=== ЗАПУСК РАЗОВОЙ СИНХРОНИЗАЦИИ ===")
        start = time.time()
        ok = False
        try:
            batch = self._prepare_batch()
            if not batch:
                logger.debug("Нет данных для синхронизации.")
                return True

            total_actions = sum(len(actions) for actions in batch.values())
            logger.info(f"Начало синхронизации пакета из {total_actions} записей.")

            # Если очередь очень большая, активируем режим восстановления
            if total_actions > 100 and not self._is_offline_recovery:
                self._is_offline_recovery = True
                self._sync_interval = SYNC_INTERVAL_OFFLINE_RECOVERY
                logger.info(f"Обнаружено большое количество действий ({total_actions}). Активирован режим восстановления.")

            ok = self._sync_batch(batch)
            logger.info(f"Результат разовой синхронизации: {'УСПЕХ' if ok else 'НЕУДАЧА'}")
        finally:
            elapsed = time.time() - start
            self._stats['last_sync'] = datetime.now().isoformat(timespec='seconds')
            self._stats['last_duration'] = round(elapsed, 3)
            self._stats['queue_size'] = self._db.get_unsynced_count()
            if ok:
                self._stats['total_synced'] += 1
            if self.signals:
                self.signals.sync_status_updated.emit(dict(self._stats))
        return ok

    def run_service(self):
        logger.info(f"Сервис синхронизации запущен. Интервал: {self._sync_interval} сек.")
        cycle_count = 0
        
        while not self._stop_event.is_set():
            cycle_count += 1
            self._last_loop_started = monotonic()
            logger.debug(f"=== ЦИКЛ СИНХРОНИЗАЦИИ #{cycle_count} ===")
            
            now = time.time()
            if (now - self._last_ping) > PING_TIMEOUT:
                logger.warning("Ping не получен более часа — завершаем работу сервиса.")
                break
            
            start_time = time.time()
            try:
                # Проверяем, есть ли интернет
                internet_available = is_internet_available()
                logger.debug(f"Доступность интернета: {internet_available}")
                
                if internet_available:
                    # Если интернет есть, проверяем, в каком режиме мы находимся
                    if self._is_offline_recovery:
                        # Если мы в режиме восстановления, проверяем, сколько записей осталось
                        queue_size = self._db.get_unsynced_count()
                        logger.debug(f"Режим восстановления. Размер очереди: {queue_size}")
                        
                        if queue_size < 50:  # Если осталось меньше 50 записей, считаем, что восстановление завершено
                            self._is_offline_recovery = False
                            self._sync_interval = SYNC_INTERVAL  # Возвращаемся к нормальному интервалу
                            logger.info("Режим восстановления завершен. Возвращаемся к нормальному интервалу синхронизации.")
                        else:
                            self._sync_interval = SYNC_INTERVAL_OFFLINE_RECOVERY
                    else:
                        # Нормальный режим
                        self._sync_interval = SYNC_INTERVAL_ONLINE
                else:
                    # Нет интернета — используем минимальный интервал для быстрого обнаружения его появления
                    self._sync_interval = 10
                    logger.debug("Нет интернета, установлен интервал 10 сек")

                logger.debug(f"Текущий интервал синхронизации: {self._sync_interval} сек")
                
                # Выполняем синхронизацию
                self.sync_once()
                self._check_remote_commands()
                
            except Exception as e:
                logger.critical(f"Критическая ошибка в цикле синхронизации: {e}", exc_info=True)
            
            elapsed = time.time() - start_time
            sleep_time = max(1, self._sync_interval - elapsed)
            logger.debug(f"Цикл завершен за {elapsed:.2f} сек. Ожидание {sleep_time:.2f} сек")
            
            self._stop_event.wait(sleep_time)

        logger.info("Сервис синхронизации завершён.")

    def stop(self):
        logger.info("Остановка SyncManager...")
        self._stop_event.set()
        try:
            self._db.close()
            logger.debug("База данных закрыта")
        except Exception as e:
            logger.error(f"Ошибка при закрытии БД: {e}", exc_info=True)
        logger.info("Сервис синхронизации остановлен.")

def configure_logging(background_mode: bool):
    log_file = 'auto_sync.log' if background_mode else None
    handlers = [logging.StreamHandler()]
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    # Увеличиваем уровень логирования до DEBUG для более детальной информации
    logging.basicConfig(
        level=logging.DEBUG,  # Изменено с INFO на DEBUG
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )
    
    # Для некоторых библиотеки устанавливаем более высокий уровень, чтобы избежать слишком много логов
    logging.getLogger('urllib3').setLevel(logging.INFO)
    logging.getLogger('googleapiclient').setLevel(logging.INFO)

def handle_shutdown(signum, frame):
    logger.info("Получен сигнал завершения работы (SIGTERM/SIGINT)")
    raise SystemExit("Завершение по сигналу.")

def main(background_mode: bool = True):
    configure_logging(background_mode)
    manager = None
    try:
        signal.signal(signal.SIGINT, handle_shutdown)
        signal.signal(signal.SIGTERM, handle_shutdown)

        demo_signals = SyncSignals()
        def on_force_logout():
            logger.info("--- Демонстрация: получен сигнал force_logout! Приложение должно выйти. ---")
        demo_signals.force_logout.connect(on_force_logout)

        manager = SyncManager(signals=demo_signals, background_mode=background_mode)

        if background_mode:
            logger.info("Запуск в режиме сервиса (демо)")
            manager.run_service()
        else:
            logger.info("Выполнение разовой синхронизации (демо)")
            manager.sync_once()
            manager._check_remote_commands()

    except SystemExit as e:
        logger.info(f"Завершение работы: {e}")
    except Exception as e:
        logger.critical(f"Фатальная ошибка в main: {e}", exc_info=True)
    finally:
        if manager:
            manager.stop()

if __name__ == "__main__":
    main(background_mode=True)

--------------------------------------------------------------------------------
# FILE: build_admin.py
# SIZE: 2141 bytes | SHA256(text): 61314b2fa48430cce7746bb0fdb899626af3e0abb44d0cccd4eee315f3035c98
--------------------------------------------------------------------------------
# build_admin.py
import os
import sys
import logging
import shutil
from pathlib import Path
from PyInstaller.__main__ import run

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('build_admin.log', mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info("🚀 Сборка админки...")
        app_name = "WorkTimeTracker_Admin"
        main_script = "admin_app/main_admin.py" # Путь от корня
        icon_file = "user_app/sberhealf.ico" # Используем ту же иконку

        for dir_name in ['dist', 'build']:
            if Path(dir_name).exists():
                shutil.rmtree(dir_name)
                logger.info(f"🧹 Очищена директория: {dir_name}")

        options = [
            main_script,
            f'--name={app_name}',
            '--onedir',
            '--windowed',
            '--clean',
            '--noconfirm',
            '--log-level=WARN',
            f'--icon={icon_file}' if Path(icon_file).exists() else None,
            '--paths=.', # Ключевая строка
            '--add-data=secret_creds.zip;.',
            '--add-data=config.py;.',
            '--add-data=user_app/sberhealf.png;user_app',
            '--hidden-import=auto_sync',
            '--hidden-import=sheets_api',
            '--hidden-import=user_app.db_local',
        ]

        options = [opt for opt in options if opt is not None]

        logger.info(f"⚙️  Запуск: {' '.join(options)}")
        run(options)

        exe_path = Path('dist') / app_name / f"{app_name}.exe"
        if exe_path.exists():
            logger.info(f"✅ Успех! {exe_path}")
        else:
            raise RuntimeError("Сборка прошла, но exe не найден.")

    except Exception as e:
        logger.critical(f"❌ Ошибка: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: build_user.py
# SIZE: 2979 bytes | SHA256(text): 4216f57927b7d0a06a8307c71e8e7ad393eec607de641709d5b8061c3f154ff3
--------------------------------------------------------------------------------
# build_user.py
import os
import sys
import logging
import shutil
from pathlib import Path
from PyInstaller.__main__ import run

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('build_user.log', mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info("🚀 Сборка пользовательской части...")
        app_name = "WorkTimeTracker_User"
        main_script = "user_app/main.py"
        icon_file = "user_app/sberhealf.ico"

        # Очистка
        for dir_name in ['dist', 'build']:
            if Path(dir_name).exists():
                shutil.rmtree(dir_name)
                logger.info(f"🧹 Очищена директория: {dir_name}")

        # Проверка существования файлов
        required_files = [
            'secret_creds.zip',
            'config.py',
            'auto_sync.py',
            'sheets_api.py',
            'user_app',
            'sync'
        ]
        for file in required_files:
            if not Path(file).exists():
                logger.critical(f"❌ КРИТИЧЕСКАЯ ОШИБКА: {file} не найден!")
                sys.exit(1)

        options = [
            main_script,
            f'--name={app_name}',
            '--onedir',
            '--windowed',
            '--clean',
            '--noconfirm',
            '--log-level=WARN',
            f'--icon={icon_file}' if Path(icon_file).exists() else None,
            '--paths=.',
            '--add-data=secret_creds.zip;.',
            '--add-data=config.py;.',
            '--add-data=auto_sync.py;.',
            '--add-data=sheets_api.py;.',
            '--add-data=user_app;user_app',
            '--add-data=sync;sync',
            '--hidden-import=PyQt5.sip',
            '--hidden-import=gspread',
            '--hidden-import=oauth2client',
            '--hidden-import=google.auth',
            '--hidden-import=googleapiclient',
            '--hidden-import=google.oauth2',
            '--hidden-import=googleapiclient.discovery',
            '--hidden-import=httplib2',
            '--hidden-import=OpenSSL',
            '--hidden-import=requests',
        ]

        options = [opt for opt in options if opt is not None]
        logger.info(f"⚙️ Запуск: {' '.join(options)}")
        run(options)

        exe_path = Path('dist') / app_name / f"{app_name}.exe"
        if exe_path.exists():
            logger.info(f"✅ Успех! {exe_path}")
        else:
            raise RuntimeError("Сборка прошла, но exe не найден.")

    except Exception as e:
        logger.critical(f"❌ Ошибка: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: bundle_project.py
# SIZE: 21101 bytes | SHA256(text): b6c1f1599c20041b8ed5c6b641e5fd454d41846711bd7674452a97216ce01493
--------------------------------------------------------------------------------
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
inspect_and_bundle.py — единый инструмент:
  1) Снимок дерева проекта (с исключениями)
  2) TXT-бандл исходников/конфигов
  3) Обзор локальной SQLite (схема, индексы, триггеры, счётчики, примеры)
  4) Обзор Google Sheets (книга, листы, заголовки, количество строк, примеры)

Зависимости:
  - stdlib
  - Ваш проект (config.py, sheets_api.py) — для путей/доступа к Google Sheets.
    sheets_api уже содержит «ленивый» прокси/клиент и ретраи.

Примеры:
  python inspect_and_bundle.py -r . -o project_report.txt
  python inspect_and_bundle.py -r . -o report.txt --db C:/path/to/local_backup.db
  python inspect_and_bundle.py --git-only --no-sheets
"""

from __future__ import annotations

import argparse
import hashlib
import mimetypes
import os
import sqlite3
import sys
import time
from pathlib import Path
from typing import Iterable, List, Dict, Optional, Tuple

# -----------------------------------
# 1) Настройки для дерева и бандла
# -----------------------------------

EXCLUDE_TREE = {'.venv', '__pycache__', '.git', '.idea', 'dist', 'build', '.vscode', '.mypy_cache', '.pytest_cache', '.ruff_cache', 'node_modules', 'target', 'out'}
DEFAULT_EXCLUDE_DIRS = {
    ".git", ".hg", ".svn", ".idea", ".vscode",
    ".venv", "venv", "env",
    "__pycache__", ".mypy_cache", ".pytest_cache", ".ruff_cache",
    "build", "dist", ".cache", ".eggs", ".tox", ".coverage",
    "node_modules", "target", "out"
}

# Текстовые расширения (можно расширить через --include-ext)
DEFAULT_INCLUDE_EXTS = {
    # code
    ".py", ".pyw", ".ipynb",
    ".js", ".jsx", ".ts", ".tsx", ".vue", ".svelte",
    ".java", ".kt", ".kts", ".scala", ".go", ".rb", ".php",
    ".c", ".cc", ".cpp", ".h", ".hpp", ".cs", ".rs", ".swift",
    # web / markup
    ".html", ".htm", ".css", ".scss", ".sass",
    ".xml", ".xsd", ".xslt",
    # config
    ".json", ".jsonc", ".yaml", ".yml", ".ini", ".cfg", ".toml", ".env",
    # scripts
    ".bat", ".cmd", ".ps1", ".psm1", ".sh", ".bash",
    # data-ish (text)
    ".md", ".rst", ".txt", ".csv", ".tsv", ".sql",
    # project files
    ".sln", ".csproj", ".vbproj", ".props", ".targets", ".cmake", "CMakeLists.txt",
    ".gradle", ".pro", ".pri", "Makefile", "Dockerfile", "Procfile",
}
SPECIAL_FILENAMES = {"Makefile", "Dockerfile", "Procfile", "CMakeLists.txt", ".gitignore", ".gitattributes"}

# -----------------------------------
# 2) Вспомогалки
# -----------------------------------

def normalize_extensions_set(exts: Iterable[str]) -> set[str]:
    out = set()
    for e in exts:
        e = (e or "").strip()
        if not e:
            continue
        if not e.startswith(".") and e not in SPECIAL_FILENAMES:
            e = "." + e
        out.add(e)
    return out

def is_binary_by_chunk(p: Path, chunk_size: int = 2048) -> bool:
    try:
        with p.open("rb") as f:
            chunk = f.read(chunk_size)
        if b"\x00" in chunk:
            return True
        text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7f})
        nontext = chunk.translate(None, text_chars)
        return len(nontext) / max(1, len(chunk)) > 0.30
    except Exception:
        return True

def should_include_file(p: Path, include_exts: set[str]) -> bool:
    name = p.name
    if name in SPECIAL_FILENAMES:
        return True
    ext = p.suffix
    if ext in include_exts:
        return True
    mtype, _ = mimetypes.guess_type(str(p))
    if mtype and mtype.startswith("text/"):
        return True
    return False

def sha256_of_text(s: str) -> str:
    import hashlib as _h
    return _h.sha256(s.encode("utf-8", errors="replace")).hexdigest()

def read_text_best_effort(p: Path) -> str:
    for enc in ("utf-8", "utf-8-sig", "cp1251", "latin-1"):
        try:
            return p.read_text(encoding=enc)
        except Exception:
            continue
    try:
        return p.read_bytes().decode("latin-1", errors="replace")
    except Exception:
        return ""

# -----------------------------------
# 3) Дерево проекта (в строку)
# -----------------------------------

def render_tree(dir_path: Path, prefix: str = "", exclude: set[str] = None) -> str:
    exclude = exclude or set()
    lines: List[str] = []
    try:
        entries = [e for e in os.listdir(dir_path) if e not in exclude]
    except Exception as e:
        return f"[tree] Ошибка доступа к {dir_path}: {e}\n"
    entries.sort()
    for i, name in enumerate(entries):
        path = dir_path / name
        connector = "└── " if i == len(entries) - 1 else "├── "
        lines.append(prefix + connector + name)
        if path.is_dir():
            extension = "    " if i == len(entries) - 1 else "│   "
            lines.append(render_tree(path, prefix + extension, exclude))
    return "\n".join(lines)

# -----------------------------------
# 4) Сбор файлов проекта в TXT
# -----------------------------------

def collect_files(root: Path, include_exts: set[str], exclude_dirs: set[str], max_bytes: int) -> List[Path]:
    files: List[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        dp = Path(dirpath)
        for fname in filenames:
            p = dp / fname
            try:
                if not p.is_file():
                    continue
                if p.stat().st_size > max_bytes:
                    continue
                if not should_include_file(p, include_exts):
                    continue
                if is_binary_by_chunk(p):
                    continue
                files.append(p)
            except Exception:
                continue
    files.sort(key=lambda x: str(x).lower())
    return files

def write_bundle(out, root: Path, files: List[Path]) -> None:
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    header = [
        "=" * 80,
        f"PROJECT REPORT",
        f"Generated:   {ts}",
        f"Root:        {root}",
        f"Python:      {sys.version.split()[0]}",
        f"Files:       {len(files)}",
        "=" * 80,
        ""
    ]
    out.write("\n".join(header) + "\n")
    for p in files:
        try:
            rel = p.relative_to(root)
        except Exception:
            rel = p
        try:
            text = read_text_best_effort(p)
            size = p.stat().st_size
            h = sha256_of_text(text)
            out.write("\n" + "-" * 80 + "\n")
            out.write(f"# FILE: {rel}\n")
            out.write(f"# SIZE: {size} bytes | SHA256(text): {h}\n")
            out.write("-" * 80 + "\n")
            out.write(text)
            if not text.endswith("\n"):
                out.write("\n")
        except Exception as e:
            out.write("\n" + "-" * 80 + "\n")
            out.write(f"# FILE: {rel}\n")
            out.write(f"# ERROR: {e}\n")
            out.write("-" * 80 + "\n\n")

# -----------------------------------
# 5) Инспекция SQLite
# -----------------------------------

def _sql_fetchall_safe(cur: sqlite3.Cursor, sql: str, params: Tuple = ()) -> List[Tuple]:
    try:
        cur.execute(sql, params)
        return cur.fetchall()
    except Exception:
        return []

def introspect_sqlite(db_path: Path, sample_limit: int = 5) -> str:
    out: List[str] = []
    out.append("=" * 80)
    out.append("LOCAL SQLITE OVERVIEW")
    out.append(f"DB Path: {db_path}")
    out.append("=" * 80)

    if not db_path.exists():
        out.append(f"[warn] Файл БД не найден: {db_path}")
        return "\n".join(out) + "\n"

    try:
        conn = sqlite3.connect(str(db_path))
        cur = conn.cursor()

        # Базовая инфо
        db_list = _sql_fetchall_safe(cur, "PRAGMA database_list;")
        out.append(f"database_list: {db_list}")

        # Таблицы (кроме служебных)
        tables = _sql_fetchall_safe(
            cur, "SELECT name, sql FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name;"
        )
        for name, create_sql in tables:
            out.append("-" * 80)
            out.append(f"[TABLE] {name}")
            out.append(f"schema: {create_sql}")

            # Колонки
            cols = _sql_fetchall_safe(cur, f"PRAGMA table_info({name});")
            if cols:
                out.append("columns:")
                for cid, cname, ctype, notnull, dflt, pk in cols:
                    out.append(f"  - {cname} {ctype or ''} NOTNULL={notnull} PK={pk} DEFAULT={dflt}")

            # Индексы
            idxs = _sql_fetchall_safe(cur, f"PRAGMA index_list({name});")
            if idxs:
                out.append("indexes:")
                for idx in idxs:
                    iname = idx[1]
                    unique = idx[2]
                    out.append(f"  - {iname} UNIQUE={unique}")
                    idxcols = _sql_fetchall_safe(cur, f"PRAGMA index_info({iname});")
                    for _, seqno, cname in idxcols:
                        out.append(f"      * {seqno}: {cname}")

            # Триггеры по таблице
            trigs = _sql_fetchall_safe(
                cur, "SELECT name, sql FROM sqlite_master WHERE type='trigger' AND tbl_name=? ORDER BY name;", (name,)
            )
            if trigs:
                out.append("triggers:")
                for tname, tsql in trigs:
                    out.append(f"  - {tname}: {tsql}")

            # Счётчик строк
            cnt = _sql_fetchall_safe(cur, f"SELECT COUNT(*) FROM {name};")
            if cnt:
                out.append(f"rows_count: {cnt[0][0]}")

            # Примеры строк
            samples = _sql_fetchall_safe(cur, f"SELECT * FROM {name} ORDER BY ROWID DESC LIMIT {int(sample_limit)};")
            if samples:
                out.append("sample rows (last):")
                for row in samples:
                    out.append(f"  • {row}")

        # Глобальные триггеры
        gtrigs = _sql_fetchall_safe(cur, "SELECT name, tbl_name, sql FROM sqlite_master WHERE type='trigger' ORDER BY name;")
        if gtrigs:
            out.append("-" * 80)
            out.append("[TRIGGERS GLOBAL]")
            for name, tbl, sql in gtrigs:
                out.append(f"  - {name} on {tbl}: {sql}")

        conn.close()
    except Exception as e:
        out.append(f"[error] Ошибка открытия/чтения SQLite: {e}")

    out.append("")
    return "\n".join(out)

# -----------------------------------
# 6) Инспекция Google Sheets
# -----------------------------------

def introspect_gsheets(sample_limit: int = 3) -> str:
    """
    Пытается импортировать ваш sheets_api и построить обзор книги:
      - Название книги из config
      - Список листов
      - Заголовок каждой таблицы
      - Кол-во непустых строк (по get_all_values)
      - Первые sample_limit строк
    """
    out: List[str] = []
    out.append("=" * 80)
    out.append("GOOGLE SHEETS OVERVIEW")
    out.append("=" * 80)

    try:
        # Импортируем ленивый прокси/клиент из вашего проекта
        # В проекте есть методы list_worksheet_titles(), get_users(), get_all_active_sessions() и т.п. :contentReference[oaicite:2]{index=2}
        import importlib

        try:
            sheets_mod = importlib.import_module("sheets_api")
        except Exception as e:
            out.append(f"[warn] Не удалось импортировать sheets_api: {e}")
            return "\n".join(out) + "\n"

        # Возьмём реальный инстанс
        if hasattr(sheets_mod, "get_sheets_api"):
            sheets = sheets_mod.get_sheets_api()
        elif hasattr(sheets_mod, "SheetsAPI"):
            sheets = sheets_mod.SheetsAPI()
        else:
            out.append("[warn] sheets_api не содержит SheetsAPI/get_sheets_api")
            return "\n".join(out) + "\n"

        # Заголовок и листы
        try:
            from config import GOOGLE_SHEET_NAME  # имя книги хранится в конфиге :contentReference[oaicite:3]{index=3}
        except Exception:
            GOOGLE_SHEET_NAME = "(см. config)"

        out.append(f"Spreadsheet: {GOOGLE_SHEET_NAME}")

        titles: List[str] = []
        try:
            titles = list(sheets.list_worksheet_titles())
        except Exception as e:
            out.append(f"[warn] list_worksheet_titles error: {e}")

        if not titles:
            out.append("[warn] Листы не найдены или нет доступа.")
            return "\n".join(out) + "\n"

        for t in titles:
            out.append("-" * 80)
            out.append(f"[SHEET] {t}")

            try:
                ws = sheets._get_ws(t)  # внутренний helper у вас есть
            except Exception:
                # fallback: через клиент
                try:
                    ss = sheets.client.open(GOOGLE_SHEET_NAME)
                    ws = ss.worksheet(t)
                except Exception as e:
                    out.append(f"  [warn] Не удалось открыть лист '{t}': {e}")
                    continue

            # Заголовок
            try:
                header = sheets._request_with_retry(lambda: ws.row_values(1))
                out.append(f"header: {header}")
            except Exception as e:
                out.append(f"  [warn] header read error: {e}")
                header = []

            # Все значения, чтобы посчитать заполненные строки (без пустых хвостов)
            values: List[List[str]] = []
            try:
                values = sheets._request_with_retry(lambda: ws.get_all_values())
            except Exception as e:
                out.append(f"  [warn] get_all_values error: {e}")

            if values:
                # Непустые строки (грубая оценка)
                nonempty = [r for r in values[1:] if any((c or "").strip() for c in r)]
                out.append(f"rows_count (non-empty): {len(nonempty)}")
                # Примеры первых N
                if nonempty:
                    out.append(f"sample rows (first {sample_limit}):")
                    for row in nonempty[:sample_limit]:
                        out.append("  • " + str(row))

    except Exception as e:
        out.append(f"[error] Ошибка обзора Google Sheets: {e}")

    out.append("")
    return "\n".join(out)

# -----------------------------------
# 7) Главная функция/CLI
# -----------------------------------

def main():
    ap = argparse.ArgumentParser(description="Собрать отчёт по проекту (дерево, бандл, SQLite, Google Sheets).")
    ap.add_argument("-r", "--root", type=str, default=".", help="Корень проекта (default .)")
    ap.add_argument("-o", "--output", type=str, default="project_report.txt", help="Путь к выходному TXT.")
    ap.add_argument("--max-bytes", type=int, default=3_000_000, help="Макс. размер одного файла (байт).")
    ap.add_argument("--include-ext", type=str, nargs="*", default=None, help="Доп. расширения (py toml conf ...)")
    ap.add_argument("--exclude-dir", type=str, nargs="*", default=None, help="Доп. каталоги для исключения (имена).")
    ap.add_argument("--git-only", action="store_true", help="Собирает только файлы, отслеживаемые Git.")
    ap.add_argument("--no-tree", action="store_true", help="Не добавлять дерево проекта.")
    ap.add_argument("--no-db", action="store_true", help="Не добавлять обзор SQLite.")
    ap.add_argument("--no-sheets", action="store_true", help="Не добавлять обзор Google Sheets.")
    ap.add_argument("--db", type=str, default=None, help="Путь к SQLite (иначе возьмём из config.LOCAL_DB_PATH).")
    ap.add_argument("--db-sample", type=int, default=5, help="Количество строк-примеров из таблиц SQLite.")
    ap.add_argument("--sheets-sample", type=int, default=3, help="Количество строк-примеров из листов Google Sheets.")

    args = ap.parse_args()

    root = Path(args.root).resolve()
    out_path = Path(args.output).resolve()
    out_path.parent.mkdir(parents=True, exist_ok=True)

    include_exts = set(DEFAULT_INCLUDE_EXTS)
    if args.include_ext:
        include_exts |= normalize_extensions_set(set(args.include_ext))

    exclude_dirs = set(DEFAULT_EXCLUDE_DIRS)
    if args.exclude_dir:
        exclude_dirs |= set(args.exclude_dir)

    # --- Подготовим список файлов ---
    if args.git_only:
        try:
            import subprocess
            res = subprocess.run(
                ["git", "ls-files"],
                check=True,
                cwd=str(root),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding="utf-8",
            )
            files = []
            tracked = [root / line.strip() for line in res.stdout.splitlines() if line.strip()]
            for p in tracked:
                try:
                    if not p.exists() or not p.is_file():
                        continue
                    if p.stat().st_size > args.max_bytes:
                        continue
                    if not should_include_file(p, include_exts):
                        continue
                    if is_binary_by_chunk(p):
                        continue
                    files.append(p)
                except Exception:
                    continue
            files.sort(key=lambda x: str(x).lower())
        except Exception as e:
            print(f"[WARN] git-only режим не удался: {e}. Переход к файловому обходу.", file=sys.stderr)
            files = collect_files(root, include_exts, exclude_dirs, args.max_bytes)
    else:
        files = collect_files(root, include_exts, exclude_dirs, args.max_bytes)

    # --- Путь к локальной БД ---
    db_path: Optional[Path] = None
    if not args.no_db:
        if args.db:
            db_path = Path(args.db)
        else:
            # Попробуем достать из config.LOCAL_DB_PATH (у вас так и сделано в проекте) :contentReference[oaicite:4]{index=4}
            try:
                import importlib
                cfg = importlib.import_module("config")
                db_path = Path(getattr(cfg, "LOCAL_DB_PATH"))
            except Exception:
                # Фолбэк — ищем *.db рядом
                candidates = list(root.glob("**/*.db"))
                db_path = candidates[0] if candidates else None

    # --- Запись отчёта ---
    with out_path.open("w", encoding="utf-8", newline="\n") as out:
        # Шапка + TREE
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        out.write("=" * 80 + "\n")
        out.write("PROJECT SNAPSHOT\n")
        out.write(f"Generated:   {ts}\n")
        out.write(f"Root:        {root}\n")
        out.write(f"Python:      {sys.version.split()[0]}\n")
        out.write("=" * 80 + "\n\n")

        if not args.no_tree:
            out.write("=" * 80 + "\n")
            out.write("PROJECT TREE\n")
            out.write("=" * 80 + "\n")
            out.write(render_tree(root, exclude=EXCLUDE_TREE))
            out.write("\n\n")

        # DB overview
        if not args.no_db and db_path:
            out.write(introspect_sqlite(db_path, sample_limit=args.db_sample))

        # Sheets overview
        if not args.no_sheets:
            out.write(introspect_gsheets(sample_limit=args.sheets_sample))

        # Бандл исходников
        write_bundle(out, root, files)

    print(f"✓ Готово: {out_path}")

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: config.py
# SIZE: 13794 bytes | SHA256(text): 2c1974d45eb66463e295ed01cce1a7b722213ca30c9967b4f06f69f00f148742
--------------------------------------------------------------------------------
# config.py
import os
import sys
import platform
from pathlib import Path
from typing import Dict, List, Set, Optional
from contextlib import contextmanager
import atexit

# ==================== Загрузка переменных окружения из .env ====================
from dotenv import load_dotenv
load_dotenv()

# ==================== Импорт для работы с зашифрованным credentials ====================
import pyzipper
import tempfile

# ==================== Базовые настройки ====================
if getattr(sys, 'frozen', False):
    # Режим сборки (PyInstaller)
    BASE_DIR = Path(sys.executable).parent
else:
    # Режим разработки
    BASE_DIR = Path(__file__).parent.absolute()

# --- Исправлено: Создаем LOG_DIR сразу ---
if platform.system() == "Windows":
    LOG_DIR = Path(os.getenv('APPDATA')) / "WorkTimeTracker" / "logs"
else:
    LOG_DIR = Path.home() / ".local" / "share" / "WorkTimeTracker" / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True) # Создаем при импорте модуля
# ---

# ==================== Пути к файлам ====================
# Настройки для зашифрованного архива с credentials
CREDENTIALS_ZIP = BASE_DIR / 'secret_creds.zip'  # архив должен лежать рядом с exe

# Пароль берётся из переменной окружения
CREDENTIALS_ZIP_PASSWORD = os.getenv("CREDENTIALS_ZIP_PASSWORD")
if CREDENTIALS_ZIP_PASSWORD is None:
    raise RuntimeError("CREDENTIALS_ZIP_PASSWORD не найден в .env файле!")
CREDENTIALS_ZIP_PASSWORD = CREDENTIALS_ZIP_PASSWORD.encode('utf-8')

# --- Ленивая загрузка credentials ---
_CREDS_TMP_DIR = Path(tempfile.gettempdir()) / "wtt_creds"
_CREDS_TMP_DIR.mkdir(parents=True, exist_ok=True)
_CREDENTIALS_FILE: Optional[Path] = None

def _cleanup_credentials():
    """Удаляет временный файл с учетными данными при выходе из процесса."""
    try:
        if _CREDENTIALS_FILE and _CREDENTIALS_FILE.exists():
            _CREDENTIALS_FILE.unlink()
    except Exception:
        pass

# Регистрируем очистку при выходе
atexit.register(_cleanup_credentials)

@contextmanager
def credentials_path() -> Path:
    """
    Лениво и временно извлекает service_account.json из зашифрованного ZIP.
    Используйте: with credentials_path() as p: ...
    """
    global _CREDENTIALS_FILE
    
    # Если файл уже извлечен и существует, используем его
    if _CREDENTIALS_FILE and _CREDENTIALS_FILE.exists():
        yield _CREDENTIALS_FILE
        return
    
    # Проверяем существование ZIP-архива
    if not CREDENTIALS_ZIP.exists():
        raise FileNotFoundError(f"Zip с credentials не найден: {CREDENTIALS_ZIP}")
    
    # Извлекаем файл из зашифрованного архива
    with pyzipper.AESZipFile(CREDENTIALS_ZIP) as zf:
        zf.pwd = CREDENTIALS_ZIP_PASSWORD
        try:
            data = zf.read('service_account.json')
        except KeyError:
            raise FileNotFoundError("Файл 'service_account.json' не найден в архиве")
        
        # Сохраняем во временный файл
        temp_file = _CREDS_TMP_DIR / 'service_account.json'
        with open(temp_file, 'wb') as f:
            f.write(data)
        
        _CREDENTIALS_FILE = temp_file
        yield _CREDENTIALS_FILE

def get_credentials_file() -> Path:
    """Обратная совместимость: получить путь к JSON (извлечёт при первом вызове)."""
    with credentials_path() as p:
        return Path(p)

LOCAL_DB_PATH = BASE_DIR / 'local_backup.db'
ERROR_LOG_FILE = LOG_DIR / 'error.log'
SYNC_LOG_FILE = LOG_DIR / 'sync.log'  # Добавлен лог для синхронизации

# ==================== Настройки Google Sheets ====================
GOOGLE_SHEET_NAME = "WorkLog"
USERS_SHEET = "Users"
WORKLOG_SHEET = "WorkLog"
ARCHIVE_SHEET = "Archive"
ACTIVE_SESSIONS_SHEET = "ActiveSessions"
SHIFT_CALENDAR_SHEET = ""  # опционально: 'ShiftCalendar' / 'График' если появится лист графика

# ==================== Лимиты API ====================
GOOGLE_API_LIMITS: Dict[str, int] = {
    'max_requests_per_minute': 60,
    'max_rows_per_request': 50,
    'max_cells_per_request': 10000,
    'daily_limit': 100000
}

# ==================== Настройки синхронизации ====================
SYNC_INTERVAL: int = 100
SYNC_BATCH_SIZE: int = 35
API_MAX_RETRIES: int = 5  # Увеличено количество ретраев
API_DELAY_SECONDS: float = 1.5  # Увеличен базовый интервал
SYNC_RETRY_STRATEGY: List[int] = [60, 300, 900, 1800, 3600]  # 1, 5, 15, 30, 60 минут - увеличенная стратегия

# Интервалы синхронизации для разных режимов работы
SYNC_INTERVAL_ONLINE: int = 60  # 60 секунд при нормальной работе
SYNC_INTERVAL_OFFLINE_RECOVERY: int = 300  # 300 секунд (5 минут) при восстановлении после оффлайна

# ==================== Группы обработки ====================
GROUP_MAPPING: Dict[str, str] = {
    "call": "Входящие",
    "appointment": "Запись",
    "mail": "Почта",
    "dental": "Стоматология",
    "default": "Входящие"
}

# ==================== Статусы системы ====================
STATUSES: List[str] = [
    "В работе",
    "Чат",
    "Аудио",
    "Запись",
    "Анкеты",
    "Перерыв",
    "Обед",
    "ЦИТО",
    "Обучение"
]

# Группы для интерфейса (раскладка кнопок)
STATUS_GROUPS: List[List[str]] = [
    ["В работе", "Чат", "Аудио", "Запись", "Анкеты"],   # Основная работа
    ["Перерыв", "Обед"],                                # Перерывы
    ["ЦИТО", "Обучение"]                                # Специальные
]

CONFIRMATION_STATUSES: Set[str] = {"Перерыв", "Обед", "ЦИТО"}
RESTRICTED_STATUSES_FIRST_2H: Set[str] = {"Перерыв", "Обед"}
MAX_COMMENT_LENGTH: int = 500
MAX_HISTORY_DAYS: int = 30

# ==================== Настройки безопасности ====================
PASSWORD_MIN_LENGTH: int = 8
SESSION_TIMEOUT: int = 3600  # секунды
ALLOWED_DOMAINS: List[str] = ["company.com", "sberhealth.ru"]

# ==================== Telegram уведомления ====================
TELEGRAM_BOT_TOKEN: str | None = os.getenv("8318266102:AAESpe4TIQpkTEAFuFD_ECZKWBkc5Tk32LU") or None
# Личный чат админа:
TELEGRAM_ADMIN_CHAT_ID: str | None = os.getenv("1053909260") or None
# Общий канал для групповых объявлений (может быть отрицательный id):
TELEGRAM_BROADCAST_CHAT_ID: str | None = os.getenv("TELEGRAM_BROADCAST_CHAT_ID") or None
# Анти-спам ключей (минут между одинаковыми событиями)
TELEGRAM_MIN_INTERVAL_SEC: int = int(os.getenv("TELEGRAM_MIN_INTERVAL_SEC", "600"))
# Тихие уведомления по умолчанию
TELEGRAM_SILENT: bool = os.getenv("TELEGRAM_SILENT", "0") == "1"
TELEGRAM_ALERTS_ENABLED: bool = bool(TELEGRAM_BOT_TOKEN and (TELEGRAM_ADMIN_CHAT_ID or TELEGRAM_BROADCAST_CHAT_ID))

# ==================== Архивирование ====================
ARCHIVE_DELETE_SOURCE_ROWS: bool = os.getenv("ARCHIVE_DELETE_SOURCE_ROWS", "1") == "1"

# ==================== Пороги правил уведомлений ====================
# опоздание на логин, минут
LATE_LOGIN_MINUTES: int = int(os.getenv("LATE_LOGIN_MINUTES", "15"))
# слишком частая смена статусов, штук за час
OVER_STATUS_MAX_PER_HOUR: int = int(os.getenv("OVER_STATUS_MAX_PER_HOUR", "10"))
# порог очереди несинхрона
NOTIFY_QUEUE_THRESHOLD: int = int(os.getenv("NOTIFY_QUEUE_THRESHOLD", "50"))

# ==================== Настройки мониторинга и логирования ====================
LOG_LEVEL: str = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_ROTATION_SIZE: int = 10 * 1024 * 1024  # 10MB
LOG_BACKUP_COUNT: int = 5  # Количество резервных копий логов

# ==================== Валидация конфигурации ====================
def validate_config() -> None:
    """Проверяет корректность конфигурации при запуске."""
    errors = []
    
    # Ленивая проверка учетных данных
    try:
        with credentials_path() as creds_file:
            if not creds_file.exists():
                errors.append(f"Файл учетных данных не найден: {creds_file}")
    except Exception as e:
        errors.append(f"Ошибка доступа к учетным данным: {e}")
    
    if not LOG_DIR.exists():
        try:
            LOG_DIR.mkdir(parents=True)
        except Exception as e:
            errors.append(f"Не удалось создать директорию логов: {e}")
    
    if not GROUP_MAPPING.get("default"):
        errors.append("Не определена группы по умолчанию в GROUP_MAPPING")
    
    # Проверяем наличие критически важных файлов
    if not CREDENTIALS_ZIP.exists():
        errors.append(f"Файл secret_creds.zip не найден: {CREDENTIALS_ZIP}")
    
    # Проверяем стратегию ретраев
    if len(SYNC_RETRY_STRATEGY) < 3:
        errors.append("Стратегия повторных попыток синхронизации должна содержать минимум 3 интервала")
    
    if max(SYNC_RETRY_STRATEGY) < 1800:
        errors.append("Максимальный интервал повторных попыток должен быть не менее 1800 секунд (30 минут)")
    
    if errors:
        raise ValueError("Ошибки конфигурации:\n- " + "\n- ".join(errors))

# ==================== Утилиты для работы с конфигурации ====================
def get_sync_retry_delay(attempt: int) -> int:
    """
    Возвращает задержку для повторной попытки синхронизации.
    
    Args:
        attempt: Номер попытки (начиная с 0)
    
    Returns:
        Задержка в секундах
    """
    if attempt < len(SYNC_RETRY_STRATEGY):
        return SYNC_RETRY_STRATEGY[attempt]
    return SYNC_RETRY_STRATEGY[-1]  # Последний интервал для всех последующих попыток

def should_retry_sync(error: Exception) -> bool:
    """
    Определяет, следует ли повторять попытку синхронизации при данной ошибке.
    
    Args:
        error: Исключение, которое произошло
        
    Returns:
        True если следует повторить, False если нет
    """
    # Ошибки, при которых стоит повторять попытку
    retryable_errors = [
        "ConnectionError",
        "TimeoutError",
        "HttpError",
        "ServiceUnavailable",
        "RateLimitExceeded"
    ]
    
    error_name = type(error).__name__
    return any(retryable in error_name for retryable in retryable_errors)

# ==================== Инициализация конфигурации ====================
try:
    validate_config()
    print("✓ Конфигурация успешно проверена")
    print(f"✓ Стратегия повторных попыток: {SYNC_RETRY_STRATEGY}")
except Exception as e:
    print(f"✗ Ошибка конфигурации: {e}")
    raise

# ==================== Утилиты для PyInstaller ====================
def get_resource_path(relative_path: str) -> str:
    """Возвращает абсолютный путь к ресурсу, учитывая PyInstaller."""
    if hasattr(sys, '_MEIPASS'):
        base_path = Path(sys._MEIPASS)
    else:
        base_path = BASE_DIR
    return str(base_path / relative_path)

# ==================== Константы для тестирования ====================
if __name__ == "__main__":
    print(f"BASE_DIR: {BASE_DIR}")
    print(f"LOG_DIR: {LOG_DIR}")
    print(f"CREDENTIALS_ZIP: {CREDENTIALS_ZIP}")
    print(f"SYNC_RETRY_STRATEGY: {SYNC_RETRY_STRATEGY}")
    print(f"Максимальная задержка: {max(SYNC_RETRY_STRATEGY)} секунд ({max(SYNC_RETRY_STRATEGY)/60} минут)")
    
    # Тестируем ленивую загрузку credentials
    try:
        with credentials_path() as creds:
            print(f"✓ Credentials file: {creds}")
            print(f"✓ File exists: {creds.exists()}")
    except Exception as e:
        print(f"✗ Error accessing credentials: {e}")

--------------------------------------------------------------------------------
# FILE: diagnostics_report.json
# SIZE: 10268 bytes | SHA256(text): 24d3d43f0e8dcf768c19369a3df6144f027ebd4d14aa43e3310cb20bda4f8f25
--------------------------------------------------------------------------------
{
  "ts": "2025-09-02T17:13:19",
  "log_dir": "C:\\Users\\Сергей\\AppData\\Roaming\\WorkTimeTracker\\logs",
  "credentials_file": "C:\\Temp\\wtt_creds\\service_account.json",
  "sqlite": {
    "objects": [
      {
        "name": "app_logs",
        "type": "table",
        "sql": "CREATE TABLE app_logs (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                level TEXT NOT NULL,\n                message TEXT NOT NULL\n            )"
      },
      {
        "name": "app_logs_legacy_20250826175446",
        "type": "table",
        "sql": "CREATE TABLE \"app_logs_legacy_20250826175446\" (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                level TEXT NOT NULL,\n                message TEXT NOT NULL\n            )"
      },
      {
        "name": "check_comment_length",
        "type": "trigger",
        "sql": "CREATE TRIGGER check_comment_length\n            BEFORE INSERT ON logs\n            FOR EACH ROW\n            WHEN length(NEW.comment) > 500\n            BEGIN\n                SELECT RAISE(ABORT, 'Comment too long');\n            END"
      },
      {
        "name": "idx_app_logs_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_app_logs_ts ON app_logs(ts)"
      },
      {
        "name": "idx_logs_email",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_email ON logs(email)"
      },
      {
        "name": "idx_logs_session",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_session ON logs(session_id)"
      },
      {
        "name": "idx_logs_synced",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_synced ON logs(synced)"
      },
      {
        "name": "idx_logs_timestamp",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_timestamp ON logs(timestamp)"
      },
      {
        "name": "idx_logs_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_logs_ts ON \"app_logs_legacy_20250826175446\"(ts)"
      },
      {
        "name": "idx_offline_actions_status_ts",
        "type": "index",
        "sql": "CREATE INDEX idx_offline_actions_status_ts ON offline_actions(status, ts)"
      },
      {
        "name": "logs",
        "type": "table",
        "sql": "CREATE TABLE logs (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                session_id TEXT NOT NULL,\n                email TEXT NOT NULL,\n                name TEXT NOT NULL,\n                status TEXT,\n                action_type TEXT NOT NULL,\n                comment TEXT,\n                timestamp TEXT NOT NULL,\n                synced INTEGER DEFAULT 0,\n                sync_attempts INTEGER DEFAULT 0,\n                last_sync_attempt TEXT,\n                priority INTEGER DEFAULT 1,\n                status_start_time TEXT,\n                status_end_time TEXT,\n                reason TEXT,\n                user_group TEXT\n            )"
      },
      {
        "name": "offline_actions",
        "type": "table",
        "sql": "CREATE TABLE offline_actions (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                ts TEXT NOT NULL,\n                action_type TEXT NOT NULL,\n                payload TEXT NOT NULL,  -- JSON-строка\n                status TEXT NOT NULL DEFAULT 'pending'  -- pending|synced|failed\n            )"
      },
      {
        "name": "prevent_duplicate_logout",
        "type": "trigger",
        "sql": "CREATE TRIGGER prevent_duplicate_logout\n            BEFORE INSERT ON logs\n            FOR EACH ROW\n            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (\n                SELECT 1 FROM logs\n                WHERE session_id = NEW.session_id\n                  AND LOWER(action_type) = 'logout'\n                  AND timestamp > datetime('now', '-5 minutes')\n            )\n            BEGIN\n                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');\n            END"
      },
      {
        "name": "sqlite_sequence",
        "type": "table",
        "sql": "CREATE TABLE sqlite_sequence(name,seq)"
      }
    ],
    "stats": {
      "app_logs": 0,
      "app_logs_legacy_20250826175446": 0,
      "logs": 26,
      "offline_actions": 0
    },
    "samples": {
      "app_logs": [],
      "app_logs_legacy_20250826175446": [],
      "logs": [
        [
          26,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Завершено",
          "LOGOUT",
          "Завершение смены (нормальное)",
          "2025-09-02T07:31:20.622314+00:00",
          0,
          0,
          null,
          1,
          "2025-09-02T10:31:20.622249",
          "2025-09-02T10:31:20.622249",
          "user",
          "Стоматология"
        ],
        [
          25,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Аудио",
          "STATUS_CHANGE",
          null,
          "2025-09-02T07:30:03.200596+00:00",
          1,
          1,
          "2025-09-02T07:30:05.016279+00:00",
          1,
          "2025-09-02T10:30:03.197439",
          "2025-09-02T07:31:20.619894+00:00",
          null,
          null
        ],
        [
          24,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "Чат",
          "STATUS_CHANGE",
          null,
          "2025-09-02T07:29:57.160421+00:00",
          1,
          2,
          "2025-09-02T07:30:03.496395+00:00",
          1,
          "2025-09-02T10:29:57.156445",
          "2025-09-02T10:30:03.197439",
          null,
          null
        ],
        [
          23,
          "10@ya.ru_20250902102558",
          "10@ya.ru",
          "тест стом 3",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-09-02T07:25:58.866299+00:00",
          1,
          2,
          "2025-09-02T07:29:57.501512+00:00",
          1,
          "2025-09-02T10:25:58.866228",
          "2025-09-02T10:29:57.156445",
          null,
          null
        ],
        [
          22,
          "10@ya.ru_20250901175741",
          "10@ya.ru",
          "тест стом 3",
          "Завершено",
          "LOGOUT",
          "Приложение закрыто через крестик",
          "2025-09-02T05:58:06.182047+00:00",
          0,
          0,
          null,
          1,
          "2025-09-02T08:58:06.181994",
          "2025-09-02T08:58:06.181994",
          "user",
          "Стоматология"
        ]
      ],
      "offline_actions": []
    },
    "extra": {
      "logs_unsynced": 2,
      "offline_actions_pending": 0
    }
  },
  "sheets": {
    "worksheets": [
      {
        "title": "Admins",
        "header": [
          "Login",
          "Password"
        ],
        "rows_hint": 1000,
        "cols_hint": 26
      },
      {
        "title": "Users",
        "header": [
          "Email",
          "Name",
          "Phone",
          "Role",
          "Telegram",
          "ShiftHours",
          "Hours",
          "NotifyTelegram",
          "Group"
        ],
        "rows_hint": 999,
        "cols_hint": 26
      },
      {
        "title": "Groups",
        "header": [
          "Group",
          "Sheet",
          "Statuses",
          "Возможные статусы: \"В работе\",\n    \"Чат\",\n    \"Аудио\",\n    \"Запись\",\n    \"Анкеты\",\n    \"Перерыв\",\n    \"Обед\",\n    \"ЦИТО\",\n    \"Обучение\" \nУказывать через запятую, без ковычек"
        ],
        "rows_hint": 1000,
        "cols_hint": 18
      },
      {
        "title": "WorkLog_Запись",
        "header": [
          "123@ya.ru",
          "тест записи",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-08-25T17:49:24.965579",
          "123@ya.r_20250825174924",
          "2025-08-25T17:49:24.965517"
        ],
        "rows_hint": 1000,
        "cols_hint": 20
      },
      {
        "title": "WorkLog_Входящие",
        "header": [
          "Email",
          "Name",
          "Status",
          "ActionType",
          "Comment",
          "Timestamp",
          "SessionID",
          "StatusStartTime",
          "StatusEndTime"
        ],
        "rows_hint": 28,
        "cols_hint": 20
      },
      {
        "title": "ActiveSessions",
        "header": [
          "Email",
          "Name",
          "SessionID",
          "LoginTime",
          "Status",
          "LogoutTime",
          "RemoteCommand"
        ],
        "rows_hint": 905,
        "cols_hint": 26
      },
      {
        "title": "WorkLog_Стоматология",
        "header": [
          "10@ya.ru",
          "тест стом 3",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-09-01 16:05:14",
          "10@ya.ru_20250901160514",
          "2025-09-01 19:05:14",
          "2025-09-01 16:05:20"
        ],
        "rows_hint": 775,
        "cols_hint": 18
      },
      {
        "title": "WorkLog_Почта",
        "header": [
          "7@ya.ru",
          "Тест почты",
          "В работе",
          "LOGIN",
          "Начало смены",
          "2025-08-25T14:21:50.941225",
          "7@ya.ru_20250825142150",
          "2025-08-25T14:21:50.941160"
        ],
        "rows_hint": 891,
        "cols_hint": 20
      },
      {
        "title": "AccessControl",
        "header": [
          "KeyType",
          "KeyValue",
          "AccessStatus",
          "BlockUntil",
          "Reason",
          "UpdatedAt"
        ],
        "rows_hint": 1000,
        "cols_hint": 26
      }
    ],
    "expectations": []
  }
}

--------------------------------------------------------------------------------
# FILE: pyproject.toml
# SIZE: 942 bytes | SHA256(text): 07a7e3d090a15914467ec8bda005dd0dfae354d6526669f2bbc98c7782ff9545
--------------------------------------------------------------------------------
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "work-time-tracker"
version = "0.4.0"
description = "Work Time Tracker"
authors = [{ name = "WTT Team" }]
requires-python = ">=3.10"
dependencies = [
  "PyQt5>=5.15",
  "gspread>=6.0.0",
  "google-auth>=2.0.0",
  "google-auth-oauthlib>=1.0.0",
  "requests>=2.31",
  "urllib3>=2.0",
  "python-dateutil>=2.9.0.post0",
]

[project.scripts]
wtt-user    = "user_app.main:main"
wtt-admin   = "admin_app.main_admin:main"
wtt-doctor  = "tools.doctor:main"
wtt-archive = "tools.archive_cli:main"
wtt-telebot = "telegram_bot.main:main"
wtt-send    = "tools.tg_send:main"
wtt-tg-env  = "tools.tg_envcheck:main"

[tool.setuptools.packages.find]
where   = ["."]
include = ["admin_app*", "user_app*", "sync*", "tools*", "telegram_bot*"]

[tool.setuptools]
py-modules = ["logging_setup", "config", "sheets_api"]

--------------------------------------------------------------------------------
# FILE: requirements.txt
# SIZE: 200 bytes | SHA256(text): eb1445194b8c0f11a15010dc9dc4033a0f2e331f9998654be26fb23e7e6db72a
--------------------------------------------------------------------------------
# === Core Google Sheets stack ===
gspread>=6.0.0
google-auth>=2.28.0
requests>=2.31.0

# === Desktop UI ===
PyQt5>=5.15.11

# === Config & secrets ===
python-dotenv>=1.0.1
pyzipper>=0.3.6

--------------------------------------------------------------------------------
# FILE: sheets_api.py
# SIZE: 35469 bytes | SHA256(text): 024aacb9b5e25c991ba2accfcf930f5129c28cdab18b7a28f9630a03d5cc4b21
--------------------------------------------------------------------------------
# sheets_api.py
import gspread
import time
import json
import sys
import os
import random
import logging
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from pathlib import Path
from google.auth.transport.requests import AuthorizedSession
from google.oauth2.service_account import Credentials
from dataclasses import dataclass
import threading
from zoneinfo import ZoneInfo  # stdlib (Python 3.9+)

logger = logging.getLogger("sheets_api")  # никаких handlers здесь — конфиг только в приложении


@dataclass
class QuotaInfo:
    remaining: int
    reset_time: int
    daily_used: float


class SheetsAPIError(Exception):
    def __init__(self, message: str, is_retryable: bool = False, details: str = None):
        super().__init__(message)
        self.is_retryable = is_retryable
        self.details = details
        logger.error(
            f"SheetsAPIError: {message}\n"
            f"Retryable: {is_retryable}\n"
            f"Details: {details if details else 'None'}"
        )


class SheetsAPI:
    """Синглтон-обёртка над gspread с ретраями, кэшем и batch-операциями."""
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialize()
        return cls._instance

    def _initialize(self):
        from config import get_credentials_file, GOOGLE_SHEET_NAME
        self._last_request_time = None
        self._sheet_cache: Dict[str, Any] = {}
        self._session: Optional[AuthorizedSession] = None
        self._quota_info = QuotaInfo(remaining=100, reset_time=60, daily_used=0.0)
        self._quota_lock = threading.Lock()
        try:
            logger.debug("=== SheetsAPI Initialization Debug ===")
            logger.debug(f"sys.frozen: {getattr(sys, 'frozen', False)}")
            logger.debug(f"sys._MEIPASS: {getattr(sys, '_MEIPASS', 'N/A')}")
            logger.debug(f"cwd: {os.getcwd()}")
            logger.debug(f"sys.path ok, len={len(sys.path)}")

            self.credentials_path = Path(get_credentials_file()).resolve()
            logger.info(f"Initializing with credentials: {self.credentials_path}")
            logger.debug(f"Credentials exists: {os.path.exists(self.credentials_path)}")
            if not self.credentials_path.exists():
                if getattr(sys, 'frozen', False):
                    logger.error("Running in frozen mode but credentials not found!")
                raise FileNotFoundError(f"Credentials file missing at: {self.credentials_path}")
            self._init_client()
        except Exception as e:
            logger.critical("Initialization failed", exc_info=True)
            raise SheetsAPIError(
                "Google Sheets API initialization failed",
                is_retryable=False,
                details=str(e)
            )

    # ---------- low-level client/bootstrap ----------

    def _init_client(self, max_retries: int = 3) -> None:
        for attempt in range(max_retries):
            try:
                logger.info(f"Client init attempt {attempt + 1}/{max_retries}")
                with open(self.credentials_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    required = {'type', 'project_id', 'private_key_id', 'private_key', 'client_email', 'client_id'}
                    if not required.issubset(data.keys()):
                        missing = required - set(data.keys())
                        raise ValueError(f"Missing fields in credentials: {missing}")

                scopes = [
                    "https://www.googleapis.com/auth/spreadsheets",
                    "https://www.googleapis.com/auth/drive",
                ]
                credentials = Credentials.from_service_account_file(str(self.credentials_path), scopes=scopes)
                self.client = gspread.client.Client(auth=credentials)
                # gspread >=5
                self.client.session = AuthorizedSession(credentials)
                # На некоторых версиях http_client может отсутствовать — оставляем, как было у тебя
                if hasattr(self.client, "http_client") and hasattr(self.client.http_client, "timeout"):
                    self.client.http_client.timeout = 30

                self._session = AuthorizedSession(credentials)
                # У объекта AuthorizedSession нет атрибута timeout во всех версиях,
                # но если есть — выставим.
                try:
                    self._session.timeout = 30  # type: ignore[attr-defined]
                except Exception:
                    pass

                self._test_connection()
                self._update_quota_info()
                logger.info("Google Sheets client initialized successfully")
                return
            except Exception as e:
                logger.error(f"Init attempt {attempt + 1} failed: {e}")
                if attempt == max_retries - 1:
                    logger.critical("Client init failed after max attempts")
                    raise SheetsAPIError(
                        "Failed to initialize Google Sheets client",
                        is_retryable=True,
                        details=str(e)
                    )
                wait = 2 ** attempt + 5
                logger.warning(f"Retrying in {wait} seconds...")
                time.sleep(wait)

    def _test_connection(self) -> None:
        try:
            logger.info("Testing API connection...")
            start = time.time()
            _ = list(self.client.list_spreadsheet_files())
            elapsed = time.time() - start
            logger.debug(f"API test OK in {elapsed:.2f}s")
            self._update_quota_info()
        except Exception as e:
            logger.error(f"API connection test failed: {e}")
            try:
                import urllib.request
                urllib.request.urlopen('https://www.google.com', timeout=5)
                logger.debug("Internet connection is available")
            except Exception:
                logger.error("No internet connection detected")
            raise SheetsAPIError(
                "Google Sheets API connection test failed",
                is_retryable=True,
                details=str(e)
            )

    def _update_quota_info(self) -> None:
        try:
            resp = self._session.get(  # type: ignore[union-attr]
                "https://www.googleapis.com/drive/v3/about",
                params={'fields': 'user,storageQuota'},
                timeout=10
            )
            resp.raise_for_status()
            with self._quota_lock:
                self._quota_info.remaining = int(resp.headers.get('x-ratelimit-remaining', 100))
                self._quota_info.reset_time = int(resp.headers.get('x-ratelimit-reset', 60))
                self._quota_info.daily_used = float(resp.json().get('storageQuota', {}).get('usage', 0) or 0.0)
            logger.debug(f"Quota updated: {self._quota_info}")
        except Exception as e:
            logger.warning(f"Failed to update quota info: {e}")
            with self._quota_lock:
                self._quota_info.remaining = max(1, self._quota_info.remaining)
                self._quota_info.reset_time = 60

    def _check_quota(self, required: int = 1) -> bool:
        with self._quota_lock:
            if self._quota_info.remaining >= required:
                return True
            wait_time = max(1, self._quota_info.reset_time - time.time() % self._quota_info.reset_time)
            logger.warning(f"Quota low. Waiting {wait_time:.1f}s")
        time.sleep(wait_time + 1)
        self._update_quota_info()
        with self._quota_lock:
            return self._quota_info.remaining >= required

    def _check_rate_limit(self, delay: float) -> None:
        if self._last_request_time:
            elapsed = time.time() - self._last_request_time
            if elapsed < delay:
                wait = delay - elapsed
                logger.debug(f"Rate limit: waiting {wait:.2f}s")
                time.sleep(wait)
        self._last_request_time = time.time()

    def _request_with_retry(self, func, *args, **kwargs):
        from config import API_MAX_RETRIES, API_DELAY_SECONDS, GOOGLE_API_LIMITS
        last_exc: Optional[Exception] = None
        for attempt in range(API_MAX_RETRIES):
            try:
                if not self._check_quota(required=1):
                    raise SheetsAPIError("Insufficient API quota", is_retryable=True)
                self._check_rate_limit(API_DELAY_SECONDS)
                name = getattr(func, "__name__", "<callable>")
                logger.debug(f"Attempt {attempt + 1}: {name}")
                result = func(*args, **kwargs)
                with self._quota_lock:
                    self._quota_info.remaining = max(0, self._quota_info.remaining - 1)
                return result
            except Exception as e:
                last_exc = e
                # Классификация: 429/5xx/сетевые — повторимые
                msg = str(e).lower()
                retryable = any(x in msg for x in ("rate limit", "quota", "429", "timeout", "temporarily", "unavailable", "socket"))
                if attempt == API_MAX_RETRIES - 1 or not retryable:
                    logger.error(f"Request failed after {API_MAX_RETRIES} attempts")
                    if isinstance(e, SheetsAPIError):
                        raise
                    raise SheetsAPIError(
                        f"API request failed: {e}",
                        is_retryable=True,
                        details=str(e)
                    )
                # Full jitter: base * 2^n + random(0..base)
                base = max(1.0, float(API_DELAY_SECONDS))
                wait = base * (2 ** attempt)
                wait = wait + random.uniform(0, base)
                # мягкая нормализация под минутный лимит
                per_min = max(1, GOOGLE_API_LIMITS.get("max_requests_per_minute", 60))
                min_gap = 60.0 / per_min
                wait = max(wait, min_gap)
                logger.warning(f"Retry {attempt + 1}/{API_MAX_RETRIES} in {wait:.2f}s (error: {e})")
                time.sleep(wait)
        raise last_exc or Exception("Unknown request error")

    # ---------- timezone helpers ----------

    def _get_tz(self):
        """
        Возвращает часовой пояс:
        1) config.APP_TIMEZONE или переменная окружения APP_TIMEZONE (например, 'Europe/Moscow')
        2) при ошибке — системный локальный TZ (datetime.now().astimezone().tzinfo)
        3) при отсутствии — UTC
        """
        try:
            try:
                from config import APP_TIMEZONE  # опционально
                tz_name = APP_TIMEZONE or os.getenv("APP_TIMEZONE", "Europe/Moscow")
            except Exception:
                tz_name = os.getenv("APP_TIMEZONE", "Europe/Moscow")
            try:
                return ZoneInfo(tz_name)
            except Exception:
                local_tz = datetime.now().astimezone().tzinfo
                if local_tz:
                    logger.warning(f"ZoneInfo('{tz_name}') unavailable; using system local TZ")
                    return local_tz
                logger.warning(f"ZoneInfo('{tz_name}') unavailable; fallback to UTC")
                return timezone.utc
        except Exception:
            return timezone.utc

    def _fmt_local(self, dt: Optional[datetime] = None) -> str:
        """
        Возвращает строку 'YYYY-MM-DD HH:MM:SS' в локальном TZ (для корректного парсинга в Google Sheets).
        """
        tz = self._get_tz()
        if dt is None:
            dt = datetime.now(tz)
        else:
            if dt.tzinfo is None:
                # считаем вход как UTC-метку без tzinfo
                dt = dt.replace(tzinfo=timezone.utc)
            dt = dt.astimezone(tz)
        return dt.strftime("%Y-%m-%d %H:%M:%S")

    def _ensure_local_str(self, ts: Optional[str]) -> str:
        """
        Принимает ISO-строку (в т.ч. ...Z или +00:00), возвращает локальную строку для Sheets.
        Если не удаётся распарсить — возвращает исходное значение.
        """
        if not ts:
            return self._fmt_local()
        try:
            dt = datetime.fromisoformat(ts.replace("Z", "+00:00"))
            return self._fmt_local(dt)
        except Exception:
            return ts

    # ---------- worksheet cache + discovery ----------

    def get_worksheet(self, sheet_name: str):
        from config import GOOGLE_SHEET_NAME
        if sheet_name not in self._sheet_cache:
            try:
                logger.debug(f"Opening spreadsheet: {GOOGLE_SHEET_NAME}")
                spreadsheet = self._request_with_retry(self.client.open, GOOGLE_SHEET_NAME)
                logger.debug(f"Caching worksheet: {sheet_name}")
                self._sheet_cache[sheet_name] = self._request_with_retry(spreadsheet.worksheet, sheet_name)
                logger.info(f"Worksheet '{sheet_name}' cached")
            except Exception as e:
                logger.error(f"Failed to access worksheet '{sheet_name}': {e}")
                try:
                    sheets = [ws.title for ws in spreadsheet.worksheets()]  # type: ignore[UnboundLocalVariable]
                    logger.debug(f"Available worksheets: {sheets}")
                except Exception:
                    pass
                raise SheetsAPIError(
                    f"Worksheet access error: {sheet_name}",
                    is_retryable=True,
                    details=str(e)
                )
        return self._sheet_cache[sheet_name]

    def _get_ws(self, name: str):
        """Единая точка доступа к листам (через кэш)."""
        return self.get_worksheet(name)

    def list_worksheet_titles(self) -> List[str]:
        """Список названий листов книги без лишних ошибок в логах."""
        from config import GOOGLE_SHEET_NAME
        spreadsheet = self._request_with_retry(self.client.open, GOOGLE_SHEET_NAME)
        sheets = self._request_with_retry(spreadsheet.worksheets)
        return [ws.title for ws in sheets]

    def has_worksheet(self, name: str) -> bool:
        """Проверяем существование листа по имени."""
        try:
            return name in self.list_worksheet_titles()
        except Exception:
            return False

    # ---------- helpers for tables ----------

    @staticmethod
    def _num_to_a1_col(n: int) -> str:
        s = ""
        while n:
            n, r = divmod(n - 1, 26)
            s = chr(65 + r) + s
        return s

    def _read_table(self, ws) -> List[Dict[str, str]]:
        rows = self._request_with_retry(lambda: ws.get_all_values())
        if not rows:
            return []
        header = rows[0]
        out: List[Dict[str, str]] = []
        for r in rows[1:]:
            if any((c or "").strip() for c in r):
                out.append({header[i]: (r[i] if i < len(header) else "") for i in range(len(header))})
        return out

    def _header_map(self, ws) -> Dict[str, int]:
        header = self._request_with_retry(lambda: ws.row_values(1))
        return {name: i + 1 for i, name in enumerate(header)}  # 1-based

    def _find_row_by(self, ws, col_name: str, value: str) -> Optional[int]:
        table = self._read_table(ws)
        val = (value or "").strip().lower()
        for idx, row in enumerate(table, start=2):  # +1 header, 1-based
            if (row.get(col_name, "") or "").strip().lower() == val:
                return idx
        return None

    # ---------- generic batch append ----------

    def batch_update(self, sheet_name: str, data: List[List[str]]) -> bool:
        if not data:
            logger.debug("No data to update - skipping")
            return True
        try:
            logger.info(f"Batch append -> '{sheet_name}' ({len(data)} rows)")
            ws = self._get_ws(sheet_name)
            chunk = 50
            for i in range(0, len(data), chunk):
                part = data[i:i + chunk]
                required_quota = max(1, len(part) // 10)
                if not self._check_quota(required=required_quota):
                    raise SheetsAPIError("Insufficient quota", is_retryable=True)
                self._request_with_retry(ws.append_rows, part, value_input_option='USER_ENTERED')
            logger.info(f"Batch append for '{sheet_name}' completed")
            return True
        except Exception as e:
            logger.error(f"Batch update failed for '{sheet_name}': {e}")
            raise SheetsAPIError(
                f"Failed to update worksheet: {sheet_name}",
                is_retryable=True,
                details=str(e)
            )

    # ========= USERS =========

    def get_users(self) -> List[Dict[str, str]]:
        from config import USERS_SHEET
        ws = self._get_ws(USERS_SHEET)
        return self._read_table(ws)

    def upsert_user(self, user: Dict[str, str]) -> None:
        from config import USERS_SHEET
        if not user.get("Email"):
            raise ValueError("user.Email is required")
        ws = self._get_ws(USERS_SHEET)
        hmap = self._header_map(ws)
        row_idx = self._find_row_by(ws, "Email", user["Email"])

        values = [[""] * len(hmap)]
        for k, v in user.items():
            if k in hmap:
                values[0][hmap[k] - 1] = str(v)

        if row_idx:
            left = self._num_to_a1_col(1)
            right = self._num_to_a1_col(len(hmap))
            rng = f"{left}{row_idx}:{right}{row_idx}"
            self._request_with_retry(lambda: ws.update(rng, values))
        else:
            self._request_with_retry(ws.append_rows, values, value_input_option='USER_ENTERED')

    def update_user_fields(self, email: str, fields: Dict[str, str]) -> None:
        from config import USERS_SHEET
        ws = self._get_ws(USERS_SHEET)
        hmap = self._header_map(ws)
        row_idx = self._find_row_by(ws, "Email", email)
        if not row_idx:
            raise ValueError(f"User {email} not found")

        row_vals = self._request_with_retry(lambda: ws.row_values(row_idx))
        row_vals = (row_vals + [""] * (len(hmap) - len(row_vals)))[:len(hmap)]
        for k, v in fields.items():
            if k in hmap:
                row_vals[hmap[k] - 1] = str(v)

        left = self._num_to_a1_col(1)
        right = self._num_to_a1_col(len(hmap))
        rng = f"{left}{row_idx}:{right}{row_idx}"
        self._request_with_retry(lambda: ws.update(rng, [row_vals]))

    def delete_user(self, email: str) -> bool:
        from config import USERS_SHEET
        ws = self._get_ws(USERS_SHEET)
        row_idx = self._find_row_by(ws, "Email", email)
        if not row_idx:
            return False
        self._request_with_retry(lambda: ws.delete_rows(row_idx))
        return True

    def get_user_by_email(self, email: str) -> Optional[Dict[str, str]]:
        """Быстрый поиск пользователя по email в листе Users."""
        from config import USERS_SHEET
        try:
            ws = self._get_ws(USERS_SHEET)
            table = self._read_table(ws)
            em = (email or "").strip().lower()
            for row in table:
                if (row.get("Email", "") or "").strip().lower() == em:
                    return {
                        "email": em,
                        "name": row.get("Name", ""),
                        "role": row.get("Role", "специалист"),
                        "shift_hours": row.get("ShiftHours", "8 часов"),
                        "telegram_login": row.get("Telegram", ""),
                        "group": row.get("Group", ""),
                    }
            return None
        except Exception as e:
            logger.error(f"User lookup failed for '{email}': {e}")
            raise SheetsAPIError("Failed to lookup user", is_retryable=True, details=str(e))

    # ========= ACTIVE SESSIONS =========

    def get_all_active_sessions(self) -> List[Dict[str, str]]:
        from config import ACTIVE_SESSIONS_SHEET
        ws = self._get_ws(ACTIVE_SESSIONS_SHEET)
        return self._read_table(ws)

    def get_active_session(self, email: str) -> Optional[Dict[str, str]]:
        email_lower = (email or "").strip().lower()
        for row in self.get_all_active_sessions():
            if (row.get("Email", "") or "").strip().lower() == email_lower and \
               (row.get("Status", "") or "").strip().lower() == "active":
                return row
        return None

    def set_active_session(self, email: str, name: str, session_id: str, login_time: Optional[str] = None) -> bool:
        from config import ACTIVE_SESSIONS_SHEET
        ws = self._get_ws(ACTIVE_SESSIONS_SHEET)
        lt = self._ensure_local_str(login_time)
        values = [[email, name, session_id, lt, "active", ""]]
        self._request_with_retry(ws.append_rows, values, value_input_option='USER_ENTERED')
        return True

    def check_user_session_status(self, email: str, session_id: str) -> str:
        """Статус по точному email+session_id, иначе — по последней записи email."""
        from config import ACTIVE_SESSIONS_SHEET
        ws = self._get_ws(ACTIVE_SESSIONS_SHEET)
        table = self._read_table(ws)

        em = (email or "").strip().lower()
        sid = str(session_id).strip()

        def key_fn(t):
            idx, r = t
            ts = (r.get("LoginTime") or "").strip()
            return (ts, idx)

        exact = [(i, r) for i, r in enumerate(table, start=2)
                 if (r.get("Email", "") or "").strip().lower() == em
                 and str(r.get("SessionID", "")).strip() == sid]

        if exact:
            _, row = sorted(exact, key=key_fn)[-1]
        else:
            same_email = [(i, r) for i, r in enumerate(table, start=2)
                          if (r.get("Email", "") or "").strip().lower() == em]
            if not same_email:
                return "unknown"
            _, row = sorted(same_email, key=key_fn)[-1]

        status = (row.get("Status", "") or "").strip().lower()
        return status or "unknown"

    def finish_active_session(self, email: str, session_id: str, logout_time: Optional[str] = None) -> bool:
        """Status=finished, LogoutTime=..., batch-обновление одной командой."""
        from config import ACTIVE_SESSIONS_SHEET
        ws = self._get_ws(ACTIVE_SESSIONS_SHEET)
        table = self._read_table(ws)
        em = (email or "").strip().lower()
        sid = str(session_id).strip()

        row_idx: Optional[int] = None
        for i, r in enumerate(table, start=2):
            if (r.get("Email", "") or "").strip().lower() == em and \
               str(r.get("SessionID", "")).strip() == sid and \
               (r.get("Status", "") or "").strip().lower() == "active":
                row_idx = i
                break
        if not row_idx:
            return False

        hmap = self._header_map(ws)
        lt = self._ensure_local_str(logout_time)

        cols = sorted([hmap["Status"], hmap["LogoutTime"]])
        left = self._num_to_a1_col(cols[0]); right = self._num_to_a1_col(cols[-1])
        rng = f"{left}{row_idx}:{right}{row_idx}"
        buf = [""] * (cols[-1] - cols[0] + 1)
        buf[hmap["Status"] - cols[0]] = "finished"
        buf[hmap["LogoutTime"] - cols[0]] = lt

        self._request_with_retry(lambda: ws.update(rng, [buf]))
        return True

    def kick_active_session(
        self,
        email: str,
        session_id: Optional[str] = None,
        status: str = "kicked",
        remote_cmd: str = "FORCE_LOGOUT",
        logout_time: Optional[datetime] = None
    ) -> bool:
        """
        Находит ПОСЛЕДНЮЮ активную сессию пользователя (опционально по SessionID) и
        batch-обновлением выставляет: Status, LogoutTime (локальное время), RemoteCommand.
        """
        from config import ACTIVE_SESSIONS_SHEET
        ws = self._get_ws(ACTIVE_SESSIONS_SHEET)
        table = self._read_table(ws)
        em = (email or "").strip().lower()

        candidates = [
            (i, r) for i, r in enumerate(table, start=2)
            if (r.get("Email", "") or "").strip().lower() == em
            and (r.get("Status", "") or "").strip().lower() == "active"
            and (session_id is None or str(r.get("SessionID", "")).strip() == str(session_id).strip())
        ]
        if not candidates:
            return False

        def key_fn(t):
            idx, r = t
            ts = (r.get("LoginTime") or "").strip()
            return (ts, idx)

        row_idx, _ = sorted(candidates, key=key_fn)[-1]

        hmap = self._header_map(ws)
        need = ["Status", "LogoutTime", "RemoteCommand"]
        if not all(k in hmap for k in need):
            raise RuntimeError("ActiveSessions headers missing one of: " + ", ".join(need))

        if isinstance(logout_time, datetime):
            lt = self._fmt_local(logout_time)
        else:
            lt = self._ensure_local_str(logout_time)

        ordered_cols = sorted([hmap["Status"], hmap["LogoutTime"], hmap["RemoteCommand"]])
        left = self._num_to_a1_col(ordered_cols[0])
        right = self._num_to_a1_col(ordered_cols[-1])
        rng = f"{left}{row_idx}:{right}{row_idx}"

        width = ordered_cols[-1] - ordered_cols[0] + 1
        buf = [""] * width
        buf[hmap["Status"] - ordered_cols[0]] = status
        buf[hmap["LogoutTime"] - ordered_cols[0]] = lt
        buf[hmap["RemoteCommand"] - ordered_cols[0]] = remote_cmd

        self._request_with_retry(lambda: ws.update(rng, [buf]))
        return True

    # ---------- remote command ACK helpers ----------
    def ack_remote_command(self, email: str, session_id: str) -> bool:
        """
        Помечает обработку команды на листе ActiveSessions:
        - если есть колонка RemoteCommandAck — ставим метку времени туда,
        - иначе мягко очищаем RemoteCommand (чтобы команда не срабатывала повторно).
        """
        SHEET = "ActiveSessions"
        try:
            ws = self._get_ws(SHEET)
            header = [h.strip() for h in self._request_with_retry(ws.row_values, 1)]
            # индексы нужных колонок (1-based для update_cell)
            def idx(col: str) -> int | None:
                return header.index(col) + 1 if col in header else None
            c_email = idx("Email")
            c_sess  = idx("SessionID")
            c_cmd   = idx("RemoteCommand")
            c_ack   = idx("RemoteCommandAck")  # может не быть — это нормально
            if not (c_email and c_sess and (c_cmd or c_ack)):
                logger.info("ACK: required columns are not present on %s", SHEET)
                return False
            values = self._request_with_retry(ws.get_all_values)
            # Поиск строки снизу вверх (чаще новые внизу)
            for i in range(len(values)-1, 0, -1):
                row = values[i]
                if len(row) >= max(c_email, c_sess):
                    if row[c_email-1] == email and row[c_sess-1] == session_id:
                        ts = time.strftime("%Y-%m-%d %H:%M:%S")
                        if c_ack:
                            self._request_with_retry(ws.update_cell, i+1, c_ack, ts)
                            logger.info("ACK set on %s for %s (%s)", SHEET, email, session_id)
                            return True
                        elif c_cmd:
                            # fallback: очищаем команду
                            self._request_with_retry(ws.update_cell, i+1, c_cmd, "")
                            logger.info("RemoteCommand cleared on %s for %s (%s)", SHEET, email, session_id)
                            return True
            logger.info("ACK: row not found for %s (%s)", email, session_id)
        except Exception as e:
            logger.warning("ACK failed: %s", e)
        return False

    # ========= LOGGING =========

    def _determine_user_group(self, email: str) -> str:
        """Сначала Users.Group, затем по префиксу GROUP_MAPPING, иначе 'Входящие'."""
        try:
            user = self.get_user_by_email(email)
            grp = str((user or {}).get("group", "")).strip()
            if grp:
                return grp
        except Exception as e:
            logger.warning(f"Users lookup failed while determining group for {email}: {e}")

        try:
            from config import GROUP_MAPPING
            email_prefix = str(email).split("@")[0].lower()
            for k, v in GROUP_MAPPING.items():
                if k and k.lower() in email_prefix:
                    return str(v).title()
        except Exception as e:
            logger.warning(f"Failed to determine group from GROUP_MAPPING for {email}: {e}")

        return "Входящие"

    def log_user_actions(self, actions: List[Dict[str, Any]], email: str, user_group: Optional[str] = None) -> bool:
        """
        Синхронно логирует действия пользователя в WorkLog_*.
        Формат строки: email, name, status, action_type, comment, timestamp, session_id,
                       status_start_time, status_end_time, reason
        """
        try:
            if not isinstance(email, str):
                guessed = actions[0].get("email") if actions and isinstance(actions[0], dict) else None
                email = guessed or str(email)
            email = (email or "").strip().lower()

            group = (user_group or "").strip() or self._determine_user_group(email)
            sheet_name = f"WorkLog_{group}"

            try:
                ws = self._get_ws(sheet_name)
            except SheetsAPIError:
                user = self.get_user_by_email(email) or {}
                grp2 = str(user.get("group", "")).strip()
                sheet_name = f"WorkLog_{grp2 or 'Входящие'}"
                ws = self._get_ws(sheet_name)

            values = []
            for a in actions:
                values.append([
                    a.get("email", ""),
                    a.get("name", ""),
                    a.get("status", ""),
                    a.get("action_type", ""),
                    a.get("comment", ""),
                    self._ensure_local_str(a.get("timestamp")),
                    a.get("session_id", ""),
                    self._ensure_local_str(a.get("status_start_time")),
                    self._ensure_local_str(a.get("status_end_time")),
                    a.get("reason", "")
                ])

            if values:
                self._request_with_retry(ws.append_rows, values, value_input_option='USER_ENTERED')
                logger.info(f"WorkLog appended: {sheet_name} (+{len(values)})")
                return True
            return False
        except Exception as e:
            logger.error(f"Failed to log actions to sheets: {e}")
            return False

    # ---------- back-compat for user_app ----------

    def check_credentials(self) -> bool:
        """
        Back-compat для user_app: проверяем, что есть файл creds и клиент инициализирован.
        """
        try:
            return (
                hasattr(self, "credentials_path")
                and self.credentials_path
                and os.path.exists(self.credentials_path)
                and hasattr(self, "client")
                and self.client is not None
            )
        except Exception as e:
            logger.error(f"Credentials validation error: {e}")
            return False

    # ---------- debug ----------

    def print_debug_info(self):
        print("\n=== SheetsAPI Debug Info ===")
        print(f"Credentials path: {self.credentials_path}")
        print(f"Credentials exists: {os.path.exists(self.credentials_path)}")
        print(f"Client initialized: {hasattr(self, 'client') and self.client is not None}")
        if hasattr(self, '_quota_info'):
            print(f"API Quota: {self._quota_info}")
        print("===========================\n")


# --- Lazy proxy for SheetsAPI (инициализация при первом обращении) ---

class _LazySheetsAPI:
    """
    Лёгкий прокси, который создаёт реальный экземпляр SheetsAPI при первом доступе
    к любому его атрибуту/методу. Это убирает сайд-эффекты при импорте модуля.
    """
    __slots__ = ("_inst",)

    def __init__(self):
        self._inst: Optional["SheetsAPI"] = None

    def _ensure(self) -> "SheetsAPI":
        if self._inst is None:
            # Важно: здесь используется текущая логика конструктора SheetsAPI — 
            # она сама подтянет пароль из .env и распакует зашифрованный ZIP.
            self._inst = SheetsAPI()
        return self._inst

    def __getattr__(self, name: str):
        # Проксируем любые обращения к реальному инстансу
        return getattr(self._ensure(), name)

    def __repr__(self) -> str:  # чтобы в логах было понятно, что это прокси
        return "<SheetsAPI (lazy proxy)>"


# Публичная точка входа, совместимая с существующим кодом:
sheets_api = _LazySheetsAPI()


def get_sheets_api() -> "SheetsAPI":
    """
    Опциональная фабрика для явного получения API.
    """
    return sheets_api._ensure()

--------------------------------------------------------------------------------
# FILE: sync\__init__.py
# SIZE: 0 bytes | SHA256(text): e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
# FILE: sync\network.py
# SIZE: 1074 bytes | SHA256(text): 577b3c117e6bc8688b6601dfe84071c1715b2c196fdf182426ec92a343a0166f
--------------------------------------------------------------------------------
# sync/network.py
import urllib.request
import socket
import logging

logger = logging.getLogger(__name__)

def is_internet_available(timeout: int = 3) -> bool:
    """Проверить доступность интернета."""
    try:
        logger.debug("Проверка доступности интернета...")
        # Используем google.com или любой стабильный сайт
        response = urllib.request.urlopen("https://www.google.com", timeout=timeout)
        if response.status == 200:
            logger.debug("Интернет доступен")
            return True
        else:
            logger.warning(f"Ответ сервера Google: {response.status}")
            return False
    except (urllib.error.URLError, socket.timeout) as e:
        logger.warning(f"Интернет недоступен: {e}")
        return False
    except Exception as e:
        logger.error(f"Неожиданная ошибка при проверке интернета: {e}")
        return False

--------------------------------------------------------------------------------
# FILE: sync\notifications.py
# SIZE: 2843 bytes | SHA256(text): 8aea8f9ca8bafef8de1b9835771f882c117e3f2929373f75473041a7b0d36230
--------------------------------------------------------------------------------
import logging
from PyQt5.QtWidgets import QMessageBox
from PyQt5.QtCore import Qt

logger = logging.getLogger(__name__)

class Notifier:
    @staticmethod
    def show(title: str, message: str, parent=None):
        """Показывает системное уведомление или Qt-сообщение"""
        try:
            # Сначала пробуем показать системное уведомление
            try:
                from plyer import notification
                notification.notify(
                    title=title,
                    message=message,
                    app_name='WorkLog',
                    timeout=5
                )
                return
            except ImportError:
                logger.debug("Plyer не установлен, используем Qt-уведомления")
            except Exception as e:
                logger.warning(f"Ошибка системного уведомления: {e}")

            # Fallback на Qt-сообщения
            msg = QMessageBox(parent)
            msg.setWindowFlags(Qt.WindowStaysOnTopHint)
            msg.setWindowTitle(title)
            msg.setText(message)
            msg.setIcon(QMessageBox.Information)
            msg.setStandardButtons(QMessageBox.Ok)
            msg.exec_()

        except Exception as e:
            logger.error(f"Ошибка показа уведомления: {e}")
            # Последний резервный вариант - вывод в консоль
            print(f"Уведомление: {title} - {message}")

    @staticmethod
    def show_warning(title: str, message: str, parent=None):
        """Показывает предупреждающее уведомление"""
        try:
            msg = QMessageBox(parent)
            msg.setWindowFlags(Qt.WindowStaysOnTopHint)
            msg.setWindowTitle(title)
            msg.setText(message)
            msg.setIcon(QMessageBox.Warning)
            msg.exec_()
        except Exception as e:
            logger.error(f"Ошибка показа предупреждения: {e}")
            print(f"Предупреждение: {title} - {message}")

    @staticmethod
    def show_error(title: str, message: str, parent=None):
        """Показывает уведомление об ошибке"""
        try:
            msg = QMessageBox(parent)
            msg.setWindowFlags(Qt.WindowStaysOnTopHint)
            msg.setWindowTitle(title)
            msg.setText(message)
            msg.setIcon(QMessageBox.Critical)
            msg.exec_()
        except Exception as e:
            logger.error(f"Ошибка показа ошибки: {e}")
            print(f"Ошибка: {title} - {message}")

--------------------------------------------------------------------------------
# FILE: sync\sync_queue.py
# SIZE: 12030 bytes | SHA256(text): 38c55f49e9e6fd549a3f667fa8621d2870f63800d6cef046542cb625601f231e
--------------------------------------------------------------------------------
import logging
import json
from pathlib import Path
from datetime import datetime, timedelta
from threading import Lock
from typing import List, Dict, Optional
import uuid
from config import MAX_COMMENT_LENGTH

logger = logging.getLogger(__name__)

class SyncQueue:
    """
    Очередь для хранения несинхронизированных действий с поддержкой:
    - Приоритезации запросов
    - Экспоненциального backoff
    - Группировки по пользователям
    - Сохранения состояния в файл
    """

    def __init__(self, queue_file: Path = Path("sync_queue.json")):
        self.queue_file = queue_file
        self.lock = Lock()
        logger.debug(f"Инициализация SyncQueue с файлом {self.queue_file}")
        self._load_queue()

    def _load_queue(self):
        """Загружает очередь из файла (если есть)"""
        try:
            if self.queue_file.exists():
                with open(self.queue_file, "r", encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        self.queue = data
                        logger.info(f"Очередь загружена из {self.queue_file} с {len(self.queue)} записями")
                    else:
                        self.queue = []
                        logger.warning("Неверный формат файла очереди, инициализация пустой очереди")
            else:
                self.queue = []
                logger.info("Файл очереди не найден, инициализация пустой очереди")
        except Exception as e:
            logger.error(f"Ошибка загрузки очереди: {e}")
            self.queue = []
            self._save_queue()

    def _save_queue(self):
        """Сохраняет очередь в файл"""
        try:
            with self.lock:
                with open(self.queue_file, "w", encoding='utf-8') as f:
                    json.dump(self.queue, f, ensure_ascii=False, indent=2, default=str)
            logger.debug("Очередь сохранена в файл")
        except Exception as e:
            logger.error(f"Ошибка сохранения очереди: {e}")

    def add_actions(self, actions: List[Dict]):
        """
        Добавляет действия в очередь
        Args:
            actions: Список словарей с действиями:
                {
                    'email': str,
                    'name': str,
                    'status': str,
                    'action_type': str,
                    'comment': str,
                    'timestamp': str (ISO format)
                }
        """
        if not actions:
            logger.debug("add_actions вызван с пустым списком")
            return

        with self.lock:
            for action in actions:
                # Генерируем уникальный ID для действия
                action_id = str(uuid.uuid4())
                
                # Проверяем и обрезаем комментарий
                comment = action.get('comment', '')
                if len(comment) > MAX_COMMENT_LENGTH:
                    comment = comment[:MAX_COMMENT_LENGTH]
                    logger.warning(f"Обрезан комментарий для действия {action_id}")

                # Определяем приоритет
                priority = self._determine_priority(action['action_type'])

                self.queue.append({
                    'id': action_id,
                    'email': action['email'],
                    'name': action['name'],
                    'status': action['status'],
                    'action_type': action['action_type'],
                    'comment': comment,
                    'timestamp': action['timestamp'],
                    'next_retry': datetime.now().isoformat(),
                    'retry_count': 0,
                    'priority': priority,
                    'last_attempt': None,
                    'attempts': []
                })
                logger.info(f"Добавлено действие в очередь: id={action_id}, action_type={action['action_type']}, email={action['email']}")
            self._save_queue()

    def _determine_priority(self, action_type: str) -> int:
        """Определяет приоритет действия"""
        priority_map = {
            'LOGIN': 3,      # Высокий приоритет для входов
            'LOGOUT': 3,     # Высокий приоритет для выходов
            'STATUS_CHANGE': 1  # Обычный приоритет для смен статусов
        }
        return priority_map.get(action_type, 1)

    def get_pending_actions(self, limit: int = 50) -> List[Dict]:
        """
        Возвращает готовые к отправке действия с учетом:
        - Времени следующей попытки
        - Приоритета
        - Даты создания
        """
        with self.lock:
            now = datetime.now()
            ready_actions = [
                a for a in self.queue
                if datetime.fromisoformat(a['next_retry']) <= now
            ]

            # Сортируем по приоритету (по убыванию) и времени создания (по возрастанию)
            sorted_actions = sorted(
                ready_actions,
                key=lambda x: (-x['priority'], x['timestamp'])
            )
            logger.debug(f"Получено {len(sorted_actions[:limit])} готовых к отправке действий (limit={limit})")
            return sorted_actions[:limit]

    def mark_as_attempted(self, action_ids: List[str], success: bool):
        """Обновляет статус действий после попытки синхронизации"""
        if not action_ids:
            logger.debug("mark_as_attempted вызван с пустым списком")
            return

        with self.lock:
            now = datetime.now().isoformat()
            for action in self.queue[:]:
                if action['id'] in action_ids:
                    action['last_attempt'] = now
                    action['attempts'].append({
                        'time': now,
                        'success': success
                    })

                    if success:
                        # Удаляем успешные действия из очереди
                        self.queue.remove(action)
                        logger.info(f"Удалено успешно синхронизированное действие id={action['id']}")
                    else:
                        # Увеличиваем счетчик попыток
                        action['retry_count'] += 1
                        # Устанавливаем время следующей попытки
                        action['next_retry'] = self._calculate_next_retry(
                            action['retry_count']
                        ).isoformat()
                        logger.info(f"Отмечено неудачное действие id={action['id']}, retry_count={action['retry_count']}")
            self._save_queue()

    def _calculate_next_retry(self, retry_count: int) -> datetime:
        """Вычисляет время следующей попытки с экспоненциальным backoff"""
        base_delay = min(60 * (2 ** retry_count), 86400)  # Максимум 1 день (86400 секунд)
        jitter = base_delay * 0.1  # Добавляем 10% случайности
        next_retry_time = datetime.now() + timedelta(seconds=base_delay + jitter)
        logger.debug(f"Расчет времени следующей попытки: retry_count={retry_count}, delay={base_delay}s, next_retry={next_retry_time.isoformat()}")
        return next_retry_time

    def clear_processed(self, action_ids: List[str]):
        """Удаляет обработанные действия из очереди"""
        if not action_ids:
            logger.debug("clear_processed вызван с пустым списком")
            return

        with self.lock:
            before_count = len(self.queue)
            self.queue = [a for a in self.queue if a['id'] not in action_ids]
            removed = before_count - len(self.queue)
            if removed > 0:
                logger.info(f"Удалено {removed} обработанных действий из очереди")
                self._save_queue()

    def retry_failed_actions(self, max_retries: int = 5):
        """Обновляет время повторных попыток для неудачных действий"""
        with self.lock:
            updated = 0
            for action in self.queue:
                if action['retry_count'] >= max_retries:
                    continue

                if not action['attempts'] or not action['attempts'][-1]['success']:
                    action['next_retry'] = self._calculate_next_retry(
                        action['retry_count']
                    ).isoformat()
                    updated += 1
            if updated > 0:
                logger.info(f"Обновлено время повторных попыток для {updated} действий")
                self._save_queue()

    def get_stats(self) -> Dict:
        """Возвращает статистику очереди"""
        with self.lock:
            now = datetime.now()
            pending = [
                a for a in self.queue
                if datetime.fromisoformat(a['next_retry']) <= now
            ]
            
            stats = {
                'total': len(self.queue),
                'pending': len(pending),
                'oldest': min(
                    [datetime.fromisoformat(a['timestamp']) for a in self.queue],
                    default=None
                ),
                'by_status': self._count_by_status()
            }
            logger.debug(f"Статистика очереди: {stats}")
            return stats

    def _count_by_status(self) -> Dict:
        """Считает действия по типам"""
        counts = {}
        for action in self.queue:
            typ = action['action_type']
            counts[typ] = counts.get(typ, 0) + 1
        return counts

    def clean_old_entries(self, days: int = 7):
        """Очищает старые записи старше указанного количества дней"""
        with self.lock:
            cutoff = datetime.now() - timedelta(days=days)
            initial_count = len(self.queue)
            
            self.queue = [
                a for a in self.queue
                if datetime.fromisoformat(a['timestamp']) >= cutoff
            ]
            
            removed = initial_count - len(self.queue)
            if removed > 0:
                logger.info(f"Удалено {removed} старых записей из очереди")
                self._save_queue()

    def __len__(self):
        """Возвращает количество элементов в очереди"""
        with self.lock:
            length = len(self.queue)
            logger.debug(f"Текущий размер очереди: {length}")
            return length

--------------------------------------------------------------------------------
# FILE: telegram_bot\__init__.py
# SIZE: 102 bytes | SHA256(text): 114f7efbc4ccea1547e4a90d1e9955ff1fcdfce1f131ce0cf9c4aa3f0ab84ca2
--------------------------------------------------------------------------------
# telegram_bot/__init__.py
from .notifier import TelegramNotifier

__all__ = ["TelegramNotifier"]

--------------------------------------------------------------------------------
# FILE: telegram_bot\main.py
# SIZE: 4086 bytes | SHA256(text): 0f38db9d0e5d5882bc8e3c126b6b4a18917ae62d9744b3cb9e421f64498acf11
--------------------------------------------------------------------------------
# telegram_bot/main.py
from __future__ import annotations
import logging, re, time, requests, os
from typing import Optional
from config import GOOGLE_SHEET_NAME, USERS_SHEET, TELEGRAM_BOT_TOKEN as CFG_TELEGRAM_BOT_TOKEN
from sheets_api import SheetsAPI

log = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)
EMAIL_RE = re.compile(r"^[^@\s]+@[^@\s]+\.[^@\s]+$")

def _base() -> str:
    # config → ENV
    token = (CFG_TELEGRAM_BOT_TOKEN or os.getenv("TELEGRAM_BOT_TOKEN", "")).strip()
    if not token:
        raise SystemExit(
            "TELEGRAM_BOT_TOKEN не задан. "
            "В PowerShell установите переменную так:\n"
            '$env:TELEGRAM_BOT_TOKEN = "123456:ABC..."\n'
            "Без угловых скобок."
        )
    return f"https://api.telegram.org/bot{token}"

def _send(chat_id: int | str, text: str) -> None:
    requests.post(_base()+"/sendMessage", json={"chat_id": chat_id, "text": text, "parse_mode": "HTML"}, timeout=20)

def _num_to_col(n: int) -> str:
    res = ""
    while n:
        n, r = divmod(n - 1, 26)
        res = chr(65 + r) + res
    return res

def _set_user_telegram(email: str, chat_id: int | str) -> bool:
    api = SheetsAPI()
    ws = api.client.open(GOOGLE_SHEET_NAME).worksheet(USERS_SHEET)
    header = api._request_with_retry(ws.row_values, 1) or []
    values = api._request_with_retry(ws.get_all_values) or []
    lh = [str(h or "").strip().lower() for h in header]
    if "email" not in lh:
        raise RuntimeError("В листе Users нет колонки 'Email'")
    ix_email = lh.index("email")
    ix_tg = lh.index("telegram") if "telegram" in lh else None
    row_ix = None
    for i, r in enumerate(values[1:], start=2):
        e = (r[ix_email] if ix_email < len(r) else "").strip().lower()
        if e == email:
            row_ix = i; break
    if row_ix is None:
        return False
    if ix_tg is None:
        header.append("Telegram")
        api._request_with_retry(ws.update, "A1", [header])
        ix_tg = len(header) - 1
    cell = f"{_num_to_col(ix_tg + 1)}{row_ix}"
    api._request_with_retry(ws.update, cell, str(chat_id))
    return True

def main():
    log.info("Telegram linker bot started")
    base = _base()
    offset: Optional[int] = None
    hello = ("👋 Привет! Отправь свой рабочий e-mail (например, user@company.com), "
             "и я привяжу этот чат к уведомлениям системы.")
    while True:
        try:
            params = {"timeout": 60}
            if offset is not None:
                params["offset"] = offset
            r = requests.get(base+"/getUpdates", params=params, timeout=70)
            data = r.json()
            if not data.get("ok"):
                time.sleep(2); continue
            for upd in data.get("result", []):
                offset = upd["update_id"] + 1
                msg = upd.get("message") or {}
                text = (msg.get("text") or "").strip()
                chat_id = (msg.get("chat") or {}).get("id")
                if not chat_id:
                    continue
                if text.startswith("/start"):
                    _send(chat_id, hello); continue
                if EMAIL_RE.match(text):
                    email = text.lower()
                    ok = _set_user_telegram(email, chat_id)
                    _send(chat_id, "✅ Готово! Связал <b>%s</b> с этим чатом." % email if ok
                                   else "⚠️ Не нашёл e-mail <b>%s</b> в списке пользователей." % email)
                else:
                    _send(chat_id, "Это не похоже на e-mail. Пришлите адрес вида <b>user@company.com</b>.")
        except KeyboardInterrupt:
            break
        except Exception as e:
            log.warning("Loop error: %s", e); time.sleep(3)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: telegram_bot\notifier.py
# SIZE: 8782 bytes | SHA256(text): e03a83684833b10d00512c5831de4d026bc0deb396c1ebde4f0530f157cc2c49
--------------------------------------------------------------------------------
# telegram_bot/notifier.py
from __future__ import annotations
import logging, time
from datetime import datetime, timezone
from typing import Dict, Optional, Tuple, List
import requests
import os

from config import (
    GOOGLE_SHEET_NAME,
    USERS_SHEET,
    TELEGRAM_BOT_TOKEN as CFG_TELEGRAM_BOT_TOKEN,
    TELEGRAM_ADMIN_CHAT_ID as CFG_TELEGRAM_ADMIN_CHAT_ID,
    TELEGRAM_BROADCAST_CHAT_ID as CFG_TELEGRAM_BROADCAST_CHAT_ID,
    TELEGRAM_MIN_INTERVAL_SEC as CFG_TELEGRAM_MIN_INTERVAL_SEC,
    TELEGRAM_SILENT as CFG_TELEGRAM_SILENT,
)

from sheets_api import SheetsAPI

log = logging.getLogger(__name__)
NOTIFICATIONS_LOG_SHEET = "NotificationsLog"


def _now_iso() -> str:
    return datetime.now(timezone.utc).astimezone().isoformat(timespec="seconds")


def _bool(v, default=False):
    if v is None:
        return default
    s = str(v).strip().lower()
    return s in ("1", "true", "yes", "y", "да")


class TelegramNotifier:
    """
    Три типа уведомлений:
      - service/admin → TELEGRAM_ADMIN_CHAT_ID
      - personal(email) → chat_id из Users.<Telegram/TelegramChatID/tg>
      - group/broadcast → TELEGRAM_BROADCAST_CHAT_ID с префиксом [Группа]/[Все]
    Аудит в лист NotificationsLog (создаётся автоматически).
    """
    def __init__(
        self,
        token: Optional[str] = None,
        admin_chat_id: Optional[str] = None,
        broadcast_chat_id: Optional[str] = None,
        min_interval_sec: Optional[int] = None,
        default_silent: Optional[bool] = None,
    ):
        # берём: явный аргумент → config → ENV
        self.token = (token
                      or (CFG_TELEGRAM_BOT_TOKEN or "")
                      or os.getenv("TELEGRAM_BOT_TOKEN", "")).strip()
        if not self.token:
            raise RuntimeError("TELEGRAM_BOT_TOKEN не задан.")
        self.api_url = f"https://api.telegram.org/bot{self.token}"

        self.admin_chat = str(
            admin_chat_id
            or (CFG_TELEGRAM_ADMIN_CHAT_ID or "")
            or os.getenv("TELEGRAM_ADMIN_CHAT_ID", "")
        ).strip()
        self.broadcast_chat = str(
            broadcast_chat_id
            or (CFG_TELEGRAM_BROADCAST_CHAT_ID or "")
            or os.getenv("TELEGRAM_BROADCAST_CHAT_ID", "")
        ).strip()
        self.min_interval = int(
            (min_interval_sec if min_interval_sec is not None else 0)
            or (CFG_TELEGRAM_MIN_INTERVAL_SEC if CFG_TELEGRAM_MIN_INTERVAL_SEC is not None else 0)
            or os.getenv("TELEGRAM_MIN_INTERVAL_SEC", "600")
        )
        self.default_silent = (
            _bool(CFG_TELEGRAM_SILENT)
            if default_silent is None else bool(default_silent)
        )

        self._last_sent: Dict[str, float] = {}      # анти-спам (key -> ts)
        self._links_cache: Dict[str, str] = {}      # email -> chat_id
        self._links_ts: float = 0.0
        self._links_ttl: float = 300.0              # 5 минут
        self._sheets: SheetsAPI | None = None

    # ---------- публичные API ----------
    def send_service(self, text: str, *, silent: Optional[bool] = None) -> bool:
        if not self.admin_chat:
            log.warning("TELEGRAM_ADMIN_CHAT_ID не настроен (поставьте переменную окружения или значение в config.py).")
            return False
        key = f"svc:{hash(text)}"
        if self._skip_by_rate(key):
            return False
        ok, err = self._send_text(self.admin_chat, text, silent)
        self._audit("service", f"admin:{self.admin_chat}", text, ok, err)
        return ok

    def send_personal(self, email: str, text: str, *, silent: Optional[bool] = None) -> bool:
        chat_id = self._resolve_chat_id(email)
        if not chat_id:
            self._audit("personal", f"email:{email}", text, False, "chat_id not found")
            return False
        key = f"pm:{email}:{hash(text)}"
        if self._skip_by_rate(key):
            return False
        ok, err = self._send_text(chat_id, text, silent)
        self._audit("personal", f"email:{email}", text, ok, err)
        return ok

    def send_group(self, text: str, *, group: Optional[str] = None, for_all: bool = False,
                   silent: Optional[bool] = None) -> bool:
        if not self.broadcast_chat:
            log.warning("TELEGRAM_BROADCAST_CHAT_ID не настроен.")
            return False
        tag = f"[{group}] " if (group and not for_all) else "[Все] " if for_all else ""
        payload_text = f"{tag}{text}"
        key = f"grp:{group or 'all'}:{hash(text)}"
        if self._skip_by_rate(key):
            return False
        ok, err = self._send_text(self.broadcast_chat, payload_text, silent)
        self._audit("group_all" if for_all else "group", f"chat:{self.broadcast_chat}", payload_text, ok, err)
        return ok

    # ---------- helpers ----------
    def _sheets_api(self) -> SheetsAPI:
        if self._sheets is None:
            self._sheets = SheetsAPI()
        return self._sheets

    def _skip_by_rate(self, key: str) -> bool:
        now = time.monotonic()
        last = self._last_sent.get(key, 0.0)
        if (now - last) < max(1, self.min_interval):
            log.debug("Анти-спам: пропуск %s", key)
            return True
        self._last_sent[key] = now
        return False

    def _send_text(self, chat_id: str, text: str, silent: Optional[bool]) -> Tuple[bool, Optional[str]]:
        payload = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": "HTML",
            "disable_notification": self.default_silent if silent is None else bool(silent),
        }
        try:
            r = requests.post(f"{self.api_url}/sendMessage", json=payload, timeout=20)
            data = r.json()
            if not data.get("ok", False):
                err = data.get("description") or r.text
                log.error("Telegram sendMessage error: %s", err)
                return False, err
            return True, None
        except Exception as e:
            log.exception("Telegram sendMessage exception: %s", e)
            return False, str(e)

    def _resolve_chat_id(self, email: str) -> Optional[str]:
        email = (email or "").strip().lower()
        links = self._load_links_cache()
        return links.get(email)

    def _load_links_cache(self) -> Dict[str, str]:
        if (time.monotonic() - self._links_ts) < self._links_ttl and self._links_cache:
            return self._links_cache
        try:
            api = self._sheets_api()
            ws = api.get_worksheet(USERS_SHEET)
            header = api._request_with_retry(ws.row_values, 1) or []
            values = api._request_with_retry(ws.get_all_values) or []
            lh = [str(h or "").strip().lower() for h in header]
            ix_email = lh.index("email") if "email" in lh else None
            ix_tg = None
            for name in ("telegram", "telegramchatid", "tg"):
                if name in lh:
                    ix_tg = lh.index(name); break
            cache: Dict[str, str] = {}
            if ix_email is not None and ix_tg is not None:
                for r in values[1:]:
                    e = (r[ix_email] if ix_email < len(r) else "").strip().lower()
                    c = (r[ix_tg] if ix_tg < len(r) else "").strip()
                    if e and c:
                        cache[e] = c
            self._links_cache, self._links_ts = cache, time.monotonic()
        except Exception as e:
            log.error("Не удалось загрузить Users -> Telegram: %s", e)
        return self._links_cache

    def _audit(self, kind: str, target: str, text: str, ok: bool, err: Optional[str]) -> None:
        try:
            api = self._sheets_api()
            ss = api.client.open(GOOGLE_SHEET_NAME)
            titles = [w.title for w in ss.worksheets()]
            if NOTIFICATIONS_LOG_SHEET not in titles:
                ws_new = ss.add_worksheet(title=NOTIFICATIONS_LOG_SHEET, rows=2000, cols=6)
                api._request_with_retry(ws_new.update, "A1", [["Ts","Kind","Target","Status","Preview","Error"]])
            ws = ss.worksheet(NOTIFICATIONS_LOG_SHEET)
            row = [_now_iso(), kind, target, "OK" if ok else "FAIL", (text or "")[:180], (err or "")[:180]]
            api._request_with_retry(ws.append_rows, [row], value_input_option="RAW")
        except Exception as e:
            log.debug("Аудит недоступен: %s", e)

--------------------------------------------------------------------------------
# FILE: tools\doctor.py
# SIZE: 7074 bytes | SHA256(text): 7c7ddc0de94f71a8f5f5dccc1ea06e0e47d54899fa48b80f7a02a8f096a45878
--------------------------------------------------------------------------------
# tools/doctor.py
from __future__ import annotations

import argparse
import json
import sqlite3
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

from config import LOG_DIR, get_credentials_file
from user_app.db_local import LocalDB
from sheets_api import sheets_api

# Минимальные ожидания под вашу фактическую схему:
EXPECTED = {
    "Users": ["Email", "Name", "Group"],  # базовые атрибуты пользователя
    "ActiveSessions": [
        "Email", "Name", "SessionID", "LoginTime", "Status", "LogoutTime", "RemoteCommand"
        # RemoteCommandAck — опционально (рекомендуем добавить)
    ],
}


def dump_sqlite_schema(conn: sqlite3.Connection, sample_limit: int = 5) -> Dict[str, Any]:
    cur = conn.cursor()
    cur.execute("SELECT name, type, sql FROM sqlite_master WHERE type IN ('table','index','trigger') ORDER BY name;")
    items = [{"name": n, "type": t, "sql": s} for (n, t, s) in cur.fetchall()]
    tables = [i["name"] for i in items if i["type"] == "table" and not i["name"].startswith("sqlite_")]
    stats = {}
    extra = {}
    samples = {}
    for t in tables:
        try:
            cur.execute(f"SELECT COUNT(*) FROM {t}")
            stats[t] = cur.fetchone()[0]
            cur.execute(f"SELECT * FROM {t} ORDER BY ROWID DESC LIMIT {sample_limit}")
            samples[t] = cur.fetchall()
        except Exception:
            pass
    # спец-метрики: несинхронизированные записи в очереди/логах
    try:
        if "logs" in tables:
            cur.execute("SELECT COUNT(*) FROM logs WHERE synced=0")
            extra["logs_unsynced"] = cur.fetchone()[0]
        if "offline_actions" in tables:
            cur.execute("SELECT COUNT(*) FROM offline_actions WHERE status<>'synced'")
            extra["offline_actions_pending"] = cur.fetchone()[0]
    except Exception:
        pass
    return {"objects": items, "stats": stats, "samples": samples, "extra": extra}


def dump_sheets_structure() -> Dict[str, Any]:
    client = sheets_api
    book_name = "CONFIGURED"
    data: Dict[str, Any] = {"worksheets": []}
    # перечислим листы и их заголовки
    titles = client.list_worksheet_titles()
    for t in titles:
        try:
            ws = client._get_ws(t)  # внутренняя помощ. функция допустима для диагностики
            header = [h.strip() for h in ws.row_values(1)]
            data["worksheets"].append({"title": t, "header": header, "rows_hint": ws.row_count, "cols_hint": ws.col_count})
        except Exception as e:
            data["worksheets"].append({"title": t, "error": str(e)})
    # лёгкая валидация ожидаемых колонок
    mismatches: List[Dict[str, Any]] = []
    for w in data["worksheets"]:
        if "header" not in w:
            continue
        exp = EXPECTED.get(w["title"])
        if exp:
            missing = [x for x in exp if x not in w["header"]]
            if missing:
                mismatches.append({"sheet": w["title"], "missing": missing})
    data["expectations"] = mismatches
    return data


def dump_sheets(sample_limit: int = 3) -> Dict[str, Any]:
    out = dump_sheets_structure()
    # добавим немного данных для примера
    client = sheets_api
    for ws in out["worksheets"]:
        if "error" in ws:
            continue
        try:
            title = ws["title"]
            data = client.get_worksheet_data(title, limit=sample_limit)
            ws["sample"] = data
            ws["rows_count"] = len(data)
        except Exception as e:
            ws["sample_error"] = str(e)
    return out


def render_markdown(report: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append(f"# Diagnostics Report — {report.get('ts')}")
    lines.append("")
    lines.append("## Credentials")
    cred = report.get("credentials_file", "unknown")
    lines.append(f"- State: **{cred}**")
    lines.append("")
    # SQLite
    s = report.get("sqlite", {})
    lines.append("## SQLite")
    stats = s.get("stats", {})
    if stats:
        lines.append("| Table | Rows |")
        lines.append("|---|---:|")
        for k, v in stats.items():
            lines.append(f"| {k} | {v} |")
        lines.append("")
    # Extra metrics
    extra = s.get("extra", {})
    if extra:
        lines.append("**Extra metrics:**")
        for k, v in extra.items():
            lines.append(f"- {k}: {v}")
        lines.append("")
    # Sheets
    sh = report.get("sheets", {})
    lines.append("## Google Sheets")
    problems = sh.get("expectations", [])
    if problems:
        lines.append("**Missing columns:**")
        for p in problems:
            lines.append(f"- `{p['sheet']}`: {', '.join(p['missing'])}")
        lines.append("")
    ws = sh.get("worksheets", [])
    for w in ws:
        lines.append(f"### {w.get('title','<no title>')}")
        if "error" in w:
            lines.append(f"> Error: {w['error']}")
            continue
        header = w.get("header", [])
        lines.append("**Header:** " + ", ".join(f"`{h}`" for h in header))
        lines.append(f"**Rows:** {w.get('rows_hint', 0)}")
        sample = w.get("sample", [])
        if sample:
            lines.append("")
            lines.append("```")
            for r in sample:
                lines.append(str(r))
            lines.append("```")
        lines.append("")
    return "\n".join(lines)


def run(out: Path) -> None:
    report: Dict[str, Any] = {
        "ts": datetime.now().isoformat(timespec="seconds"),
        "log_dir": str(LOG_DIR),
    }
    # creds check
    try:
        cf = get_credentials_file()
        report["credentials_file"] = str(cf)
    except Exception as e:
        report["credentials_error"] = str(e)

    # DB
    db = LocalDB()
    conn = db.conn  # type: ignore
    report["sqlite"] = dump_sqlite_schema(conn)

    # Sheets
    try:
        report["sheets"] = dump_sheets_structure()
    except Exception as e:
        report["sheets_error"] = str(e)

    out_path = Path(out)
    if out_path.suffix.lower() == ".md":
        out_path.write_text(render_markdown(report), encoding="utf-8")
    else:
        out_path.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"OK: written {out_path}")


def main():
    ap = argparse.ArgumentParser(description="WorkTimeTracker Doctor: локальная БД + структура Google Sheets + быстрая валидация.")
    ap.add_argument("-o", "--output", default="diagnostics_report.json", help="Путь к итоговому отчёту (JSON или MD).")
    args = ap.parse_args()
    run(Path(args.output))


if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: tools\tg_envcheck.py
# SIZE: 934 bytes | SHA256(text): c440e8216adcd0d3c73e5dcc8711572438f554daeea6542d1559dac8494c05e7
--------------------------------------------------------------------------------
from __future__ import annotations
import os
from config import (
    TELEGRAM_BOT_TOKEN as CFG_TELEGRAM_BOT_TOKEN,
    TELEGRAM_ADMIN_CHAT_ID as CFG_TELEGRAM_ADMIN_CHAT_ID,
    TELEGRAM_BROADCAST_CHAT_ID as CFG_TELEGRAM_BROADCAST_CHAT_ID,
)

def _mask(s: str, keep=6) -> str:
    if not s:
        return ""
    s = str(s)
    return s[:keep] + "..." if len(s) > keep else s

def main():
    print("=== TELEGRAM effective settings ===")
    tok = (CFG_TELEGRAM_BOT_TOKEN or os.getenv("TELEGRAM_BOT_TOKEN", ""))
    adm = (CFG_TELEGRAM_ADMIN_CHAT_ID or os.getenv("TELEGRAM_ADMIN_CHAT_ID", ""))
    brc = (CFG_TELEGRAM_BROADCAST_CHAT_ID or os.getenv("TELEGRAM_BROADCAST_CHAT_ID", ""))
    print("TELEGRAM_BOT_TOKEN:", "set" if tok else "EMPTY", _mask(tok))
    print("TELEGRAM_ADMIN_CHAT_ID:", adm or "<empty>")
    print("TELEGRAM_BROADCAST_CHAT_ID:", brc or "<empty>")

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: tools\tg_send.py
# SIZE: 1398 bytes | SHA256(text): 37dc26d5f8c933c8d6ac0d272e5fda8d8d6fff06f3ca056c2e09cabd7114dd20
--------------------------------------------------------------------------------
# tools/tg_send.py
from __future__ import annotations
import argparse, logging
from telegram_bot.notifier import TelegramNotifier

logging.basicConfig(level=logging.INFO)

def main():
    ap = argparse.ArgumentParser("Отправка уведомлений в Telegram")
    ap.add_argument("--type", choices=["service", "personal", "group"], required=True)
    ap.add_argument("--email", help="для personal: e-mail сотрудника")
    ap.add_argument("--group", help="для group: пометка в сообщении")
    ap.add_argument("--all", action="store_true", help="для group: отправить всем (без метки)")
    ap.add_argument("--text", required=True, help="текст (HTML допустим)")
    ap.add_argument("--silent", action="store_true", help="тихое уведомление")
    args = ap.parse_args()

    n = TelegramNotifier()
    if args.type == "service":
        ok = n.send_service(args.text, silent=args.silent)
    elif args.type == "personal":
        if not args.email: ap.error("--email обязателен для personal")
        ok = n.send_personal(args.email, args.text, silent=args.silent)
    else:
        ok = n.send_group(args.text, group=None if args.all else args.group, for_all=args.all, silent=args.silent)
    print("OK" if ok else "FAIL")

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: user_app\__init__.py
# SIZE: 0 bytes | SHA256(text): e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
# FILE: user_app\api.py
# SIZE: 1986 bytes | SHA256(text): 66effaf4453efe34f32ee113e4dfb03709c5c44d2bb0eb2855f898de8e4311d2
--------------------------------------------------------------------------------
# user_app/api.py
from __future__ import annotations
from typing import Optional, Dict, List
from sheets_api import SheetsAPI
from datetime import datetime, timezone
import uuid

class UserNotFound(Exception):
    pass

class UserAPI:
    """
    Сервис-слой user_app: вся работа с Google Sheets только через SheetsAPI.
    """
    def __init__(self, sheets: Optional[SheetsAPI] = None):
        self.sheets = sheets or SheetsAPI()

    # ---- Users ----
    def find_user(self, email: str) -> Dict:
        email = (email or "").strip().lower()
        user = self.sheets.get_user_by_email(email)
        if not user:
            raise UserNotFound(email)
        return user

    # ---- Sessions ----
    def start_session(self, email: str, name: str) -> str:
        """
        Создаёт запись в ActiveSessions (Status=active).
        Возвращает session_id.
        """
        session_id = str(uuid.uuid4())
        self.sheets.set_active_session(
            email=email,
            name=name,
            session_id=session_id,
            login_time=datetime.now(timezone.utc).isoformat()
        )
        return session_id

    def finish_session(self, email: str, session_id: str) -> bool:
        return self.sheets.finish_active_session(email=email, session_id=session_id)

    def force_logout_if_needed(self, email: str, session_id: str) -> bool:
        """
        Пулинг статуса: если админ принудительно разлогинил (Status=kicked) — вернём True.
        """
        st = self.sheets.check_user_session_status(email=email, session_id=session_id)
        return st in ("kicked", "finished")

    # ---- WorkLog ----
    def log_actions(self, actions: List[Dict], email: str, user_group: Optional[str] = None) -> bool:
        return self.sheets.log_user_actions(actions, email=email, user_group=user_group)

--------------------------------------------------------------------------------
# FILE: user_app\db_local.py
# SIZE: 20676 bytes | SHA256(text): 07a1b7e672b1fee5fac5470839188a10ed65d53bb61ec779836e57130b65fc57
--------------------------------------------------------------------------------
# user_app/db_local.py
from __future__ import annotations

import sqlite3
import threading
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import Optional, Dict, Any, Iterable, Tuple, List
import logging

from config import LOCAL_DB_PATH, MAX_COMMENT_LENGTH, MAX_HISTORY_DAYS
from user_app.db_migrations import apply_migrations

logger = logging.getLogger(__name__)


class LocalDBError(Exception):
    """Ошибки локальной БД."""


class LocalDB:
    """
    Локальная БД с полной совместимостью со старым кодом.
    Авто-открытие, самовосстановление, безопасное закрытие.
    """

    def __init__(self, db_path: Optional[str] = None) -> None:
        self.conn: Optional[sqlite3.Connection] = None
        self.db_path: Optional[Path] = None
        self._lock = threading.RLock()
        self._opened_path: Optional[Path] = None

        # автозагрузка как раньше
        self._bootstrap_open(db_path or str(LOCAL_DB_PATH))

    # ------------------------------------------------------------------ #
    # Bootstrap & lifecycle
    # ------------------------------------------------------------------ #
    def _bootstrap_open(self, primary_path: str) -> None:
        """Пробуем основной путь, затем домашний, затем ':memory:'."""
        try:
            self.open(primary_path)
            return
        except Exception as e:
            logger.error("Не удалось открыть БД по основному пути '%s': %s", primary_path, e)

        home_fallback = Path.home() / "WorkTimeTracker" / "local_backup.db"
        try:
            self.open(str(home_fallback))
            logger.warning("Используется резервный путь локальной БД: %s", home_fallback)
            return
        except Exception as e:
            logger.error("Не удалось открыть резервную БД '%s': %s", home_fallback, e)

        # крайний случай — in-memory (чтобы UI не падал)
        with self._lock:
            self.db_path = None
            self.conn = sqlite3.connect(":memory:", timeout=10, check_same_thread=False)
            self.conn.execute("PRAGMA journal_mode=MEMORY;")
            self.conn.execute("PRAGMA synchronous=OFF;")
            self.conn.execute("PRAGMA foreign_keys=ON;")
            self._ensure_schema()
            self._opened_path = None
            logger.warning("Локальная БД запущена в режиме ':memory:' (без записи на диск).")

    def open(self, db_path: str) -> None:
        with self._lock:
            self.db_path = Path(db_path).resolve()
            self.db_path.parent.mkdir(parents=True, exist_ok=True)

            logger.debug("Инициализация LocalDB по пути: %s", self.db_path)
            try:
                self.conn = sqlite3.connect(str(self.db_path), timeout=10, check_same_thread=False)
                self.conn.execute("PRAGMA journal_mode=WAL;")
                self.conn.execute("PRAGMA synchronous=NORMAL;")
                self.conn.execute("PRAGMA foreign_keys=ON;")
                self._ensure_schema()
                
                # миграции индексов (быстро и безопасно)
                try:
                    apply_migrations(self.conn)
                    logger.info("DB migrations (indexes) applied")
                except Exception as e:
                    logger.warning("DB migrations failed: %s", e)
                
                self._opened_path = self.db_path
                # профилактика
                self.cleanup_old_action_logs(days=MAX_HISTORY_DAYS)
                logger.info("Локальная БД успешно инициализирована: %s", self.db_path)
            except sqlite3.Error as e:
                self.conn = None
                raise LocalDBError(f"Ошибка инициализации БД: {e}")

    def _ensure_open(self) -> None:
        if self.conn is not None:
            return
        base = str(self._opened_path or self.db_path or LOCAL_DB_PATH)
        try:
            self.open(base)
        except Exception as e:
            logger.error("Повторное открытие БД по '%s' не удалось: %s", base, e)
            self._bootstrap_open(base)

    def close(self) -> None:
        with self._lock:
            conn = getattr(self, "conn", None)
            if conn is not None:
                try:
                    conn.commit()
                except Exception:
                    pass
                try:
                    conn.close()
                except Exception:
                    pass
            self.conn = None
            logger.info("Соединение с локальной БД закрыто")

    def __del__(self):
        try:
            self.close()
        except Exception:
            pass

    # ------------------------------------------------------------------ #
    # Schema & migration
    # ------------------------------------------------------------------ #
    def _ensure_schema(self) -> None:
        assert self.conn is not None, "База не открыта"
        cur = self.conn.cursor()

        # Если есть старая таблица logs (без нужных колонок) — переименуем
        cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='logs';")
        if cur.fetchone():
            cur.execute("PRAGMA table_info(logs);")
            cols = [r[1] for r in cur.fetchall()]
            required = {'session_id', 'email', 'name', 'action_type', 'timestamp'}
            if not required.issubset(set(cols)):
                legacy_name = f"app_logs_legacy_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                cur.execute(f"ALTER TABLE logs RENAME TO {legacy_name};")
                logger.warning("Обнаружена старая схема 'logs' — переименована в %s", legacy_name)

        # Основная таблица действий
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                email TEXT NOT NULL,
                name TEXT NOT NULL,
                status TEXT,
                action_type TEXT NOT NULL,
                comment TEXT,
                timestamp TEXT NOT NULL,
                synced INTEGER DEFAULT 0,
                sync_attempts INTEGER DEFAULT 0,
                last_sync_attempt TEXT,
                priority INTEGER DEFAULT 1,
                status_start_time TEXT,
                status_end_time TEXT,
                reason TEXT,
                user_group TEXT
            );
            """
        )

        # Индексы (безопасно: проверяем наличие колонок)
        cur.execute("PRAGMA table_info(logs);")
        cols = {r[1] for r in cur.fetchall()}
        if 'email' in cols:
            cur.execute("CREATE INDEX IF NOT EXISTS idx_logs_email ON logs(email);")
        if 'synced' in cols:
            cur.execute("CREATE INDEX IF NOT EXISTS idx_logs_synced ON logs(synced);")
        if 'timestamp' in cols:
            cur.execute("CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp);")
        if 'session_id' in cols:
            cur.execute("CREATE INDEX IF NOT EXISTS idx_logs_session ON logs(session_id);")

        # Триггеры
        cur.execute(
            f"""
            CREATE TRIGGER IF NOT EXISTS check_comment_length
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN length(NEW.comment) > {int(MAX_COMMENT_LENGTH)}
            BEGIN
                SELECT RAISE(ABORT, 'Comment too long');
            END;
            """
        )
        cur.execute(
            """
            CREATE TRIGGER IF NOT EXISTS prevent_duplicate_logout
            BEFORE INSERT ON logs
            FOR EACH ROW
            WHEN LOWER(NEW.action_type) = 'logout' AND EXISTS (
                SELECT 1 FROM logs
                WHERE session_id = NEW.session_id
                  AND LOWER(action_type) = 'logout'
                  AND timestamp > datetime('now', '-5 minutes')
            )
            BEGIN
                SELECT RAISE(ABORT, 'Duplicate LOGOUT action');
            END;
            """
        )

        # Диагностические логи приложения
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS app_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL
            );
            """
        )
        cur.execute("CREATE INDEX IF NOT EXISTS idx_app_logs_ts ON app_logs(ts);")

        self.conn.commit()

    # ------------------------------------------------------------------ #
    # App logs (диагностика)
    # ------------------------------------------------------------------ #
    def add_log(self, level: str, message: str) -> int:
        self._ensure_open()
        if self.conn is None:
            return -1
        ts = datetime.now(timezone.utc).isoformat()
        with self._lock:
            cur = self.conn.cursor()
            cur.execute("INSERT INTO app_logs (ts, level, message) VALUES (?, ?, ?)", (ts, level, message))
            self.conn.commit()
            return int(cur.lastrowid)

    def cleanup_old_logs(self, days: int = 30) -> int:
        """Очистка app_logs старше N дней (совм. со старым вызовом)."""
        self._ensure_open()
        if self.conn is None:
            return 0
        cutoff = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()
        with self._lock:
            cur = self.conn.cursor()
            cur.execute("SELECT COUNT(*) FROM app_logs WHERE ts < ?", (cutoff,))
            cnt = int(cur.fetchone()[0] or 0)
            cur.execute("DELETE FROM app_logs WHERE ts < ?", (cutoff,))
            self.conn.commit()
            return cnt

    def cleanup_old_action_logs(self, days: int = 30) -> int:
        self._ensure_open()
        if self.conn is None:
            return 0
        cutoff = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()
        with self._lock:
            cur = self.conn.cursor()
            cur.execute("SELECT COUNT(*) FROM logs WHERE timestamp < ?", (cutoff,))
            cnt = int(cur.fetchone()[0] or 0)
            cur.execute("DELETE FROM logs WHERE timestamp < ?", (cutoff,))
            self.conn.commit()
            return cnt

    # ------------------------------------------------------------------ #
    # Action logs (то, что синхронизируется)
    # ------------------------------------------------------------------ #
    def _gen_session_id(self, email: str) -> str:
        return f"{(email or '')[:8]}_{datetime.now().strftime('%Y%m%d%H%M%S')}"

    def log_action(
        self,
        email: str,
        name: str,
        status: Optional[str],
        action_type: str,
        comment: Optional[str] = None,
        immediate_sync: bool = False,
        priority: int = 1,
        session_id: Optional[str] = None,
        status_start_time: Optional[str] = None,
        status_end_time: Optional[str] = None,
        reason: Optional[str] = None,
        user_group: Optional[str] = None,
    ) -> int:
        if not email or not name or not action_type:
            raise LocalDBError("Обязательные поля не заполнены (email/name/action_type)")

        if comment and len(comment) > MAX_COMMENT_LENGTH:
            comment = comment[:MAX_COMMENT_LENGTH]

        ts = datetime.now(timezone.utc).isoformat()
        session_id = session_id or self._gen_session_id(email)
        prio = max(1, min(3, int(priority or 1)))

        self._ensure_open()
        if self.conn is None:
            raise LocalDBError("Не удалось открыть локальную БД")

        try:
            with self._lock:
                cur = self.conn.cursor()
                cur.execute(
                    """
                    INSERT INTO logs
                    (email, name, status, action_type, comment, timestamp, priority,
                     session_id, status_start_time, status_end_time, reason, user_group)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        email.strip(),
                        name.strip(),
                        status,
                        action_type,
                        comment,
                        ts,
                        prio,
                        session_id,
                        status_start_time,
                        status_end_time,
                        reason,
                        user_group,
                    ),
                )
                self.conn.commit()
                return int(cur.lastrowid)
        except sqlite3.Error as e:
            if "Duplicate LOGOUT action" in str(e):
                logger.warning("Попытка дублирования LOGOUT (session_id=%s)", session_id)
                return -1
            raise LocalDBError(f"Ошибка записи в лог: {e}")

    def get_action_by_id(self, action_id: int) -> Optional[Tuple]:
        """Нужен GUI для немедленной отправки одной записи."""
        self._ensure_open()
        if self.conn is None:
            return None
        with self._lock:
            cur = self.conn.cursor()
            cur.execute("SELECT * FROM logs WHERE id = ?", (int(action_id),))
            return cur.fetchone()

    def get_unsynced_actions(self, limit: int = 100) -> List[Tuple]:
        self._ensure_open()
        if self.conn is None:
            return []
        with self._lock:
            cur = self.conn.cursor()
            cur.execute(
                """
                SELECT id, email, name, status, action_type, comment, timestamp,
                       session_id, status_start_time, status_end_time, reason, user_group
                  FROM logs
                 WHERE synced = 0
              ORDER BY priority DESC, timestamp ASC
                 LIMIT ?
                """,
                (int(limit),),
            )
            return list(cur.fetchall())

    def get_unsynced_count(self) -> int:
        """Нужен авто-синху для статистики очереди."""
        self._ensure_open()
        if self.conn is None:
            return 0
        with self._lock:
            cur = self.conn.cursor()
            cur.execute("SELECT COUNT(*) FROM logs WHERE synced = 0;")
            row = cur.fetchone()
            return int(row[0] or 0)

    def mark_actions_synced(self, ids: List[int]) -> None:
        if not ids:
            return
        self._ensure_open()
        if self.conn is None:
            return
        with self._lock:
            cur = self.conn.cursor()
            placeholders = ",".join(["?"] * len(ids))
            cur.execute(
                f"""
                UPDATE logs
                   SET synced = 1,
                       sync_attempts = sync_attempts + 1,
                       last_sync_attempt = ?
                 WHERE id IN ({placeholders})
                """,
                [datetime.now(timezone.utc).isoformat(), *ids],
            )
            self.conn.commit()

    def check_existing_logout(self, email: str, session_id: Optional[str] = None) -> bool:
        self._ensure_open()
        if self.conn is None:
            return False
        with self._lock:
            cur = self.conn.cursor()
            if session_id:
                cur.execute(
                    "SELECT COUNT(*) FROM logs WHERE email=? AND session_id=? AND LOWER(action_type)='logout'",
                    (email, session_id),
                )
            else:
                cur.execute(
                    "SELECT COUNT(*) FROM logs WHERE email=? AND LOWER(action_type)='logout'",
                    (email,),
                )
            return (cur.fetchone()[0] or 0) > 0

    def finish_last_status(self, email: str, session_id: str) -> Optional[int]:
        self._ensure_open()
        if self.conn is None:
            return None
        with self._lock:
            cur = self.conn.cursor()
            cur.execute(
                """
                SELECT id FROM logs
                 WHERE email=? AND session_id=? AND status_end_time IS NULL
                   AND (action_type='STATUS_CHANGE' OR action_type='LOGIN')
              ORDER BY id DESC LIMIT 1
                """,
                (email, session_id),
            )
            row = cur.fetchone()
            if not row:
                return None
            rid = int(row[0])
            cur.execute(
                "UPDATE logs SET status_end_time=? WHERE id=?",
                (datetime.now(timezone.utc).isoformat(), rid),
            )
            self.conn.commit()
            return rid

    def get_last_unfinished_session(self, email: str) -> Optional[Dict[str, Any]]:
        self._ensure_open()
        if self.conn is None:
            return None
        with self._lock:
            cur = self.conn.cursor()
            cur.execute(
                """
                SELECT session_id, timestamp
                  FROM logs
                 WHERE email=? AND action_type='LOGIN'
                   AND session_id NOT IN (
                        SELECT session_id FROM logs
                         WHERE email=? AND LOWER(action_type)='logout'
                   )
              ORDER BY timestamp DESC
                 LIMIT 1
                """,
                (email, email),
            )
            row = cur.fetchone()
            return {"session_id": row[0], "timestamp": row[1]} if row else None

    def get_active_session(self, email: str) -> Optional[Dict[str, Any]]:
        return self.get_last_unfinished_session(email)

    def get_current_user_email(self) -> Optional[str]:
        self._ensure_open()
        if self.conn is None:
            return None
        with self._lock:
            cur = self.conn.cursor()
            cur.execute(
                """
                SELECT email
                  FROM logs
                 WHERE status_end_time IS NULL
                   AND action_type IN ('LOGIN','STATUS_CHANGE')
              ORDER BY id DESC
                 LIMIT 1
                """
            )
            row = cur.fetchone()
            return row[0] if row else None


# Синглтон (при необходимости)
_DB_SINGLETON: Optional[LocalDB] = None
_SINGLETON_LOCK = threading.Lock()

def get_db() -> LocalDB:
    global _DB_SINGLETON
    if _DB_SINGLETON is None:
        with _SINGLETON_LOCK:
            if _DB_SINGLETON is None:
                _DB_SINGLETON = LocalDB(str(LOCAL_DB_PATH))
    return _DB_SINGLETON


if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser(description="LocalDB helper")
    ap.add_argument("--path", type=str, default=str(LOCAL_DB_PATH))
    ap.add_argument("--add-log", type=str, default=None, help="Добавить app_log (level:msg)")
    ap.add_argument("--cleanup-days", type=int, default=None, help="Удалить app_logs старше N дней")
    args = ap.parse_args()

    db = LocalDB(args.path)
    if args.add_log:
        try:
            level, msg = args.add_log.split(":", 1)
        except Exception:
            level, msg = "INFO", args.add_log
        rid = db.add_log(level, msg)
        print(f"Inserted app_log id={rid}")

    if args.cleanup_days is not None:
        cnt = db.cleanup_old_logs(days=args.cleanup_days)
        print(f"Deleted {cnt} old app_log rows")

    db.close()

--------------------------------------------------------------------------------
# FILE: user_app\db_migrations.py
# SIZE: 1215 bytes | SHA256(text): 4552095da96ffb8e4de2e3a02f4af41a430ec59bf558e9a26988de74623a6b29
--------------------------------------------------------------------------------
# user_app/db_migrations.py
from __future__ import annotations
import sqlite3
from typing import Iterable

DDL: Iterable[str] = [
    # ActiveSessions: ускоряем поиск по e-mail/сессии/статусу
    "CREATE INDEX IF NOT EXISTS idx_active_email_session ON ActiveSessions(Email, SessionID);",
    "CREATE INDEX IF NOT EXISTS idx_active_status ON ActiveSessions(Status);",

    # WorkLog: по опыту — фильтры по Email/Timestamp/SessionID
    "CREATE INDEX IF NOT EXISTS idx_worklog_email_ts ON WorkLog(Email, Timestamp);",
    "CREATE INDEX IF NOT EXISTS idx_worklog_session ON WorkLog(SessionID);",

    # ActionLogs/Queue (если у вас есть очередь или флаг synced)
    "CREATE INDEX IF NOT EXISTS idx_actions_synced ON ActionLogs(Synced, CreatedAt);",
]

def apply_migrations(conn: sqlite3.Connection) -> None:
    cur = conn.cursor()
    for sql in DDL:
        try:
            cur.execute(sql)
        except Exception as e:
            # не валим миграцию, просто пишем в лог через pragma user_version позже при развитии схемы
            pass
    conn.commit()

--------------------------------------------------------------------------------
# FILE: user_app\gui.py
# SIZE: 28195 bytes | SHA256(text): 563e907196e31a2bac6583f45b370a77ed13816e3a486610582c427a38858795
--------------------------------------------------------------------------------
import sys
import os
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Callable
import threading

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config import STATUSES, STATUS_GROUPS, MAX_COMMENT_LENGTH
from sheets_api import sheets_api
from user_app.db_local import LocalDB, LocalDBError

try:
    from sync.notifications import Notifier
except ImportError:
    try:
        from .sync.notifications import Notifier
    except ImportError:
        from notifications import Notifier

from PyQt5.QtWidgets import (
    QWidget, QLabel, QPushButton, QVBoxLayout,
    QHBoxLayout, QMessageBox, QTextEdit,
    QSizePolicy, QApplication
)
from PyQt5.QtCore import QTimer, Qt, pyqtSignal
from PyQt5.QtGui import QFont, QPixmap, QIcon

logger = logging.getLogger(__name__)

class EmployeeApp(QWidget):
    status_changed = pyqtSignal(str)
    app_closed = pyqtSignal(str)

    def __init__(
        self,
        email: str,
        name: str,
        role: str = "специалист",
        group: str = "",
        shift_hours: str = "8 часов",
        telegram_login: str = "",
        on_logout_callback: Optional[Callable] = None,
        session_id: Optional[str] = None,
        login_was_performed: bool = True
    ):
        super().__init__()
        self.email = email
        self.name = name
        self.role = role
        self.group = group
        self.shift_hours = shift_hours
        self.telegram_login = telegram_login
        self.on_logout_callback = on_logout_callback

        self.current_status = "В работе"
        self.status_start_time = datetime.now()
        self.shift_start_time = datetime.now()
        self.last_sync_time = None
        self.shift_ended = False

        # Логика закрытия: None, "admin_logout", "user_close", "auto_logout"
        self._closing_reason = None

        if session_id is not None:
            self.session_id = session_id
            self._continue_existing_session = True
        else:
            self.session_id = self._generate_session_id()
            self._continue_existing_session = False
        self.status_buttons = {}

        self.login_was_performed = login_was_performed

        self._init_db()
        self._init_ui()
        self._init_timers()
        self._init_shift_check_timer()

    def get_user(self):
        return {
            "Email": self.email,
            "Name": self.name,
            "Role": self.role,
            "Telegram": self.telegram_login,
            "ShiftHours": self.shift_hours,
            "Group": self.group,
        }

    def _generate_session_id(self) -> str:
        return f"{self.email[:8]}_{datetime.now().strftime('%Y%m%d%H%M%S')}"

    def _make_action_payload_from_row(self, row):
        # Порядок столбцов в logs:
        # 0:id 1:session_id 2:email 3:name 4:status 5:action_type 6:comment
        # 7:timestamp 8:synced 9:sync_attempts 10:last_sync_attempt 11:priority
        # 12:status_start_time 13:status_end_time 14:reason 15:user_group
        return {
            "session_id": row[1],
            "email": row[2],
            "name": row[3],
            "status": row[4],
            "action_type": row[5],
            "comment": row[6],
            "timestamp": row[7],
            "status_start_time": row[12],
            "status_end_time": row[13],
            "reason": row[14] if len(row) > 14 else None,
        }

    def _send_action_to_sheets(self, record_id, user_group=None):
        threading.Thread(target=self._send_action_to_sheets_worker, args=(record_id, user_group), daemon=True).start()

    def _send_action_to_sheets_worker(self, record_id, user_group=None):
        try:
            row = self.db.get_action_by_id(record_id)
            if not row:
                logger.error(f"Не удалось найти запись с id={record_id} для отправки в Sheets")
                return

            action = self._make_action_payload_from_row(row)
            # ВАЖНО: сначала actions (список словарей), затем email
            ok = sheets_api.log_user_actions([action], action["email"], user_group=user_group or self.group)
            if ok:
                self.db.mark_actions_synced([record_id])
            else:
                logger.warning("Sheets: log_user_actions вернул False — оставляю запись несинхронизированной")
        except Exception as e:
            logger.warning(f"Ошибка отправки действия в Google Sheets: {e}")
            Notifier.show("Оффлайн режим", "Данные будут отправлены при появлении интернета.")

    def _finish_and_send_previous_status(self):
        prev_id = self.db.finish_last_status(self.email, self.session_id)
        if prev_id:
            threading.Thread(target=self._finish_and_send_previous_status_worker, args=(prev_id,), daemon=True).start()

    def _finish_and_send_previous_status_worker(self, prev_id):
        row = self.db.get_action_by_id(prev_id)
        if not row:
            return
        try:
            action = self._make_action_payload_from_row(row)
            ok = sheets_api.log_user_actions([action], action["email"], user_group=self.group)
            if ok:
                self.db.mark_actions_synced([prev_id])
            else:
                logger.warning("Sheets: log_user_actions вернул False — оставляю запись несинхронизированной")
        except Exception as e:
            logger.warning(f"Ошибка отправки завершённого статуса в Sheets: {e}")
            Notifier.show("Оффлайн режим", "Предыдущий статус будет синхронизирован позже.")

    def _init_db(self):
        try:
            self.db = LocalDB()
            if self.login_was_performed:
                now = datetime.now().isoformat()
                record_id = self.db.log_action(
                    email=self.email,
                    name=self.name,
                    status=self.current_status,
                    action_type="LOGIN",
                    comment="Начало смены",
                    immediate_sync=False,
                    session_id=self.session_id,
                    status_start_time=now,
                    status_end_time=None,
                    reason=None
                )
                self.status_start_time = datetime.fromisoformat(now)
                self._send_action_to_sheets(record_id)
        except LocalDBError as e:
            logger.error(f"Ошибка инициализации БД: {e}")
            QMessageBox.critical(self, "Ошибка", "Не удалось инициализировать локальную базу данных")
            raise

    def _init_ui(self):
        self.setWindowTitle("🕓 Учёт рабочего времени")
        self.setWindowIcon(QIcon(str(Path(__file__).parent / "sberhealf.png")))
        self.resize(500, 440)
        self.setMinimumSize(400, 350)

        main_layout = QVBoxLayout()
        main_layout.setContentsMargins(15, 15, 15, 15)
        main_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        logo_label = QLabel()
        logo_path = Path(__file__).parent / "sberhealf.png"
        if logo_path.exists():
            pixmap = QPixmap(str(logo_path))
            pixmap = pixmap.scaled(180, 80, Qt.KeepAspectRatio, Qt.SmoothTransformation)
            logo_label.setPixmap(pixmap)
        header_layout.addWidget(logo_label)

        title_label = QLabel("Учёт рабочего времени")
        title_label.setStyleSheet("font-size: 18px; font-weight: bold;")
        header_layout.addWidget(title_label, alignment=Qt.AlignCenter)
        main_layout.addLayout(header_layout)

        self.info_label = QLabel()
        self.info_label.setStyleSheet("QLabel { background-color: #f5f5f5; border-radius: 5px; padding: 10px; }")
        self._update_info_text()
        main_layout.addWidget(self.info_label)

        self.comment_input = QTextEdit()
        self.comment_input.setPlaceholderText("Введите комментарий...")
        self.comment_input.setMaximumHeight(80)
        self.comment_input.setStyleSheet("QTextEdit { border: 1px solid #ddd; border-radius: 5px; padding: 5px; }")
        main_layout.addWidget(self.comment_input)

        self.time_label = QLabel("⏱ Время в статусе: 00:00:00")
        self.time_label.setAlignment(Qt.AlignCenter)
        self.time_label.setStyleSheet("font-size: 14px;")
        main_layout.addWidget(self.time_label)

        self.shift_timer_label = QLabel("⏰ Время смены: 00:00:00")
        self.shift_timer_label.setAlignment(Qt.AlignCenter)
        self.shift_timer_label.setStyleSheet("font-size: 14px; color: #0069c0;")
        main_layout.addWidget(self.shift_timer_label)

        for group in STATUS_GROUPS:
            btn_layout = QHBoxLayout()
            btn_layout.setSpacing(10)
            for status in group:
                btn = QPushButton(status)
                btn.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)
                btn.clicked.connect(lambda _, s=status: self.set_status(s))
                btn_layout.addWidget(btn)
                self.status_buttons[status] = btn
            main_layout.addLayout(btn_layout)

        self.finish_btn = QPushButton("Завершить смену")
        self.finish_btn.setStyleSheet("""
            QPushButton {
                padding: 10px;
                border-radius: 5px;
                background-color: #f44336;
                color: white;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #d32f2f;
            }
        """)
        self.finish_btn.clicked.connect(self.finish_shift)
        main_layout.addWidget(self.finish_btn)

        self.setLayout(main_layout)
        self._update_button_states()

    def _init_timers(self):
        self.status_timer = QTimer(self)
        self.status_timer.timeout.connect(self._update_time_display)
        self.status_timer.start(1000)

        self.sync_timer = QTimer(self)
        self.sync_timer.timeout.connect(self._check_sync_status)
        self.sync_timer.start(60000)

    def _init_shift_check_timer(self):
        self.shift_check_timer = QTimer(self)
        self.shift_check_timer.timeout.connect(self._auto_check_shift_ended)
        self.shift_check_timer.start(30000)  # каждые 30 сек
        self._auto_check_shift_ended()

    def _is_session_finished_remote(self) -> bool:
        """
        True — если в ActiveSessions текущая (или последняя по email) сессия
        имеет статус 'finished' или 'kicked'.
        """
        try:
            if hasattr(sheets_api, "check_user_session_status"):
                st = str(sheets_api.check_user_session_status(self.email, self.session_id)).strip().lower()
                logger.debug(f"[ACTIVESESSIONS] status for {self.email}/{self.session_id}: {st}")
                if st in ("finished", "kicked"):
                    return True

            if hasattr(sheets_api, "get_all_active_sessions"):
                sessions = sheets_api.get_all_active_sessions() or []
                last_for_email = None
                for s in sessions:
                    if str(s.get("Email", "")).strip().lower() == self.email.lower():
                        last_for_email = s
                if last_for_email:
                    st2 = str(last_for_email.get("Status", "")).strip().lower()
                    logger.debug(f"[ACTIVESESSIONS] fallback status for {self.email}: {st2}")
                    return st2 in ("finished", "kicked")
        except Exception as e:
            logger.debug(f"_is_session_finished_remote error: {e}")
        return False

    def _auto_check_shift_ended(self):
        if self.shift_ended:
            return

        # 1) локальная проверка
        if self._is_shift_ended():
            self.shift_ended = True
            self.finish_btn.setEnabled(False)
            for btn in self.status_buttons.values():
                btn.setEnabled(False)
            Notifier.show("WorkLog", "Смена завершена (автоматически, по данным системы).")
            logger.info(f"[AUTO_LOGOUT_DETECT] Локально найден LOGOUT для {self.email}")
            return

        # 2) удалённая проверка ActiveSessions
        if self._is_session_finished_remote():
            logger.info(f"[AUTO_LOGOUT_DETECT] В ActiveSessions статус НЕ active для {self.email}, session={self.session_id}")
            self._closing_reason = "auto_logout"
            self.finish_btn.setEnabled(False)
            for btn in self.status_buttons.values():
                btn.setEnabled(False)
            Notifier.show("WorkLog", "Смена завершена администратором.")
            try:
                self._log_shift_end("Разлогинен администратором (удалённо)", reason="admin")
            except Exception as e:
                logger.error(f"Ошибка при автологаутах по сигналу из Sheets: {e}")
            self.shift_ended = True
            self.close()

    def _update_info_text(self):
        info_text = (
            f"<b>Сотрудник:</b> {self.name}<br>"
            f"<b>Должность:</b> {self.role}<br>"
            f"<b>Группа:</b> {self.group}<br>"
            f"<b>Смена:</b> {self.shift_hours}<br>"
            f"<b>Текущий статус:</b> <span style='color: #2e7d32;'>{self.current_status}</span>"
        )
        self.info_label.setText(info_text)
        self.status_changed.emit(self.current_status)
        self._update_button_states()

    def _update_button_states(self):
        for status, btn in self.status_buttons.items():
            if status == self.current_status:
                btn.setStyleSheet("""
                    QPushButton {
                        padding: 8px;
                        border-radius: 5px;
                        background-color: #b3ffb3;
                        font-weight: bold;
                        border: 2px solid #2e7d32;
                    }
                    QPushButton:hover {
                        background-color: #a1e6a1;
                    }
                """)
                btn.setEnabled(False)
            else:
                btn.setStyleSheet("""
                    QPushButton {
                        padding: 8px;
                        border-radius: 5px;
                        background-color: #e0e0e0;
                    }
                    QPushButton:hover {
                        background-color: #d0d0d0;
                    }
                """)
                btn.setEnabled(True)
            if self.shift_ended:
                btn.setEnabled(False)

    def _update_time_display(self):
        time_in_status = datetime.now() - self.status_start_time
        hours, remainder = divmod(time_in_status.seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        self.time_label.setText(f"⏱ Время в статусе: {hours:02d}:{minutes:02d}:{seconds:02d}")

        shift_time = datetime.now() - self.shift_start_time
        h, rem = divmod(shift_time.seconds, 3600)
        m, s = divmod(rem, 60)
        self.shift_timer_label.setText(f"⏰ Время смены: {h:02d}:{m:02d}:{s:02d}")

    def _check_sync_status(self):
        if self.last_sync_time:
            time_since_sync = datetime.now() - self.last_sync_time
            if time_since_sync > timedelta(hours=1):
                Notifier.show("WorkLog", "Данные не синхронизировались более часа")

    def _is_shift_ended(self) -> bool:
        try:
            return self.db.check_existing_logout(self.email, session_id=self.session_id)
        except Exception as e:
            logger.error(f"Ошибка проверки завершения смены: {e}")
            return False

    def set_status(self, new_status: str):
        if self.shift_ended:
            QMessageBox.warning(self, "Ошибка", "Смена уже завершена")
            return

        if new_status == self.current_status:
            QMessageBox.information(self, "Информация", "Вы уже находитесь в этом статусе.")
            return

        comment = self.comment_input.toPlainText().strip()

        try:
            now = datetime.now().isoformat()
            
            # --- ШАГ 1: Явно завершаем ПОСЛЕДНИЙ статус, устанавливая end_time ---
            # Находим id последнего статуса (LOGIN или STATUS_CHANGE)
            with self.db._lock:
                cursor = self.db.conn.execute(
                    "SELECT id, status FROM logs WHERE email=? AND session_id=? "
                    "AND status_end_time IS NULL "
                    "AND action_type IN ('LOGIN', 'STATUS_CHANGE') "
                    "ORDER BY id DESC LIMIT 1",
                    (self.email, self.session_id)
                )
                row = cursor.fetchone()
                if row:
                    prev_id, prev_status = row
                    # Явно устанавливаем время окончания
                    self.db.conn.execute(
                        "UPDATE logs SET status_end_time=? WHERE id=?",
                        (now, prev_id)
                    )
                    self.db.conn.commit()
                    logger.info(f"Статус '{prev_status}' (id={prev_id}) завершен в {now}")
                    # Отправляем старую запись в фоне
                    self._send_action_to_sheets(prev_id)
                else:
                    logger.warning("Не найден незавершенный статус для обновления end_time")

            # --- ШАГ 2: Логируем НОВЫЙ статус ---
            record_id = self.db.log_action(
                email=self.email,
                name=self.name,
                status=new_status,
                action_type="STATUS_CHANGE",
                comment=comment if comment else None,
                immediate_sync=False,
                session_id=self.session_id,
                status_start_time=now,
                status_end_time=None
            )
            
            # Отправляем новую запись в фоне
            self._send_action_to_sheets(record_id)
            
            # --- ШАГ 3: Обновляем состояние приложения ---
            self.current_status = new_status
            self.status_start_time = datetime.fromisoformat(now)
            self.comment_input.clear()
            self._update_info_text()
            Notifier.show("WorkLog", f"Статус изменен на: {new_status}")
            
        except Exception as e:
            logger.error(f"Ошибка при изменении статуса: {e}")
            QMessageBox.critical(self, "Ошибка", f"Не удалось изменить статус: {e}")

    def finish_shift(self):
        if self.shift_ended:
            QMessageBox.information(self, "Информация", "Смена уже завершена")
            return

        reply = QMessageBox.question(
            self,
            "Подтверждение",
            "Вы уверены, что хотите завершить смену?",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )

        if reply == QMessageBox.Yes:
            try:
                result = self._log_shift_end("Завершение смены (нормальное)", reason="user", group=self.group, sync=False)
                if result:
                    logger.info(f"[LOGOUT] Запись LOGOUT успешно произведена для {self.email}")
                else:
                    logger.warning(f"[LOGOUT] LOGOUT уже был записан для {self.email}")
                self.shift_ended = True
                self.finish_btn.setEnabled(False)
                for btn in self.status_buttons.values():
                    btn.setEnabled(False)
                try:
                    sheets_api.finish_active_session(self.email, self.session_id, datetime.now().isoformat())
                except Exception as e:
                    logger.error(f"Ошибка завершения сессии в ActiveSessions: {e}")
                self.close()
            except LocalDBError as e:
                logger.error(f"Ошибка завершения смены: {e}")
                QMessageBox.critical(self, "Ошибка", f"Не удалось завершить смену: {e}")

    def force_logout_by_admin(self):
        """Принудительный выход по инициативе администратора с уведомлением пользователя"""
        if self.shift_ended:
            logger.info(f"[ADMIN_LOGOUT] Попытка принудительного выхода для уже завершенной смену: {self.email}")
            return
            
        self._closing_reason = "admin_logout"
        self.finish_btn.setEnabled(False)
        for btn in self.status_buttons.values():
            btn.setEnabled(False)
            
        try:
            # синхронно пишем статус+LOGOUT в WorkLog_Группа
            self._log_shift_end("Разлогинен администратором", reason="admin",
                                group=self.group, sync=True)
            # и сразу помечаем ActiveSessions как "kicked"
            try:
                sheets_api.kick_active_session(self.email, self.session_id, datetime.now().isoformat())
            except Exception as e:
                logger.error(f"kick_active_session error: {e}")
        except Exception as e:
            logger.error(f"Ошибка при админском выходе: {e}")
            if self.on_logout_callback:
                self.on_logout_callback()

        self.shift_ended = True

        # Показываем информационное окно (не критическое)
        QMessageBox.information(
            self,
            "Смена завершена администратором",
            "Ваша смена была завершена администратором.\n\nПриложение будет закрыто."
        )

        self.close()

    def _log_shift_end(self, comment: str, reason: str = "user", 
                       group: Optional[str] = None, sync: bool = False) -> bool:
        """
        Завершает смену и записывает LOGOUT.
        :param comment: Комментарий к выходу.
        :param reason: Причина выхода (user, admin, auto).
        :param group: Группа пользователя (для правильного выбора листа в Google Sheets).
        :param sync: Синхронная отправка данных (True для админского выхода).
        """
        try:
            if self._is_shift_ended():
                logger.warning(f"[LOGOUT] Повторная попытка LOGOUT для {self.email} — пропуск.")
                return False

            # 1) закрыть предыдущий статус
            prev_id = self.db.finish_last_status(self.email, self.session_id)
            if prev_id:
                if sync:
                    row = self.db.get_action_by_id(prev_id)
                    action = self._make_action_payload_from_row(row)
                    if sheets_api.log_user_actions([action], self.email, user_group=group or self.group):
                        self.db.mark_actions_synced([prev_id])
                else:
                    self._send_action_to_sheets(prev_id, user_group=group or self.group)

            # 2) записать LOGOUT
            now = datetime.now().isoformat()
            record_id = self.db.log_action(
                email=self.email,
                name=self.name,
                status="Завершено",
                action_type="LOGOUT",
                comment=comment,
                immediate_sync=False,
                session_id=self.session_id,
                status_start_time=now,
                status_end_time=now,
                reason=reason,
                user_group=group or self.group
            )

            if sync:
                row2 = self.db.get_action_by_id(record_id)
                action2 = self._make_action_payload_from_row(row2)
                if sheets_api.log_user_actions([action2], self.email, user_group=group or self.group):
                    self.db.mark_actions_synced([record_id])
            else:
                self._send_action_to_sheets(record_id, user_group=group or self.group)

            self.last_sync_time = datetime.now()
            self._check_sync_status()
            logger.info(f"[LOGOUT] Смена завершена: {self.email}. Причина: {comment}, reason={reason}")

            if self.on_logout_callback:
                self.on_logout_callback()
                
            return True
        except Exception as e:
            logger.error(f"Ошибка записи LOGOUT: {e}")
            return False

    def closeEvent(self, event):
        if self._closing_reason == "admin_logout":
            # Закрываем без подтверждения
            event.accept()
            self._closing_reason = None
            return

        if self._closing_reason == "auto_logout":
            # Можно закрыть без подтверждения или показать уведомление
            event.accept()
            self._closing_reason = None
            return

        # Если пользователь пытается закрыть окно вручную
        reply = QMessageBox.question(
            self,
            'Подтверждение закрытия',
            'Вы уверены, что хотите закрыть приложение? Смена будет автоматически завершена...',
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )

        if reply == QMessageBox.Yes:
            self._closing_reason = "user_close"
            try:
                self._log_shift_end("Приложение закрыто через крестик", reason="user", group=self.group, sync=False)
                sheets_api.finish_active_session(self.email, self.session_id, datetime.now().isoformat())
            except Exception as e:
                logger.error(f"Ошибка при закрытии приложения: {e}")
            self.shift_ended = True
            event.accept()
            self._closing_reason = None
        else:
            event.ignore()

--------------------------------------------------------------------------------
# FILE: user_app\login_window.py
# SIZE: 11741 bytes | SHA256(text): 9a1004cc885cef2aef40a9f55518c02fa6b6d46f66ba1d948f3e8a68160e30fd
--------------------------------------------------------------------------------
import re
import logging
import sys
from pathlib import Path
from PyQt5.QtWidgets import (
    QDialog, QVBoxLayout, QLabel,
    QLineEdit, QPushButton, QMessageBox, QSpacerItem, QSizePolicy
)
from PyQt5.QtCore import Qt, pyqtSignal, QDateTime
from PyQt5.QtGui import QIcon, QPixmap, QFont

try:
    from config import validate_config
    from sheets_api import SheetsAPI
    from user_app.db_local import LocalDB
except ImportError:
    try:
        from roma.config import validate_config
        from roma.sheets_api import SheetsAPI
        from roma.user_app.db_local import LocalDB
    except ImportError:
        from config import validate_config
        from sheets_api import SheetsAPI
        from user_app.db_local import LocalDB

logger = logging.getLogger(__name__)

class LoginWindow(QDialog):
    login_success = pyqtSignal(dict)
    login_failed = pyqtSignal(str)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Вход в систему")
        self.setWindowIcon(QIcon(self._resource_path("user_app/sberhealf.png")))
        self.setFixedSize(440, 360)
        self.user_data = None
        self.sheets_api = SheetsAPI()
        self.auth_in_progress = False
        self._success_emitted = False
        self._showing_error = False
        logger.debug("LoginWindow: инициализация окна входа")
        self._init_ui()
        self._setup_shortcuts()

    def _resource_path(self, relative_path):
        if hasattr(sys, '_MEIPASS'):
            base_path = Path(sys._MEIPASS)
        else:
            base_path = Path(__file__).parent.parent
        return str(base_path / relative_path)

    def _init_ui(self):
        self.setFont(QFont("Segoe UI", 11))
        layout = QVBoxLayout()
        layout.setContentsMargins(30, 25, 30, 25)
        layout.setSpacing(18)

        logo_label = QLabel()
        try:
            pixmap = QPixmap(self._resource_path("user_app/sberhealf.png"))
            target_width = 170
            target_height = 70
            pixmap = pixmap.scaled(
                target_width, target_height,
                Qt.KeepAspectRatio, Qt.SmoothTransformation
            )
            logo_label.setPixmap(pixmap)
            logo_label.setAlignment(Qt.AlignCenter)
            layout.addWidget(logo_label)
        except Exception as e:
            logger.warning(f"Не удалось загрузить логотип: {e}")

        title_label = QLabel("Вход в систему")
        title_label.setAlignment(Qt.AlignCenter)
        title_label.setStyleSheet("""
            font-size: 22px;
            font-weight: bold;
            color: #222;
            margin-bottom: 15px;
        """)
        layout.addWidget(title_label)

        layout.addSpacerItem(QSpacerItem(20, 10, QSizePolicy.Minimum, QSizePolicy.Fixed))

        self.email_input = QLineEdit()
        self.email_input.setPlaceholderText("Корпоративный email")
        self.email_input.setStyleSheet("""
            QLineEdit {
                padding: 11px;
                border: 1.5px solid #ccc;
                border-radius: 8px;
                font-size: 15px;
                min-width: 290px;
                max-width: 350px;
            }
        """)
        self.email_input.setMinimumWidth(290)
        self.email_input.setMaximumWidth(350)
        layout.addWidget(self.email_input, alignment=Qt.AlignCenter)

        layout.addSpacerItem(QSpacerItem(20, 8, QSizePolicy.Minimum, QSizePolicy.Fixed))

        self.login_btn = QPushButton("Войти")
        self.login_btn.setStyleSheet("""
            QPushButton {
                background-color: #4CAF50;
                color: white;
                border: none;
                padding: 13px;
                font-size: 16px;
                border-radius: 9px;
                min-width: 180px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:disabled {
                background-color: #cccccc;
            }
        """)
        self.login_btn.setMinimumHeight(40)
        self.login_btn.setMaximumWidth(220)
        self.login_btn.clicked.connect(self._try_login)
        layout.addWidget(self.login_btn, alignment=Qt.AlignCenter)

        self.status_label = QLabel()
        self.status_label.setStyleSheet("""
            color: #666;
            font-size: 13px;
            margin-top: 12px;
            min-height: 18px;
        """)
        self.status_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.status_label)

        layout.addStretch(1)
        self.setLayout(layout)
        logger.debug("LoginWindow: интерфейс инициализирован")

    def _setup_shortcuts(self):
        self.email_input.returnPressed.connect(self._try_login)

    def _validate_email(self, email: str) -> bool:
        logger.debug(f"LoginWindow: валидация email '{email}'")
        pattern = r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$"
        return re.match(pattern, email) is not None

    def _try_login(self):
        logger.info("LoginWindow: старт логина")
        if self.auth_in_progress or self._success_emitted:
            logger.debug(f"LoginWindow: пропуск попытки логина (auth_in_progress={self.auth_in_progress}, _success_emitted={self._success_emitted})")
            return
        self.auth_in_progress = True

        email = self.email_input.text().strip()
        logger.info(f"LoginWindow: введён email: {email}")

        if not email:
            error_msg = "Введите email адрес"
            logger.warning(f"LoginWindow: {error_msg}")
            self._show_error_once(error_msg)
            self.login_failed.emit(error_msg)
            self.auth_in_progress = False
            return

        if not self._validate_email(email):
            error_msg = "Некорректный формат email"
            logger.warning(f"LoginWindow: {error_msg}")
            self._show_error_once(error_msg)
            self.login_failed.emit(error_msg)
            self.auth_in_progress = False
            return

        self._set_loading_state(True)

        try:
            logger.debug("LoginWindow: вызов validate_config")
            validate_config()
            logger.debug("LoginWindow: вызов get_user_by_email")
            user_data = self.sheets_api.get_user_by_email(email)

            if user_data:
                logger.info("LoginWindow: пользователь найден, продолжаем")
                
                # --- ВСЕГДА ЗАВЕРШАЕМ СТАРУЮ СЕССИЮ И НАЧИНАЕМ НОВУЮ ---
                # 1. Находим активную сессию
                active_session = self.sheets_api.get_active_session(email)
                if active_session:
                    session_id = active_session.get("SessionID")
                    login_time = active_session.get("LoginTime")
                    # Автоматически завершаем старую сессию без вопроса
                    logger.info(f"LoginWindow: Автоматически завершаем старую сессию от {login_time}")
                    logout_time = QDateTime.currentDateTime().toString(Qt.ISODate)
                    self.sheets_api.finish_active_session(email, session_id, logout_time)
                
                # 2. Создаем новую сессию
                session_id = f"{email[:8]}_{QDateTime.currentDateTime().toString('yyyyMMddHHmmss')}"
                self.sheets_api.set_active_session(
                    email,
                    user_data.get("name", ""),
                    session_id,
                    QDateTime.currentDateTime().toString(Qt.ISODate)
                )
                login_was_performed = True
                # --- КОНЕЦ ---
                
                # Формируем данные для передачи в GUI
                self.user_data = {
                    "email": user_data["email"],
                    "name": user_data["name"],
                    "role": user_data["role"],
                    "shift_hours": user_data["shift_hours"],
                    "telegram_login": user_data.get("telegram_login", ""),
                    "group": user_data.get("group", ""),
                    "login_was_performed": login_was_performed,
                    "session_id": session_id
                }
                
                # Испускаем сигнал и закрываем окно
                if not self._success_emitted:
                    logger.debug("LoginWindow: испускаем login_success")
                    self._success_emitted = True
                    self.login_success.emit(self.user_data)
                else:
                    logger.debug("LoginWindow: login_success уже испущен")
                self.accept()
            else:
                error_msg = "Пользователь не найден. Проверьте email или обратитесь к администратору."
                logger.error(f"LoginWindow: {error_msg}")
                self._show_error_once(error_msg)
                self.login_failed.emit(error_msg)

        except Exception as e:
            logger.error(f"LoginWindow: Ошибка авторизации: {e}")
            error_msg = f"Ошибка подключения: {str(e).replace("'", "")}"
            self._show_error_once(error_msg)
            self.login_failed.emit(error_msg)
        finally:
            logger.debug("LoginWindow: завершение попытки логина")
            self._set_loading_state(False)
            self.auth_in_progress = False

    def _set_loading_state(self, loading: bool):
        logger.debug(f"LoginWindow: установка состояния loading={loading}")
        self.login_btn.setDisabled(loading)
        self.email_input.setReadOnly(loading)
        self.login_btn.setText("Проверка..." if loading else "Войти")
        self.status_label.setText("Идет проверка данных..." if loading else "")

    def _show_error_once(self, message: str):
        logger.debug(f"LoginWindow: _show_error_once вызван с message='{message}', _showing_error={self._showing_error}")
        if self._showing_error:
            logger.warning("LoginWindow: попытка повторного показа ошибки, пропуск")
            return
        self._showing_error = True
        logger.info(f"LoginWindow: показываем QMessageBox.warning с текстом: {message}")
        QMessageBox.warning(self, "Ошибка", message)
        self.status_label.setText(f'<span style="color: red;">{message}</span>')
        self._showing_error = False

    def keyPressEvent(self, event):
        if event.key() in (Qt.Key_Return, Qt.Key_Enter):
            logger.debug("LoginWindow: нажатие Enter/Return, пробуем логин")
            self._try_login()
        else:
            super().keyPressEvent(event)

if __name__ == "__main__":
    from PyQt5.QtWidgets import QApplication
    logging.basicConfig(level=logging.DEBUG)
    app = QApplication(sys.argv)
    window = LoginWindow()
    window.show()
    sys.exit(app.exec_())

--------------------------------------------------------------------------------
# FILE: user_app\main.py
# SIZE: 8823 bytes | SHA256(text): 278a32ec4642a3e17031067d7e0099c3fc4a642a48a5c89a9bbc1d53b17bd3f2
--------------------------------------------------------------------------------
# user_app/main.py
import sys
import logging
from pathlib import Path
from typing import Dict, Any
from PyQt5.QtWidgets import QApplication, QMessageBox
from PyQt5.QtCore import QObject, pyqtSignal, QThread
import traceback
import atexit

# Добавляем корень проекта в sys.path
ROOT = Path(__file__).parent.parent.resolve()
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

# Инициализация логирования через единый модуль
from config import LOG_DIR, get_credentials_file
from logging_setup import setup_logging
from user_app.signals import SyncSignals
from sheets_api import SheetsAPI  # Явный импорт класса SheetsAPI
from auto_sync import SyncManager  # ← добавили

# ----- Сигналы приложения -----
class ApplicationSignals(QObject):
    app_started = pyqtSignal()
    app_shutdown = pyqtSignal()
    login_attempt = pyqtSignal(str)
    login_success = pyqtSignal(dict)
    login_failed = pyqtSignal(str)
    sync_status_changed = pyqtSignal(bool)
    sync_progress = pyqtSignal(int, int)
    sync_finished = pyqtSignal(bool)

# ----- Менеджер приложения -----
class ApplicationManager(QObject):
    def __init__(self):
        super().__init__()
        self.app = QApplication(sys.argv)
        self.app.setStyle("Fusion")
        self.app.setApplicationName("WorkTimeTracker")
        self.app.setApplicationVersion("1.0.0")

        self.login_window = None
        self.main_window = None
        self.signals = ApplicationSignals()

        self.sync_thread: QThread | None = None
        self.sync_worker: SyncManager | None = None
        self.sync_signals = SyncSignals()  # сигналы доступны и для GUI, и для SyncManager

        sys.excepthook = self.handle_uncaught_exception

        try:
            self._initialize_resources()
            self._start_sync_service()
            self.signals.app_started.emit()
        except Exception as e:
            self._show_error("Initialization Error", f"Failed to initialize: {e}")
            sys.exit(1)

    # --- Инициализация ресурсов ---
    def _initialize_resources(self):
        creds_path = get_credentials_file()
        if not creds_path.exists():
            raise FileNotFoundError(f"Credentials file not found: {creds_path}")
        
        # Инициализация клиента Google Sheets
        try:
            self.sheets_api = SheetsAPI()
        except Exception as e:
            logging.getLogger(__name__).error("SheetsAPI init failed: %s", e)
            raise
        
        if not self.sheets_api.check_credentials():
            raise RuntimeError("Invalid Google Sheets credentials")

    # --- Фоновая синхронизация ---
    def _start_sync_service(self):
        try:
            logger = logging.getLogger(__name__)
            logger.info("=== ЗАПУСК СЕРВИСА СИНХРОНИЗАЦИИ ===")
            
            # Запускаем сервис синхронизации в фоне
            self.sync_manager = SyncManager(signals=self.sync_signals, background_mode=True)
            if hasattr(self.sync_manager, "start"):
                self.sync_manager.start()
            elif hasattr(self.sync_manager, "start_background"):
                self.sync_manager.start_background()
            
            logger.info("Sync service started")
        except Exception as e:
            logger.error(f"Failed to start sync service: {e}")

    # --- UI потоки ---
    def show_login_window(self):
        try:
            from user_app.login_window import LoginWindow
            self.login_window = LoginWindow()
            self.login_window.login_success.connect(self.handle_login_success)
            self.login_window.login_failed.connect(self.handle_login_failed)
            self.login_window.show()
        except Exception as e:
            self._show_error("Login Error", f"Cannot show login window: {e}")
            self.quit_application()

    def handle_login_success(self, user_data: Dict[str, Any]):
        try:
            from user_app.gui import EmployeeApp

            # закрыть окно логина
            if self.login_window:
                try:
                    self.login_window.close()
                except Exception:
                    pass

            # достаём данные, которые LoginWindow уже собирает
            session_id = None
            login_was_performed = True
            if user_data.get("unfinished_session"):
                session_id = user_data["unfinished_session"].get("session_id")
            if "login_was_performed" in user_data:
                login_was_performed = bool(user_data["login_was_performed"])

            def on_logout_wrapper():
                # корректно завершаем приложение по запросу из EmployeeApp
                self.quit_application()

            # создаём главное окно как раньше
            self.main_window = EmployeeApp(
                email=user_data["email"],
                name=user_data["name"],
                role=user_data["role"],
                shift_hours=user_data["shift_hours"],
                telegram_login=user_data.get("telegram_login", ""),
                on_logout_callback=on_logout_wrapper,
                session_id=session_id,
                login_was_performed=login_was_performed,
                group=user_data.get("group", "")
            )
            self.main_window.show()

            # подключаем «принудительный разлогин» из сервиса синхронизации
            self.sync_signals.force_logout.connect(self.main_window.force_logout_by_admin)
            logger = logging.getLogger(__name__)
            logger.info("force_logout сигнал подключён к force_logout_by_admin")

        except Exception as e:
            self._show_error("Main Window Error", f"Cannot show main window: {e}")
            self.quit_application()

    def handle_login_failed(self, message: str):
        self._show_error("Login Failed", message)

    # --- Общее ---
    def _show_error(self, title: str, message: str):
        QMessageBox.critical(None, title, message)
        logger = logging.getLogger(__name__)
        logger.error("%s: %s", title, message)

    def handle_uncaught_exception(self, exc_type, exc_value, exc_traceback):
        logger = logging.getLogger(__name__)
        logger.critical(
            "Unhandled exception",
            exc_info=(exc_type, exc_value, exc_traceback)
        )
        self._show_error("Critical Error", f"An unexpected error occurred:\n\n{exc_value}")
        self.quit_application()

    def quit_application(self):
        logger = logging.getLogger(__name__)
        logger.info("Shutting down application.")
        self.signals.app_shutdown.emit()

        # закрываем окна
        if self.main_window:
            try:
                self.main_window.close()
            except Exception as e:
                logger.error("Error on main_window.close(): %s", e)
            self.main_window = None

        if self.login_window:
            try:
                self.login_window.close()
            except Exception as e:
                logger.error("Error on login_window.close(): %s", e)
            self.login_window = None

        # останавливаем сервис синхронизации
        try:
            if self.sync_worker:
                self.sync_worker.stop()
        except Exception:
            pass
        if self.sync_thread and self.sync_thread.isRunning():
            self.sync_thread.quit()
            self.sync_thread.wait()

        self.app.quit()

    # точка входа UI
    def run(self):
        self.show_login_window()
        sys.exit(self.app.exec_())

# ----- CLI -----
def main():
    try:
        # единый логгер
        log_path = setup_logging(app_name="wtt-user", log_dir=LOG_DIR)
        logger = logging.getLogger(__name__)
        logger.info("Logging initialized (path=%s)", log_path)
        
        app_manager = ApplicationManager()
        app_manager.run()
    except Exception as e:
        logging.critical(f"Fatal error: {e}\n{traceback.format_exc()}")
        QMessageBox.critical(None, "Fatal Error", f"Application failed to start:\n{e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
# FILE: user_app\signals.py
# SIZE: 543 bytes | SHA256(text): 398f86cb7ea6ca6a8362b6114b5d5af9172feea88b74243af669cf415c3a4d8f
--------------------------------------------------------------------------------
# user_app/signals.py
from PyQt5.QtCore import QObject, pyqtSignal


class SyncSignals(QObject):
    """
    Общие сигналы синка/управления для прокидывания в GUI и фоновый менеджер.
    """
    # Администратор принудительно завершил сессию
    force_logout = pyqtSignal()
    # Телеметрия синхронизации (обновляется после каждого цикла)
    sync_status_updated = pyqtSignal(dict)

--------------------------------------------------------------------------------
# FILE: user_app\ui_helpers.py
# SIZE: 915 bytes | SHA256(text): 5e17c90fa5930c93d96d64d421c101987d71c21e69eda74c4093952e8ac4c4f5
--------------------------------------------------------------------------------
# user_app/ui_helpers.py
import re, time
from typing import Optional

EMAIL_RE = re.compile(r"^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}$", re.IGNORECASE)

class MessageDebouncer:
    """
    Блокирует повтор одного и того же сообщения в течение N секунд,
    чтобы не было дубля "e-mail не найден".
    """
    def __init__(self, cooldown_sec: float = 1.0):
        self.cooldown = cooldown_sec
        self._last_key: Optional[str] = None
        self._last_ts: float = 0.0

    def should_show(self, key: str) -> bool:
        now = time.monotonic()
        if self._last_key == key and (now - self._last_ts) < self.cooldown:
            return False
        self._last_key, self._last_ts = key, now
        return True

def is_valid_email(email: str) -> bool:
    return bool(EMAIL_RE.match((email or "").strip()))

--------------------------------------------------------------------------------
# FILE: work_time_tracker.egg-info\dependency_links.txt
# SIZE: 1 bytes | SHA256(text): 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
# FILE: work_time_tracker.egg-info\entry_points.txt
# SIZE: 257 bytes | SHA256(text): dfbe78e5fd4cef48f42cf4aa4e603286c7b2945c2dd1afab51d031a858b4df22
--------------------------------------------------------------------------------
[console_scripts]
wtt-admin = admin_app.main_admin:main
wtt-archive = tools.archive_cli:main
wtt-doctor = tools.doctor:main
wtt-send = tools.tg_send:main
wtt-telebot = telegram_bot.main:main
wtt-tg-env = tools.tg_envcheck:main
wtt-user = user_app.main:main

--------------------------------------------------------------------------------
# FILE: work_time_tracker.egg-info\requires.txt
# SIZE: 131 bytes | SHA256(text): a5114a6ed8158dfe0c7811946380ce52a4810e2268e711431b4adba5869bdbce
--------------------------------------------------------------------------------
PyQt5>=5.15
gspread>=6.0.0
google-auth>=2.0.0
google-auth-oauthlib>=1.0.0
requests>=2.31
urllib3>=2.0
python-dateutil>=2.9.0.post0

--------------------------------------------------------------------------------
# FILE: work_time_tracker.egg-info\SOURCES.txt
# SIZE: 781 bytes | SHA256(text): 9a933f37829522dbc1a73c498771bf87ba0f855276edbd20f5aafa66a86577e0
--------------------------------------------------------------------------------
config.py
logging_setup.py
pyproject.toml
sheets_api.py
admin_app/gui_admin.py
admin_app/main_admin.py
admin_app/repo.py
admin_app/schedule_parser.py
sync/__init__.py
sync/network.py
sync/notifications.py
sync/sync_queue.py
telegram_bot/__init__.py
telegram_bot/main.py
telegram_bot/notifier.py
tools/doctor.py
tools/tg_envcheck.py
tools/tg_send.py
user_app/__init__.py
user_app/api.py
user_app/db_local.py
user_app/db_migrations.py
user_app/gui.py
user_app/login_window.py
user_app/main.py
user_app/signals.py
user_app/ui_helpers.py
work_time_tracker.egg-info/PKG-INFO
work_time_tracker.egg-info/SOURCES.txt
work_time_tracker.egg-info/dependency_links.txt
work_time_tracker.egg-info/entry_points.txt
work_time_tracker.egg-info/requires.txt
work_time_tracker.egg-info/top_level.txt

--------------------------------------------------------------------------------
# FILE: work_time_tracker.egg-info\top_level.txt
# SIZE: 75 bytes | SHA256(text): 60bedc573116b9f548d9b9860dc19f85ebdd1beeb2758883f7c48720aaac571d
--------------------------------------------------------------------------------
admin_app
config
logging_setup
sheets_api
sync
telegram_bot
tools
user_app
